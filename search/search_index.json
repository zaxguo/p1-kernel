{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A tiny, modern kernel for Raspberry Pi 3","text":"<p>Experiment descriptions are for you to read &amp; reproduce. The assignments will be on LMS (e.g. Canvas). </p> <p>Get the code: </p> <pre><code>git clone https://github.com/fxlin/p1-kernel\n# load build commands\ncd p1-kernel &amp;&amp; source env-qemu.sh\n</code></pre> <p>A tiny kernel incrementally built for OS education. </p> <p>Start with minimal, baremetal code. Then each assignment adds new features. Each experiment is a self-contained and can run on both Rpi3 hardware and QEMU. </p> <p>On the website, there is a top-right search box -- use it!</p>"},{"location":"#learning-objectives","title":"Learning objectives","text":"<p>Knowledge: </p> <ul> <li>protection modes</li> <li>interrupt handling</li> <li>preemptive scheduling</li> <li>virtual memory </li> </ul> <p>Skills: </p> <ul> <li>Learning by doing: the core concepts of a modern OS kernel</li> <li>Experiencing OS engineering: hands-on programming &amp; debugging at the hardware/software boundary</li> <li>Daring to plumb: working with baremetal hardware: CPU protection modes, registers, IO, MMU, etc.</li> </ul> <p>Secondary: * Armv8 programming. Arm is everywhere, including future Mac.  * Working with C and assembly  * Cross-platform development </p> <p>Non-goals:</p> <ul> <li>Non-core or advanced functions of OS kernel, e.g. filesystem or power management, which can be learnt via experimenting with commodity OS. </li> <li>Rpi3-specific hardware details. The SoC of Rpi3 is notoriously unfriendly to kernel hackers. </li> <li>Implementation details of commodity kernels, e.g. Linux or Windows.  </li> </ul>"},{"location":"#experiments","title":"Experiments","text":"<ol> <li>Sharpen your tools! (p1 exp0) </li> <li>Helloworld from baremetal (p1 exp1) <ul> <li>Power on + UART bring up</li> <li>Simplifying dev workflow (rpi3 hardware only)</li> </ul> </li> <li>Exception elevated (p1 exp2) <ul> <li>CPU initialization, exception levels</li> </ul> </li> <li>Heartbeats on (p1 exp3) <ul> <li>Interrupt handling</li> <li>Interrupt-driven animation</li> </ul> </li> <li>Process scheduler (p1 exp4) <ul> <li>A. Cooperative </li> <li>B. Preemptive </li> </ul> </li> <li>A world of two lands (p1 exp5) <ul> <li>User processes and system calls </li> </ul> </li> <li>Into virtual (p1 exp6) <ul> <li>Virtual memory management </li> </ul> </li> </ol>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>Derived from the RPi OS project and its tutorials, which is modeled after the Linux kernel. </p>"},{"location":"cheatsheet/","title":"ARMv8 cheat sheet","text":""},{"location":"cheatsheet/#general-purpose-registers","title":"General purpose registers","text":"<ul> <li> <p>x0 - x30: 64-bit general purpose registers, where: </p> </li> <li> <p>x0-x18. callee can corrupt</p> <ul> <li>x0-x7  Arguments and  return values.  additional arguments are on the stack</li> <li>x8: Indirect result. For syscalls, the syscall number is in r8</li> </ul> </li> <li>x19-x29: callee must preserve<ul> <li>x9-x28: caller-saved registers. In general okay to use in your code</li> </ul> </li> <li>x29 (FP): frame pointer, pointing to the base of the current stack frame</li> <li>x30 (LR): link register</li> <li>SP      Stack pointer                      </li> <li>PC     Program counter                     </li> </ul> <p>Our GDB customization color-codes the registers. </p> <p>White highlight (x0-x7): parameter/results; red background (x19-x29): callee saved. </p> <p>(Green reg values: the values have changed since the last instruction)</p> <p></p>"},{"location":"cheatsheet/#special-purpose-registers","title":"Special purpose registers","text":"Control and Translation Registers SCTLR EL{1..3}   System Control ACTLR EL{1..3}  Auxiliary Control                            64 CPACR EL1       Architectural Feature Access Control HCR EL2         Hypervisor Configuration                     64 CPTR EL{2,3}    Architectural Feature Trap HSTR EL2        Hypervisor System  Trap HACR EL2        Hypervisor Auxiliary Control SCR EL3         Secure Configuration TTBR0  EL{1..3}  Translation Table Base 0 (4/16/64kb aligned)    64 TTBR1  EL1       Translation Table Base 1 (4/16/64kb aligned)    64 TCR EL{1..3}     Translation Control                           64 VTTBR  EL2      Virt Translation Table Base (4/16/64kb aligned)  64 VTCR EL2        Virt Translation Control {A}MAIR EL{1..3} {Auxiliary} Memory Attribute Indirection         64 LOR{S,E}A EL1   LORegion {Start,End} Address                64,1 LOR{C,N,ID} EL1   LORegion {Control,Number,ID}           64,1 System Control Register (SCTLR) M      0x00000001 MMU enabled A      0x00000002 Alignment check enabled C     0x00000004 Data and  unified caches enabled SA    0x00000008 Enable SP alignment check SA0   0x00000010 Enable  SP alignment check  for EL0             E1 UMA   0x00000200 Trap EL0 access of DAIF to EL1               E1 I       0x00001000 Instruction cache enabled DZE    0x00004000 Trap EL0 DC instruction to EL1               E1 UCT   0x00008000 Trap EL0 access of CTR EL0 to EL1            E1 nTWI  0x00010000 Trap EL0 WFI instruction to EL1              E1 nTWE  0x00040000 Trap EL0 WFE instruction to EL1              E1 WXN  0x00080000 Write permission implies  XN SPAN   0x00800000 Set privileged access never                  E1,1 E0E   0x01000000 Data at EL0 is big-endian                    E1 EE    0x02000000 Data at EL1 is big-endian UCI   0x04000000 Trap EL0 cache instructions to EL1             E1 Secure Configuration Registers (SCR) NS   0x0001 System state is non-secure unless  in EL3 IRQ   0x0002  IRQs taken to EL3 FIQ   0x0004 FIQs taken to EL3 EA    0x0008  External aborts and  SError taken to EL3 SMD  0x0080 Secure monitor call disable HCE   0x0100 Hyp Call enable SIF   0x0200 Secure instruction fetch RW    0x0400 Lower  level is AArch64 ST     0x0800  Trap secure EL1 to CNTPS registers to EL3 TWI   0x1000 Trap EL{0..2} WFI instruction to EL3 TWE  0x2000 Trap EL{0..2} WFE instruction to EL3 TLOR  0x4000 Trap LOR registers                                1 Generic Timer Registers CNTFRQ EL0                  Ct Frequency (in Hz) CNT{P,V}CT EL0               Ct {Physical,Virtual} Count   RO,64 CNTVOFF EL2                 Ct Virtual Offset              64 CNTHCTL  EL2                 Ct Hypervisor Control CNTKCTL   EL1                 Ct Kernel Control CNT{P,V} {TVAL,CTL,CVAL} EL0 Ct {Physical,Virtual} Timer CNTHP {TVAL,CTL,CVAL} EL2   Ct Hypervisor Physical Timer CNTPS {TVAL,CTL,CVAL} EL1    Ct Physical  Secure Timer CNTHV {TVAL,CTL,CVAL} EL2   Ct Virtual Timer                 1"},{"location":"cheatsheet/#exception-levels","title":"Exception levels","text":"AArch64/ARMv8 name remarks EL3 highest exception level, mostly for firmware EL2 exception level for hypervisors like Xen (or parts of KVM) EL1 the Linux kernel is running in this EL0 for unprivileged userland"},{"location":"cheatsheet/#exception-vectors","title":"Exception vectors","text":"<p>EL1t Exception is taken from EL1 while stack pointer was shared with EL0. This happens when SPSel register holds the value 0.</p> <p>EL1h Exception is taken from EL1 at the time when dedicated stack pointer was allocated for EL1. This means that SPSel holds the value 1 and this is the mode that we are currently using.</p> <p>EL0_64 Exception is taken from EL0 executing in 64-bit mode.</p> <p>EL0_32 Exception is taken from EL0 executing in 32-bit mode.</p>"},{"location":"cheatsheet/#pstate","title":"PSTATE","text":"<p>See \"Fundamentals of ARMv8-A\", Chapter \"Processor state\"</p>"},{"location":"cheatsheet/#return-from-exceptions","title":"Return from exceptions","text":"<p>ELR_EL1, Exception Link Register. \"When taking an exception to EL1, holds the address to return to.\"</p> <p>SPSR_EL1, status regs, including irq enable/disable</p> <p>eret. Returns from an exception. It restores the processor state based on SPSR_ELn and branches to ELR_ELn, where n is the current exception level.</p>"},{"location":"cheatsheet/#common-instructions","title":"Common instructions","text":"<p>A more detailed instruction quick reference </p> <ul> <li>mrs   Load value from a system register to one of the general purpose registers (x0\u2013x30)</li> <li>and   Perform the logical AND operation. </li> <li>cbz   Compare the result of the previously executed operation to 0 and jump (or <code>branch</code> in ARM terminology) to the provided label if the comparison yields true.</li> <li>b     Perform an unconditional branch to some label.</li> <li>adr   Load a label's relative address into the target register. In this case, we want pointers to the start and end of the <code>.bss</code> region.</li> <li>sub   Subtract values from two registers.</li> <li>bl    \"Branch with a link\": perform an unconditional branch and store the return address in x30 (the link register). When the subroutine is finished, use the <code>ret</code> instruction to jump back to the return address.</li> <li>mov   Move a value between registers or from a constant to a register.</li> <li>cbz, cbnz Compare and Branch on Zero, Compare and Branch on Non-Zero.</li> <li>stp   store a pair of registers</li> </ul> Condition  Codes EQ    Equal                        Z NE    Not  equal                     !Z CS/HS  Carry set, Unsigned higher or same C CC/LO  Carry clear, Unsigned lower       !C MI     Minus, Negative               N PL     Plus, Positive or zero            !N VS    Overflow                     V VC    No overflow                   !V HI      Unsigned higher                C &amp; !Z LS    Unsigned lower or same           !C | Z GE    Signed greater than or equal      N = V LT     Signed less than                N /= V GT     Signed greater than             !Z &amp;  N = V LE    Signed less than or equal         Z | N /= V AL     Always (default)                 1"},{"location":"cheatsheet/#architecture-naming","title":"Architecture naming","text":"<p>There is an updated ARM architecture revision called \"ARMv8\", which evolved from the ARMv7 architecture. Among other things it introduces a new execution state called \"AArch64\", which provides a full 64-bit architecture.</p> <p>ARMv8 compliant implementations can provide this state or not, also they are free to implement the \"AArch32\" state, which closely resembles the ARMv7 architecture. So both 32-bit and 64-bit states are optional - but you should of course have at least one ;-). ARM Cortex cores provide both states, while there are implementations from other vendors which do not provide AArch32, for instance.</p> <p>The Linux kernel chose to call this new architecture \"arm64\", the same name got picked up by Debian for their architecture port name.</p> <p>The GNU toolchain however elected the official \"aarch64\" name for the port, so the GCC (cross-)compiler is usually called \"aarch64-linux-gnu-gcc\". So although the arm64 name is not official, it can be used interchangeably for aarch64.</p>"},{"location":"cheatsheet/#references","title":"References","text":"<p>This page incorporates many contents from various sources. </p> <ul> <li>\"arm64 assembly crash course\", https://github.com/Siguza/ios-resources/blob/master/bits/arm64.md</li> <li>https://linux-sunxi.org/Arm64#ARM64_cheat_sheet</li> <li>https://wiki.cdot.senecacollege.ca/wiki/AArch64_Register_and_Instruction_Quick_Start</li> <li>https://tc.gts3.org/cs3210/2020/spring/r/AArch64-ISA-Cheat-Sheet.pdf</li> <li>\"ARMv8 A64 Quick Reference\", https://github.com/flynd/asmsheets</li> </ul>"},{"location":"dump/","title":"Inspect kernel binary","text":""},{"location":"dump/#lookup-source-line-given-an-address","title":"Lookup source line given an address","text":"<pre><code>addr2line -e build/kernel8.elf 0x80038\n</code></pre> <p>Explanation: -e specifies the ELF file with debugging info, followed by a given address</p>"},{"location":"dump/#list-all-symbols-addresses","title":"List all symbols &amp; addresses","text":"<pre><code>nm build/kernel8.elf\n</code></pre> <p>Output format: \"link address\" - \"symbol type\" - \"symbol name\". Sample output below. Your symbol names &amp; addresses may be different.</p> <pre><code>ffff000000082934 t a2d\nffff0000000829b4 t a2i\n...\nffff000000085130 B bss_begin\nffff000000102944 B bss_end\n...\nffff000000081000 T user_begin\nffff0000000810c8 T user_delay\nffff00000008112e R user_end\nffff00000008105c T user_process\n</code></pre>"},{"location":"dump/#kernel-disassembly","title":"Kernel disassembly","text":""},{"location":"dump/#disassemble-the-whole-kernel","title":"Disassemble the whole kernel","text":"<pre><code>aarch64-linux-gnu-objdump -dS build/kernel8.elf\n</code></pre> <p>Explanation: -d disassembly; -S interleave assembly instructions with source</p> <p>Sample output: </p> <pre><code>build/kernel8.elf:     file format elf64-littleaarch64\nDisassembly of section .text.boot:\nffff000000080000 &lt;_start&gt;:\n.section \".text.boot\"\n.globl _start\n_start:\n        mrs     x0, mpidr_el1\nffff000000080000:       d53800a0        mrs     x0, mpidr_el1\n        and     x0, x0,#0xFF            // Check processor id\nffff000000080004:       92401c00        and     x0, x0, #0xff\n...\nvoid user_process()\n{\nffff00000008105c:       a9be7bfd        stp     x29, x30, [sp, #-32]!\nffff000000081060:       910003fd        mov     x29, sp\n        call_sys_write(\"User process\\n\\r\");\nffff000000081064:       90000000        adrp    x0, ffff000000081000 &lt;loop&gt;\nffff000000081068:       9103e000        add     x0, x0, #0xf8\nffff00000008106c:       9400001a        bl      ffff0000000810d4 &lt;call_sys_write&gt;\n        int pid = call_sys_fork();\nffff000000081070:       9400001f        bl      ffff0000000810ec &lt;call_sys_fork&gt;\nffff000000081074:       b9001fa0        str     w0, [x29, #28]\n...\n</code></pre>"},{"location":"dump/#disassemble-a-specific-address-range","title":"Disassemble a specific address range","text":"<pre><code>aarch64-linux-gnu-objdump -dS build/kernel8.elf \\\n--start-address=0xffff000000081000 \\\n--stop-address=0xffff00000008112e \n</code></pre> <p>Explanation: -d disassembly; -S interleave assembly instructions with source</p> <p>Sample output: </p> <pre><code>build/kernel8.elf:     file format elf64-littleaarch64\nDisassembly of section .text.user:\nffff000000081000 &lt;loop&gt;:\n#include \"user_sys.h\"\n#include \"user.h\"\n#include \"printf.h\"\n\nvoid loop(char* str)\n{\nffff000000081000:       a9bd7bfd        stp     x29, x30, [sp, #-48]!\nffff000000081004:       910003fd        mov     x29, sp\nffff000000081008:       f9000fa0        str     x0, [x29, #24]\n        char buf[2] = {\"\"};\nffff00000008100c:       790053bf        strh    wzr, [x29, #40]\n        while (1){\n</code></pre>"},{"location":"dump/#disassemble-a-specific-function","title":"Disassemble a specific function","text":"<pre><code>gdb-multiarch -batch -ex 'file build/kernel8.elf' -ex 'disassemble /mr loop'\n</code></pre> <p>Explanation: -multiarch is the gdb version that can recognize aarch64 instructions. </p> <p>Sample output:</p> <pre><code>Dump of assembler code for function loop:\n6       {\n   0x00081000 &lt;+0&gt;:     fd      std\n   0x00081001 &lt;+1&gt;:     7b bd   jnp    0x80fc0\n   0x00081003 &lt;+3&gt;:     a9 fd 03 00 91  test   $0x910003fd,%eax\n   0x00081008 &lt;+8&gt;:     a0 0f 00 f9 bf  mov    0xbff9000f,%al\n\n7               char buf[2] = {\"\"};\n</code></pre>"},{"location":"dump/#dump-a-section-as-raw-bytes","title":"Dump a section as raw bytes","text":"<pre><code>aarch64-linux-gnu-objdump -s -j .rodata build/kernel8.elf\n</code></pre> <p>Explanation: -j specify which elf section (.rodata in this example) to dump. </p> <p>Sample output: </p> <pre><code>Contents of section .rodata:                                                                                                         [0/1839] ffff0000000849a8 4b65726e 656c2070 726f6365 73732073  Kernel process s\n ffff0000000849b8 74617274 65642e20 454c2025 640d0a00  tarted. EL %d...\n ffff0000000849c8 4572726f 72207768 696c6520 6d6f7669  Error while movi\n ffff0000000849d8 6e672070 726f6365 73732074 6f207573  ng process to us\n ffff0000000849e8 6572206d 6f64650a 0d000000 00000000  er mode.........\n ffff0000000849f8 6b65726e 656c2062 6f6f7473 202e2e2e  kernel boots ...\n ffff000000084a08 0a0d0000 00000000 6572726f 72207768  ........error wh\n ffff000000084a18 696c6520 73746172 74696e67 206b6572  ile starting ker\n</code></pre>"},{"location":"dump/#disassemblers","title":"Disassemblers","text":""},{"location":"dump/#online-aarch64-disassemblers","title":"Online aarch64 disassemblers","text":"<ul> <li>https://armconverter.com</li> <li>https://shell-storm.org/online/Online-Assembler-and-Disassembler</li> </ul>"},{"location":"dump/#oda-offline-for-now-for-archival-purpose","title":"ODA (offline for now, for archival purpose)","text":"<p>https://onlinedisassembler.com/odaweb/  </p> <p>A nice web UI for disassembling ELF files</p> <p>Download kernel8.elf to your local machine, if you build it on the course server. Command line users: use the  <code>scp</code> command. VSCode users: right click on kernel8.elf-&gt;Download. </p> <p></p> <p>Then, upload the file to ODA.</p> <p> Figure above: upload file to ODA. </p> <p> Figure above: ODA recognizes the uploaded file as ELF for aarch64. </p> <p></p> <p>Figure above: kernel8.elf disassembled. Top (the blue bar): a mini map of memory layout. Left: a list of symbols. Right: the list of instructions at the specified symbol. </p> <p></p> <p>Figure above: ODA shows ELF sections of kernel8.elf. </p> <p></p> <p>Figure above: ODA visualizes the memory layout of IRQ vectors </p>"},{"location":"gdb/","title":"Using GDB to debug kernel","text":"<p>NOTE: </p> <ol> <li>Read the whole document before you try. </li> <li>WSL users who want to develop on local machines instead of the server: gdbserver may not play well with WSL. See \"troubleshooting\"  below. You are fine if you develop on the server. </li> </ol>"},{"location":"gdb/#gdb-installation-not-needed-if-you-use-course-servers","title":"GDB Installation (not needed if you use course servers)","text":"<p>We've done this on the server already. Do this if developing on local machines (Linux or WSL). </p> <pre><code>sudo apt install gdb-multiarch gcc-aarch64-linux-gnu build-essential \n</code></pre> <p>Note: the gdb for aarch64 is NOT called aarch64-XXXX-gdb.</p>"},{"location":"gdb/#the-workflow","title":"The workflow","text":""},{"location":"gdb/#1-launch-qemu-the-kernel-and-wait-for-the-debugger","title":"1. Launch QEMU + the kernel and wait for the debugger","text":"<p>1/24/2024: the below can be done with one command \"p1-run-debug\" (after \"source env-qemu.sh\")</p> <pre><code># will wait for gdb to connect at local tcp 1234\nqemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S\n\n# OR, will wait for gdb to connect at local tcp 5678\nqemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -gdb tcp::5678 -S\n</code></pre> <p>Explanation: -S not starting the guest until you tell it to from gdb.  -s listening for an incoming connection from gdb on TCP port 1234</p> <p>WARNING If multiple students run the first command on the server machine, they all attempt to listen on tcp port 1234. Only one will succeed. If you see such a failure, use the second form to specify a different TCP port number (not necessarily 5678 which may be in use as well). </p> <pre><code>xzl@granger1[~]$ netstat -tulpn|grep 5678\n(Not all processes could be identified, non-owned process info\n will not be shown, you would have to be root to see it all.)\ntcp        0      0 0.0.0.0:5678            0.0.0.0:*               LISTEN      -\ntcp6       0      0 :::5678                 :::*                    LISTEN      -\nxzl@granger1[~]$ netstat -tulpn|grep 1234\n(Not all processes could be identified, non-owned process info\n will not be shown, you would have to be root to see it all.)\ntcp        2      0 0.0.0.0:1234            0.0.0.0:*               LISTEN      -\ntcp        0      0 127.0.0.1:12345         0.0.0.0:*               LISTEN      -\ntcp        0      0 127.0.0.1:12346         0.0.0.0:*               LISTEN      -\ntcp6       0      0 :::1234                 :::*                    LISTEN      -\n</code></pre>"},{"location":"gdb/#launch-gdb","title":"Launch GDB","text":"<p>From another terminal</p> <pre><code>gdb-multiarch build/kernel8.elf \n(gdb) target remote :1234 \n(gdb) layout asm \n</code></pre> <p>The port number (e.g. 1234) must match what you specified for QEMU.</p> <p>Single step </p> <pre><code>(gdb) si \n</code></pre> <p></p>"},{"location":"gdb/#dump-register-contents","title":"Dump register contents","text":"<pre><code>(gdb) info reg \n</code></pre> <p>show reg information at each step. This example shows </p> <pre><code>(gdb) display/10i $sp\n</code></pre> <p></p>"},{"location":"gdb/#dump-memory","title":"Dump memory","text":"<p>You can specify a symbol or a raw addr </p> <p>... as instructions</p> <pre><code>x/20i _start\n</code></pre> <p>... as hex (bytes)</p> <pre><code>x/20xb _start\n</code></pre> <p>... as hex (words)</p> <pre><code>x/20xw _start\n</code></pre> <p>... as a textual string</p> <pre><code>x/s _start\nx/s $x0\n</code></pre>"},{"location":"gdb/#print-out-variablesstructures","title":"Print out variables/structures","text":"<pre><code>print *mem_map\n</code></pre> <p>print the first 10 elements of mem_map, a pointer of type short*</p> <pre><code>print (short[10])*mem_map\n</code></pre>"},{"location":"gdb/#set-a-breakpoint-at-addr","title":"Set a breakpoint at addr","text":"<pre><code>b *0xffff0000\n</code></pre>"},{"location":"gdb/#disassemble-at-given-addr","title":"Disassemble at given addr","text":"<pre><code>disas 0xffff0000\n</code></pre>"},{"location":"gdb/#functionsource-lookup","title":"Function/source lookup","text":"<p>Look up type of a given symbol </p> <pre><code>ptype mem_map\n</code></pre> <p>Find out function name at a given addr</p> <pre><code>info line *0x10000000\n</code></pre> <p>List source at a given addr</p> <pre><code>list *0x10000000\nlist *fn \n</code></pre>"},{"location":"gdb/#watchpoint","title":"Watchpoint","text":"<p>Will break if the given memory addr is altered </p> <pre><code>watch *0xffff0000\n</code></pre>"},{"location":"gdb/#the-gdb-dashboard-enhancement","title":"The GDB \"dashboard\" enhancement","text":"<p>The basic GDB UI is too primitive to beginners. We provide you an enhancement called GDB-dashboard. The upstream source is here. I adapted it for aarch64. Screenshot: </p> <p></p>"},{"location":"gdb/#installation","title":"Installation","text":"<p>Grab from my repository: </p> <pre><code>wget -P ~ https://raw.githubusercontent.com/fxlin/gdb-dashboard-aarch64/master/.gdbinit\n</code></pre> <p>There's only one file: <code>.gdbinit</code>. It's the initial script that GDB will load upon start. The above line download it to your home directory. </p>"},{"location":"gdb/#set-your-port","title":"Set your port","text":"<p>Open ~/.gdbinit. Go to near line 2500 where you can see initialization commands for GDB, e.g. </p> <pre><code>file build/kernel8.elf\ntarget remote :1234\n</code></pre> <p>The port number (e.g. 1234) must match what you specified for QEMU.</p>"},{"location":"gdb/#usage","title":"Usage","text":"<p>All GDB commands still apply, e.g. \"si\" is single step per instruction; \"b\" is to set a breakpoint; \"c\" for continuing execution. See below for more. </p> <p>The major features here are multiple views: for registers, stack, assembly, and source. </p>"},{"location":"gdb/#customize","title":"Customize","text":"<p>GDB execute these commands whenever it starts, so you do not have to type them every time. </p> <p>In the above example, GDB loads the ELF file kernel8.elf (only for parsing symbols and debugging info); it connects to a remote target at local port 1234. </p> <p>Lines below customize gdb-dashboard behaviors, e.g. </p> <pre><code>dashboard source -style height 15\ndashboard assembly -style height 8\n</code></pre> <p>These lines set the height of the \"source\" panel and the \"assembly\" panel. </p> <p>The best documentation of gdb-dashboard seems from typing <code>help dashboard</code> in the GDB console. e.g. In GDB, type: </p> <pre><code>&gt;&gt;&gt; help dashboard expressions \n</code></pre> <p>Cannot connect? See \"troubleshooting\" below.</p>"},{"location":"gdb/#other-enhancement-fyi","title":"Other enhancement (FYI)","text":"<p>GEF (https://github.com/hugsy/gef) is also viable. Both GEF and GDB-dashboard: </p> <ul> <li> <p>Both enhanced GDB significantly. </p> </li> <li> <p>GEF understands aarch64 semantics (e.g. CPU flags) very well. It can even tell why a branch was taken/not taken. However, GEF does not parse aarch64 callstack properly (at least I cannot get it work). </p> </li> <li> <p>GDB-dashboard nicely parses the callstack. It, however, does not display aarch64 registers properly. </p> </li> </ul> <p>GEF screenshot (note the CPU flags it recognized)</p> <p></p>"},{"location":"gdb/#troubleshooting","title":"Troubleshooting","text":"<p>Cannot connect and need help? Report the following:</p> <ul> <li>Your QEMU version. i.e. the output of \"qemu-system-aarch64  --version\"</li> <li>Have you tried other kernel binaries, e.g. from p1exp1? And the binaries provided by us? https://github.com/fxlin/p1-kernel/releases</li> <li>The full commands you use to launch QEMU. Have you tried different port numbers? </li> <li>Launch GDB w/o loading .gdbinit: </li> </ul> <pre><code>gdb-multiarch -n\n</code></pre> <p>Then enter GDB commands manually, e.g. load, target remote, etc. Does the problem persist? What's the output? </p> <ul> <li>Attach screenshot(s) of the above steps, if possible. </li> </ul> <p>WSL caveat:</p> <p>\"gdbserver: Target description specified unknown architecture \u201caarch64\u201d  https://stackoverflow.com/questions/53524546/gdbserver-target-description-specified-unknown-architecture-aarch64  It seems GDB server does not play well with WSL\u2026 be aware! </p>"},{"location":"gdb/#reference","title":"Reference","text":"<p>Launch qemu with gdb </p> <p>https://en.wikibooks.org/wiki/QEMU/Debugging_with_QEMU#Launching_QEMU_from_GDB </p> <p>more info about gdb for kernel debugging </p> <p>https://wiki.osdev.org/Kernel_Debugging </p> <p>Good article</p> <p>https://interrupt.memfault.com/blog/advanced-gdb#source-files</p>"},{"location":"jtag/","title":"JTAG for Rpi3","text":"<p>Picture above: A JTAG debugger (blackbox), among other things, connected to an Rpi3 board. </p> <p>JTAG is a special hardware connection to a target board, allowing debugging of the target board in situ -- watching registers,  setting breakpoints, dumping memory regions -- just as we debug kernel on QEMU. </p> <p>While sounding very useful, JTAG is not widely used even by kernel hackers as a debugging method. When building kernels on real hardware, programmers mostly debug by printing to UART, except for the very early stage of kernel boot, before the UART is up. </p> <p>Because of this reason, hardware/software for JTAG is lacking, even for popular boards like Rpi. Years ago, I have done JTAG debugging with a board of Texas Instruments (Pandaborad, Cortex-A9) with their $5,000 proprietary tool. I can attest it was very difficult to use. </p> <p>For education purpose though, it may be useful to watch registers &amp; set breakpoints when we play with Rpi3. There are reports on how to do so (see references below). In general, the support for aarch64 seems spotty (as opposed to microcontroller boards).  As of Jan 2021, the support was described as \"stalled\". I would expect caveats. </p> <p>That being said, it's gonna be fun to try! If you are interested, let us know by all means! We can provide JTAG hardware for you. </p> <p>References:</p> <p>https://metebalci.com/blog/bare-metal-raspberry-pi-3b-jtag/</p> <p>https://www.suse.com/c/debugging-raspberry-pi-3-with-jtag/</p> <p>https://www.linaro.org/blog/open-on-chip-debugger-ocd-at-linaro/</p> <p>https://collaborate.linaro.org/display/TCWGPUB/OpenOCD+for+AArch64</p>"},{"location":"qemu/","title":"QEMU cheetsheet (make it easier to use)","text":""},{"location":"qemu/#add-qemu-to-path","title":"Add QEMU to PATH","text":"<pre><code># assuming the qemu source tree has been built, and it is under ./qemu\nexport PATH=\"$(pwd)/qemu/aarch64-softmmu:${PATH}\"\n\n# (optional: grab a sample kernel binary for testing)\nwget https://github.com/fxlin/p1-kernel/releases/download/exp1-qemu/kernel8.img\n</code></pre> <p>Explanation: the <code>export</code> command adds the path to QEMU to the search paths, so that whenever you type <code>qemu-system-aarch64</code>, the shell can find it. You may want to add the line to <code>~/.bashrc</code> so it is executed whenever you log in to the server</p> <p><code>echo export PATH=\"$(pwd)/aarch64-softmmu:${PATH}\" &gt;&gt; ~/.bashrc</code></p> <p>To test if the QEMU path is added to PATH.</p> <pre><code>$ whereis qemu-system-aarch64\nqemu-system-aarch64: /home/xzl/qemu/aarch64-softmmu/qemu-system-aarch64\n</code></pre> <p>Note the output path is just an example from my machine.</p>"},{"location":"qemu/#launch-the-kernel-free-run","title":"Launch the kernel, free run","text":"<pre><code>qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio\n\n# if you want to suppress graphics ... \nqemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -nographic\n</code></pre> <p>Explanation:  * -M machine type * Two \"-serial\" options correspond to the two UARTs of Rpi3 as emulated by QEMU. Note: Our kernel writes message to the 2nd one. So we tell QEMU to redirect the 2nd UART to stdio. </p>"},{"location":"qemu/#launch-the-kernel-for-gdb-debugging","title":"Launch the kernel, for GDB debugging","text":"<pre><code># will wait for gdb to connect at local tcp 1234\nqemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S\n\n# will wait for gdb to connect at local tcp 5678\nqemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -gdb tcp::5678 -S\n</code></pre> <p>Explanation: -S not starting the guest until you tell it to from gdb.  -s listening for an incoming connection from gdb on TCP port 1234</p> <p>The second form is useful in that if multiple students attempt to listen on tcp port 1234 on the same machine, all but one will fail. See  for details. </p>"},{"location":"qemu/#launch-the-kernel-with-monitor","title":"Launch the kernel with monitor","text":"<pre><code>qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -monitor stdio\n# multiplex both board serial and monitor output on stdio\nqemu-system-aarch64 -machine raspi3 -serial null -serial mon:stdio -kernel kernel8.img\n</code></pre> <p>More on the monitor mode. </p>"},{"location":"qemu/#launch-the-kernel-with-tracing","title":"Launch the kernel with tracing","text":"<pre><code>qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -d int -D qemu.log \n</code></pre> <p>Explanation: </p> <ul> <li>-d int enables interrupt dedug       </li> <li>-D test.log  puts debug msg to a file \"qemu.log\"</li> </ul> <p>Sample log from executing p1exp3:</p> <pre><code>Exception return from AArch64 EL2 to AArch64 EL1 PC 0x80038\nTaking exception 5 [IRQ]\n...from EL1 to EL1\n...with ESR 0x0/0x0\n...with ELR 0x8095c\n...to EL1 PC 0x81a80 PSTATE 0x3c5\nException return from AArch64 EL1 to AArch64 EL1 PC 0x8095c\nTaking exception 5 [IRQ]\n...from EL1 to EL1\n...with ESR 0x0/0x0\n...with ELR 0x8095c\n...to EL1 PC 0x81a80 PSTATE 0x3c5\nException return from AArch64 EL1 to AArch64 EL1 PC 0x8095c\nTaking exception 5 [IRQ]\n...from EL1 to EL1\n...with ESR 0x0/0x0\n...with ELR 0x8095c\n...to EL1 PC 0x81a80 PSTATE 0x3c5\nException return from AArch64 EL1 to AArch64 EL1 PC 0x8095c\nTaking exception 5 [IRQ]\n...from EL1 to EL1\n...with ESR 0x0/0x0\n...with ELR 0x8095c\n...to EL1 PC 0x81a80 PSTATE 0x3c5\nException return from AArch64 EL1 to AArch64 EL1 PC 0x8095c\n</code></pre> <p>Quick explanation: </p> <ul> <li>ESR - exception syndrome register, encoding the cause of the exception. </li> <li>ELR - exception link register, containing the return address of the exception handler. </li> <li>PSTATE - CPU flags when the exception is taken </li> </ul>"},{"location":"qemu/#putting-everything-in-one-file-env-qemush","title":"Putting everything in one file (env-qemu.sh)","text":"<pre><code># change the line as needed\nexport PATH=\"${HOME}/qemu/aarch64-softmmu:${PATH}\"\n\nrun-uart0() {\n   qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial stdio\n}\n\nrun() {\n    qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio\n}\n\nrun-mon() {\n    qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -monitor stdio\n}\n\nrun-debug() {\n    qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -s -S\n}\n\nrun-log() {\n    qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio -d int -D qemu.log \n}\n</code></pre> <p>To use: every time when you log in to the server and wants to develop the kernel</p> <pre><code># switch to dir where the qemu source directory is qemu/\n$ source env-qemu.sh\n\n# switch to dir where kernel8.img resides\n$ run\nVNC server running on 127.0.0.1:5900\nkernel boots...\ninterval is set to: 67108864\n</code></pre> <p>A full version of the above file is already in the code repo:</p> <p>https://github.com/fxlin/p1-kernel/blob/master/env-qemu.sh</p>"},{"location":"qemu/#reference","title":"Reference","text":"<p>https://wiki.osdev.org/QEMU</p> <p>All QEMU options: https://github.com/qemu/qemu/blob/master/qemu-options.hx</p>"},{"location":"rationales/","title":"Rationales","text":""},{"location":"rationales/#rationale","title":"Rationale","text":"<p>The kernel must run on cheap &amp; modern hardware. </p> <p>Showing the kernel's evolution path is important. Along the path, each version must be self-contained runnable. </p> <p>We deem the following kernel functions crucial to implement:  * protection modes * interrupt handling * preemptive scheduling * virtual memory </p> <p>Experimenting with these features is difficult with commodity kernels due to their complexity. </p>"},{"location":"rationales/#raspberry-pi-os-project-introduction-or-how-to-efficiently-learn-operating-system-development","title":"Raspberry Pi OS project introduction or how to efficiently learn operating system development?","text":"<p>A few years ago, I opened the source code of the Linux kernel for the first time. At that time, I considered myself more or less a skillful software developer: I knew a little bit of assembler and C programming, and had a high-level understanding of major operating system concepts, such as process scheduling and virtual memory management. However, my first attempt was a complete failure - I understood almost nothing.</p> <p>For other software projects that I have to deal with, I have a simple approach that usually works very well: I find the entry point of the program and then start reading the source code, going as deep as necessary to understand all the details that I am interested in. This approach works well, but not for something as sophisticated as an operating system. It was not just that it took me more than a week just to find an entry point - the main problem was that I quickly found myself in a situation where I was looking at a few lines of code,  and I had no idea how to find any clues about what those lines were doing. This was especially true for the low-level assembler source code, but it worked no better for any other part of the system that I tried to investigate. </p> <p>I don't like the idea of dismissing a problem just because it looks complex from the beginning. Furthermore, I believe that there are no complex problems. Instead, there are a lot of problems we simply don't know how to address efficiently, so I started to look for an effective way to learn OS development in general and Linux in particular.</p>"},{"location":"rationales/#challenges-in-learning-os-development","title":"Challenges in learning OS development","text":"<p>I know that there are tons of books and documentation written about Linux kernel development, but neither of them provides me with the learning experience that I want. Half of the material are so superficial that I already know it. With the other half I have a very similar problem that I have with exploring the kernel source code: as soon as a book goes deep enough, 90% of the details appear to be irrelevant to the core concepts, but related to some security, performance or legacy considerations as well as to millions of features that the Linux kernel supports. As a result, instead of learning core operating system concepts, you always end up digging into the implementation details of those features.</p> <p>You may be wondering why I need to learn operating system development in the first place. For me, the main reason is that I was always interested in how things work under the hood. It is not just curiosity: the more difficult the task you are working on, frequently things begin to trace down to the operating system level. You just can't make fully informed technical decisions if you don't understand how everything works at a lower level. Another thing is that if you really like a technical challenge, working with OS development can be an exciting task for you.</p> <p>The next question you may ask is, why Linux? Other operating systems would probably be easier to approach. The answer is that I want my knowledge to be, at least in some way, relevant to what I am currently doing and to something I expect to be doing in the future. Linux is perfect in this regard because nowadays everything from small IoT devices to large servers tend to run Linux.</p> <p>When I said that most of the books about Linux kernel development didn't work well for me - I wasn't being quite honest. There was one book that explained some essential concepts using the actual source code that I was capable of fully understanding even though I am a novice in OS development. This book is \"Linux Device Drivers\", and it's no wonder that it is one of the most famous technical books about the Linux kernel. It starts by introducing source code of a simple driver that you can compile and play around with. Then it begins to introduce new driver related concepts one by one and explains how to modify the source code of the driver to use these new concepts. That is exactly what I refer to as a \"good learning experience\". The only problem with this book is that it focuses explicitly on driver development and says very little about core kernel implementation details.</p> <p>But why has nobody created a similar book for kernel developers? I think this is because if you use the current Linux kernel source code as a base for your book, then it's just not possible. There is no function, structure, or module that can be used as a simple starting point because there is nothing simple about the Linux source. You also can't introduce new concepts one at a time because in the source code, everything is very closely related to one another. After I realized this, an idea came to me: if the Linux kernel is too vast and too complicated to be used as a starting point for learning OS development, why don't I implement my own OS that will be explicitly designed for learning purposes? In this way, I can make the OS simple enough to provide a good learning experience. Also, if this OS will be implemented mostly by copying and simplifying different parts of the Linux kernel source, it would be straightforward to use it as a starting point to learn the Linux kernel as well. In addition to the OS, I decided to write a series of lectures that teaches major OS development concepts and fully explains the OS source code.</p>"},{"location":"rationales/#os-requirements","title":"OS requirements","text":"<p>I started working on the project, which later became the RPi OS. The first thing I had to do was to determine what parts of kernel development I considered to be \"basic\", and what components I considered to be not so essential and can be skipped (at least in the beginning). In my understanding, each operating system has 2 fundamental goals:</p> <ol> <li>Run user processes in isolation.</li> <li>Provide each user process with a unified view of the machine hardware.</li> </ol> <p>To satisfy the first requirement, the RPi OS needs to have its own scheduler. If I want to implement a scheduler, I also have to handle timer interrupts. {xzl: not necessarily if you consider cooperative scheduling} The second requirement implies that the OS should support some drivers and provide system calls to expose them to user applications. Since this is for beginners, I don't want to work with complicated hardware, so the only drivers I care about are drivers that can write something to screen and read user input from a keyboard. Also, the OS needs to be able to load and execute user programs, so naturally it needs to support some sort of file system and be capable of understanding some sort of executable file format. It would be nice if the OS can support basic networking, but I don't want to focus on that in a text for beginners. So those are basically the things that I can identify as \"core concepts of any operating system\".</p> <p>Now let's take a look at the things that I want to ignore: 1. Performance I don't want to use any sophisticated algorithms in the OS. I am also going to disable all caches and other performance optimization techniques for simplicity. 1. Security It is true that the RPi OS has at least one security feature: virtual memory. Everything else can be safely ignored. 1. Multiprocessing and synchronization I am quite happy with my OS being executed on a single processor core. In particular, this allows me to get rid of a vast source of complexity - synchronization.  1. Support for multiple architectures and different types of devices More on this in the next section. 1. Millions of other features that any production-ready operating system supports</p>"},{"location":"rationales/#how-raspberry-pi-comes-into-play","title":"How Raspberry Pi comes into play","text":"<p>I already mentioned that I don't want the RPi OS to support multiple computer architectures or a lot of different devices. I felt even stronger about this after I dug into the Linux kernel driver model. It appears that even devices with similar purposes can largely vary in implementation details. This makes it very difficult to come up with simple abstractions around different driver types, and to reuse driver source code. To me, this seems like one of the primary sources of complexity in the Linux kernel, and I definitely want to avoid it in the RPi OS. Ok, but what kind of computer should I use then? I clearly don't want to test my bare metal programs using my working laptop, because I'm honestly not sure that it is going to survive. More importantly, I don't want people to buy an expensive laptop just to follow my OS development exercises (I don't think anybody would do this anyway). Emulators look like more or less a good choice, but I want to work with a real device because it gives me the feeling that I am doing something real rather than playing with bare metal programming. {xzl: very true}</p> <p>I ended up using the Raspberry Pi, in particular, the Raspberry Pi 3 Model B. Using this device looks like the ideal choice for a number of reasons:</p> <ol> <li>It costs something around $35. I think that should be an affordable price.</li> <li>This device is specially designed for learning. Its inner architecture is as simple as possible, and that perfectly suits my needs. {xzl: not necessarily. Rpi3 has many hardware quirks. But it's probably one of the few viable choices. More on this later}</li> <li>This device uses ARM v8 architecture. This is a simple RISC architecture, is very well adapted to OS authors' needs, and doesn't have so many legacy requirements as, for example, the popular x86 architecture. If you don't believe me, you can compare the amount of source code in the <code>/arch/arm64</code> and <code>/arch/x86</code> folders in the Linux kernel. {xzl: I concur. I want you to learn something new enough and used in real-world. This also explains why I rule out RISC-V}</li> </ol> <p>The OS is not compatible with the older versions of the Raspberry Pi, because neither of them support 64 bit ARM v8 architecture, though I think that support for all future devices should be trivial.</p>"},{"location":"rationales/#working-with-community","title":"Working with community","text":"<p>One major drawback of any technical book is that very soon after release each book becomes obsolete. Technology nowadays is evolving so fast that it is almost impossible for book writers to keep up with it. That's why I like the idea of an \"open source book\" - a book that is freely available on the internet and encourages its readers to participate in content creation and validation. If the book content is available on Github, it is very easy for any reader to fix and develop new code samples, update the book content, and participate in writing new chapters. I understand that right now the project is not perfect, and at the time of writing it is even not finished. But I still want to publish it now, because I hope that with the help of the community I will be able to not only complete the project faster but also to make it much better and much more useful than it was in the beginning. </p>"},{"location":"ssh-proxy-windows-caveat-jumphost/","title":"Ssh proxy windows caveat jumphost","text":""},{"location":"ssh-proxy-windows-caveat-jumphost/#windows-caveat-2-an-outdated-ssh-client-only-needed-if-you-run-into-this-bug","title":"Windows caveat 2: an outdated ssh client (only needed if you run into this bug)","text":"<p>Previously, some students reported VSCode has a bug that broke ssh with jumphost. You can refer to this. In a nutshell, manual download a newer win32 ssh to overwrite the one shipping with Win 10 (it's a good idea to save a back up). Window's security mechanism is in your way. Work around it. </p> <p>Make sure to download the OpenSSH-Win64 version (not Win32). 2. Double check the SSH version. See the screenshot below.</p> Turning off protection on ssh.exe (see link above) The newer ssh client manually installed <p>Now, you should be good to go with VSCode. </p> <p>Password-less login used to work fine, but suddenly breaks? A common cause is that VSCode updates automatically, overwriting the ssh client you manually installed. Solution: check your ssh version and use the one we suggested. </p>"},{"location":"ssh-proxy/","title":"Accessing the course server(s)","text":"<p>Last updated: 1/26/2024</p> <p>This document describes server resources and how to connect for development. </p> <p>Applicable to local machine: Windows, Linux, &amp; Mac</p> hardware specs OS granger1.cs.virginia.edu Dual Xeon 2630v4 Broadwell (10c20t), 20 cores Ubuntu 20.04 LTS granger2.cs.virginia.edu Dual Xeon 2630v4 Broadwell (10c20t), 20 cores Ubuntu 20.04 LTS <ul> <li> <p>VPN: If you are off the grounds, you must connect the UVA VPN first. These servers are behind the campus firewall. </p> </li> <li> <p>Login credentials: Use your CS account (NOT your UVA computing ID/password). </p> </li> <li> <p>Forgot password? https://www.cs.virginia.edu/wiki/doku.php?id=accounts_password</p> </li> <li> <p>For non-CS students without CS server accounts, email cshelpdesk@virginia.edu asking for creating an account, stating that you are in CS4414 and need access to granger1/2</p> </li> <li> <p>Server storage: home directories are shared, meaning that files modified on granger1 will be available on granger2, as well as other CS servers like portal. </p> </li> <li> <p>Load balance: As the semester begins, TAs may inform you which server you should use primarily. </p> </li> </ul>"},{"location":"ssh-proxy/#note-to-windows-machine-owners","title":"Note to Windows machine owners","text":"<p>Your machine has two separate SSH clients (with separate configurations).</p> <p>Windows native SSH client. It's a Windows program. Configuration: <code>c:\\users\\%username%\\.ssh\\</code></p> <p>When you type <code>ssh</code> from CMD or PowerShell, this is what you will invoke. </p> <p>This is also what VSCode's remote explorer will invoke. It will load the above configuration file. If VSCode SSH won't work, this SSH client needs to be configured (read on). </p> <p></p> <p>WSL's SSH client. It's a Linux program in the WSL virtual machine. Configuration: (inside WSL): <code>~/.ssh/</code></p> <p>It is only invoked if you type <code>ssh</code> within WSL environment. VSCode's remote explorer is not concerned with this SSH client. </p>"},{"location":"ssh-proxy/#step-1-terminal-over-ssh","title":"Step 1: Terminal over SSH","text":"<p>Reference: CS wiki https://www.cs.virginia.edu/wiki/doku.php?id=linux_ssh_access</p> <p>The picture below shows: from a local terminal (e.g. called \"minibox\"), connecting to a course server by simply typing <code>ssh granger1</code>. Read on for how to configure.</p> <p></p>"},{"location":"ssh-proxy/#11-use-key-based-authentication-in-lieu-of-password","title":"1.1. Use key-based authentication in lieu of password","text":"<p>In the example below: </p> <ul> <li>\"granger1\" is used. Replace it with \"granger2\" as needed.</li> <li>Windows owners: </li> <li>to configure Windows native ssh (needed by VSCode in p1), use configuration path <code>c:\\users\\%username%\\.ssh\\</code>; type commands from Windows CMD or PowerShell</li> <li>to configure WSL ssh (needed by future projects), use configuration path <code>~/.ssh</code>; type commands from the WSL shell.</li> <li>you are recommended to configure both. </li> </ul> <p>The pub key on your local machine is at <code>~/.ssh/id_rsa.pub</code>. Check out the file &amp; its content. If it does not exist, generate a pub key by running <code>ssh-keygen</code>. </p> <pre><code># on the local console -- Mac, Linux, or Windows (WSL/CMD/PowerShell)\n$ ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/xzl/.ssh/id_rsa):\n</code></pre> <p>Now, append your public key to granger1 (<code>~/.ssh/authorized_keys</code>). A quick way is by command <code>ssh-copy-id</code>. For instance: </p> <pre><code># copy the pubkey from your local machine to granger1\n$ ssh-copy-id xl6yq@granger1.cs.virginia.edu\n(... type in password ...)\n\n# next time, it should no longer ask for password\n$ ssh xl6yq@granger1.cs.virginia.edu\n</code></pre>"},{"location":"ssh-proxy/#troubleshooting-the-server-still-asks-for-password","title":"Troubleshooting: the server still asks for password?","text":"<p>Still use granger1 as an example. </p> <ul> <li>On granger1, check the content of ~/.ssh/authorized_keys. You should see your public key saved there. For instance, mine is: </li> </ul> <pre><code>$ cat ~/.ssh/authorized_keys\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCkkCZ2PO7GdX5CBL26zcIFz4XgMiHSQjaU32evuidvMXsC\nZExT9QHl3Ou00QfuagmfebugxB0aruGAsKmBxEBmlj0r1uAVCekYaIn8IPA5jynQnDRDdIABaZBWlsPx9jKo\nKQqLlKgdG4JziQOAr0HaUgr+oIXgRUq7V/W1OhV9SQVF+vcIy8vVwNdLBNdbw/GtU0oKb76yxfXOC/VZM7eZ\nxhovb/J450U5Op8tL/+Lg5x2sJKqR2juCFAicGbVNuXXazEDrXHgDQp+WQS8rYK4Zs95KqAsMfxvsFSbs8lf\nh0pIs+sozBNUt+1noJkcyLfxhzu0yGEsxMULHE/KdAst xl6yq@portal03                        \n</code></pre> <ul> <li>On granger1, check the permission of ~/.ssh. It should be: </li> </ul> <pre><code>$ ls -la ~ | grep .ssh\ndrwx------ \n</code></pre> <p>Check the permission of ~/.ssh/authorized_keys. It should be: </p> <pre><code>$ ls -l ~/.ssh/authorized_keys\n-rw------- \n</code></pre> <p>If none of the above works, you can put ssh in the verbose mode to see what's going on. From your local machine, type</p> <pre><code>ssh -vv granger1.cs.virginia.edu\n</code></pre> <p>Explanation: -vv tells ssh to dump its interactions with granger1 on negotiating keys. As a reference, my output is here. At the end of the output, you can see granger1 accepts my key offered from portal. </p> <p>Note to Windows Users: the native ssh-copy-id.exe (the one you invoke from PowerShell or CMD) was reported to show caveats. See here. Not sure if it fixed in newer Windows. If no luck, consider manual copy &amp; paste the key. </p>"},{"location":"ssh-proxy/#12-save-connection-info-in-ssh-config","title":"1.2. Save connection info in SSH config","text":"<p>Append the following to your ssh client configuration (<code>~/.ssh/config</code>). Replace USERNAME with your actual username: </p> <pre><code>Host granger1\n   User USERNAME\n   HostName granger1.cs.virginia.edu\n\nHost granger2\n   User USERNAME\n   HostName granger2.cs.virginia.edu   \n</code></pre> <p>With the configuration, you can type from your local machine: </p> <pre><code>$ ssh granger1\n# or \n$ ssh granger2\n</code></pre>"},{"location":"ssh-proxy/#step-2-remote-development-with-vscode","title":"Step 2: Remote development with VSCode","text":"<p>Below we use Windows as the local machine example. Linux/Mac should be similar (even fewer caveats)</p> <p>End results: being able to develop, compile, and do version control -- all from the VSCode IDE. </p> <p></p> <p>We will use VSCode's official Remote.SSH extension, which will connect to the course server using Windows native SSH. An official tutorial is here. </p> <p>To do so you install the \"Remote development\" package which will install the \"Remote.SSH\" extension for VSCode. </p> <p></p> <p>After installation, click \"Remote Explorer\" on the left bar. The extension will pick up your ssh config file (again that's <code>C:/Users/%USERNAME%/.ssh/config</code>) and present a list of hosts recognized. Click one to connect to it. The extension will copy a bunch of stuffs to the host and launch some daemon on the host. Then you are connected. </p>"},{"location":"ssh-proxy/#warning-3rd-party-vscode-extensions","title":"Warning - 3rd party VSCode extensions","text":"<p>When opening a large codebase on the server, these extensions may consume lots of resources and hang the server. This happened repeatedly before. </p> <p>If that happens, TAs have to manually kill your server processes. </p>"},{"location":"ssh-proxy/#windows-owners-ssh-keys","title":"Windows owners: ssh keys","text":"<p>The extension (Remote.SSH) will invoke Window's ssh client (<code>c:\\Windows\\System32\\OpenSSH\\ssh.exe</code>).The Window's ssh client expects its config file at <code>C:\\Users\\%USERNAME%\\.ssh\\config</code>. This is NOT the ssh client you run from WSL. </p> <p></p> <p>If you haven't generated your SSH keys so far, you can do so by launching a PowerShell console and run <code>ssh-keygen</code> there. </p> Launch PowerShell ssh-keygen in PowerShell Access WSL root <p>Or, you can you copy existing ssh keys and config (e.g. from WSL <code>~/.ssh/</code>) to the location mentioned above. Btw, the way to access WSL's root filesystem is to type <code>\\\\wsl$</code> in the explorer address bar. See the figure above. </p>"},{"location":"ssh-proxy/#launch-a-terminal","title":"Launch a terminal","text":"<p>After connection, click \"remote\" on the left bar to bring up a remote terminal, in which you can execute commands to build projects, etc. Make sure to click the \"+\" sign to create a new shell terminal. </p> <p></p>"},{"location":"ssh-proxy/#file-browsing-editing","title":"File browsing &amp; editing","text":"<p>Then you will specify a remote folder on the server to \"open\": </p> <p></p> <p>To browse &amp; edit files on the server, click \"explorer\" on the left bar</p> <p></p> <p>Click  \"source control\" on the left bar for a handy git interface. </p>"},{"location":"ssh-proxy/#copy-files-tofrom-the-server","title":"Copy files to/from the server","text":"<p>Just drag and drop the files between VSCode's file list and your local directory. </p>"},{"location":"ssh-proxy/#troubleshooting","title":"Troubleshooting","text":"<p>Things like Windows auto update may break VSCode's ssh configuration that worked previously. In this case, try deleting (or moving to other places) the <code>.vscode-server</code> folder on the course servers (under the <code>p1-kernel/</code> directory), close all remote connections, and close the local VSCode program. Then start from a clean slate. </p> <p>If things still break, seek help from the online discussion forum. Provide the following information: </p> <ul> <li>the error message of VSCode</li> <li>the PowerShell output when you try to connect to granger1 from the PowerShell command line. Have you tried granger2?</li> <li>any recent Windows/VSCode updates?</li> <li>any other relevant information </li> </ul>"},{"location":"archived/assignment%20weights%20-%20old/","title":"Assignment weights   old","text":""},{"location":"archived/assignment%20weights%20-%20old/#assignment-weights","title":"Assignment weights","text":"Exp Weights 00 Sharpen your tools 10 01 Helloworld from baremetal 10 02 Exception elevated 10 03 Heartbeats on 10 04a Process scheduler - cooperative 10 04b Process scheduler - preemptive 10 05 A world of two lands 20 06 Into virtual (6a:10; 6b:10) 20 <p>The weights are relative and may not necessarily add up to 100. </p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/","title":"Accessing the course server(s) --- archived","text":"<p>This document describes server resources and how to connect for development. </p> Projects hardware specs OS granger1.cs.virginia.edu p1-p4 Dual Xeon 2630v4 Broadwell (10c20t), 20 cores Ubuntu 20.04 LTS granger2.cs.virginia.edu p1-p4 Dual Xeon 2630v4 Broadwell (10c20t), 20 cores Ubuntu 20.04 LTS ~~labsrv06.cs.virginia.edu (out of service)~~ All but p2 Single Xeon Silver 4410 CPU (8c16t), 8 cores Ubuntu 20.04 LTS <p>These servers are behind the campus firewall. If you are off the grounds, you must connect the UVA VPN first. </p> <p>(Jan 2023): The above should be it! The following method of SSH jumphost is considered obsoleted. It is kept for archival.</p> <p>You need to first SSH to portal.cs.virginia.edu, and from there SSH over to the course servers, e.g. labsrv06. This is described here. </p> <p>WARNING: portal is managed by the UVA IT. You use your existing computing ID &amp; password. The course server is managed by cs4414 staff. Use the credentials that we share with you. </p> <p> Figure above: your local machine, the portal, and the server. Texts on the bottom: key files and their purpose. </p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#terminal-over-ssh","title":"Terminal over SSH","text":"<pre><code>$ ssh xl6yq@portal.cs.virginia.edu\n(type in password...)\nWarning: No xauth data; using fake authentication data for X11 forwarding.\nLast login: Sun Jan 24 16:48:29 2021 from c-71-62-166-85.hsd1.va.comcast.net\n********************************** **********************\nType \"module avail\" to see software available.\nSee: www.cs.virginia.edu/computing for more information.\n\n$ ssh xl6yq@granger1.cs.virginia.edu\n(type in password...)\nWelcome to Ubuntu 20.04 LTS (GNU/Linux 5.4.0-45-generic x86_64)\n</code></pre> <p>Connecting to the course servers can be automated. </p> <p></p> <p>The picture shows the final results: From a local terminal (e.g. my minibox), connecting to a course server by simply typing <code>ssh granger1</code>. Read on for how to configure.</p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#1-use-key-based-authentication-in-lieu-of-password","title":"1. Use key-based authentication in lieu of password","text":"<p>Applicable local environment: Linux, MacOS, &amp; Windows (WSL)</p> <p>The pub key on your local machine is at <code>~/.ssh/id_rsa.pub</code>. Check out the file &amp; its content. If it does not exist, generate a pub key by running <code>ssh-keygen</code>. </p> <pre><code># on the local console (Linux or WSL)\n$ ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/xzl/.ssh/id_rsa):\n</code></pre> <p>Now, append your public key to both portal and granger1 (<code>~/.ssh/authorized_keys</code>). </p> <p>Don't do this manually. Instead, do so by the command <code>ssh-copy-id</code>. For instance: </p> <pre><code># copy the pubkey from your local machine to portal\n$ ssh-copy-id xl6yq@portal.cs.virginia.edu\n(... type in password ...)\n\n# connect to \"portal\", it should no longer ask for password\n$ ssh xl6yq@portal.cs.virginia.edu\n\n# now we are on \"portal\". generate a new pair of public/private keys, which will be used between portal and granger1 \n$ ssh-keygen\n\n# copy the new public key from portal to granger1\n$ ssh-copy-id xl6yq@granger1.cs.virginia.edu\n(... type in password ...)\n\n# it should no longer ask for password\n$ ssh xl6yq@granger1.cs.virginia.edu\n</code></pre> <p>An alternative procedure (02/07/21) Credits Peiyi Yang, TA 2021. </p> <p>Started from scratch. First edited the ssh config file on the local computer saying to jump through portal when going to granger1. Then ran ssh-copy-id id@portal and entered the password to install the local's pubkey on portal. Then from local, ran ssh-copy-id id@granger1 and entered the password to install the local's pubkey on granger1.</p> <p>So there is only one key pair. The pubkey is copied to portal and then to granger1. </p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#troubleshooting-the-server-still-asks-for-password","title":"Troubleshooting: the server still asks for password?","text":"<p>Let's use granger1 as an example. </p> <ul> <li>On granger1, check the content of ~/.ssh/authorized_keys. You should see your public key saved there. For instance, mine is: </li> </ul> <pre><code>$ cat ~/.ssh/authorized_keys\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCkkCZ2PO7GdX5CBL26zcIFz4XgMiHSQjaU32evuidvMXsC\nZExT9QHl3Ou00QfuagmfebugxB0aruGAsKmBxEBmlj0r1uAVCekYaIn8IPA5jynQnDRDdIABaZBWlsPx9jKo\nKQqLlKgdG4JziQOAr0HaUgr+oIXgRUq7V/W1OhV9SQVF+vcIy8vVwNdLBNdbw/GtU0oKb76yxfXOC/VZM7eZ\nxhovb/J450U5Op8tL/+Lg5x2sJKqR2juCFAicGbVNuXXazEDrXHgDQp+WQS8rYK4Zs95KqAsMfxvsFSbs8lf\nh0pIs+sozBNUt+1noJkcyLfxhzu0yGEsxMULHE/KdAst xl6yq@portal03                        \n</code></pre> <p>\"xl6yq@portal03\" is the textual tag of the pubkey, indicating it is a pubkey generated on portal.cs</p> <ul> <li>On granger1, check the permission of ~/.ssh. It should be: </li> </ul> <pre><code>$ ls -la ~ | grep .ssh\ndrwx------ \n</code></pre> <p>Check the permission of ~/.ssh/authorized_keys. It should be: </p> <pre><code>$ ls -l ~/.ssh/authorized_keys\n-rw------- \n</code></pre> <p>If none of the above works, you can put ssh in the verbose mode to see what's going on. From <code>portal</code>, type</p> <pre><code>ssh -vv granger1.cs.virginia.edu\n</code></pre> <p>Explanation: -vv tells ssh to dump its interactions with granger1 on negotiating keys. As a reference, my output is here. At the end of the output, you can see granger1 accepts my key offered from portal. </p> <p>Can do password-less authentication between local/portal and between portal/granger[12], but are still required to enter password between local/granger? From your local machine, type</p> <pre><code>ssh -vv granger1.cs.virginia.edu\n</code></pre> <p>And compare line-by-line with the output to the reference output here. </p> <p>Note to Windows Users: if you try to invoke ssh-copy-id that comes with Windows (the one you can invoke in PowerShell, not the one in WSL), there may be some caveats. See here. I would say just invoke ssh-copy-id in WSL. </p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#2-save-connection-info-in-ssh-config","title":"2. Save connection info in SSH config","text":"<p>Append the following to your ssh client configuration (<code>~/.ssh/config</code>). Replace USERNAME with your actual username: </p> <pre><code>Host granger1\n   User USERNAME\n   HostName granger1.cs.virginia.edu\n   ProxyJump USERNAME@portal.cs.virginia.edu:22\n</code></pre> <p>With the configuration, your local ssh client knows that when connecting  to host <code>granger1</code>, use <code>portal</code> as the jump proxy. So you can directly connect to <code>granger1</code> from your local machine: </p> <pre><code>$ ssh granger1\n</code></pre>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#aside-a-one-liner-for-connecting-to-course-servers","title":"Aside: a one-liner for connecting to course servers","text":"<pre><code>$ ssh -l USERNAME granger1.cs.virginia.edu -J portal.cs.virginia.edu\n</code></pre> <p>The -J option is available with your local ssh client OpenSSH &gt;= 7.3p1. See here for more details. For instance, my version: </p> <pre><code>$ ssh -V\nOpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n  7 Dec 2017\n</code></pre>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#remote-development-with-vscode","title":"Remote development with VSCode","text":"<p>Many students may prefer VSCode. Here is how to make it work for our kernel hacking. </p> <p>End results: being able to develop, compile, and do version control from VSCode. See an example screenshot below. </p> <p></p> <p>So we will use VSCode's official Remote.SSH extension. I do not recommend 3rd party extensions, e.g. sftp. </p> <p>An official tutorial is here. </p> <p>tl;dr: VSCode will connect to the course server (Linux) using SSH under the hood. To do so you install the \"Remote development\" package which will install the \"Remote.SSH\" extension for VSCode. </p> <p></p> <p>Screenshot from Peiyi Yang (py5yy@). Her VSCode color scheme is different from mine. </p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#windows-caveat-1-ssh-keys","title":"Windows caveat 1: ssh keys","text":"<p>The extension (Remote.SSH) will invoke Window's ssh client (<code>c:\\Windows\\System32\\OpenSSH\\ssh.exe</code>).The Window's ssh client expects its config file at <code>C:\\Users\\%USERNAME%\\.ssh\\config</code>. This is NOT the ssh client you run from WSL. </p> <p></p> <p>If you haven't generated your SSH keys so far, you can do so by launching a PowerShell console and run <code>ssh-keygen</code> there. </p> Launch PowerShell ssh-keygen in PowerShell Access WSL root <p>Or, you can you copy existing ssh keys and config (e.g. from WSL <code>~/.ssh/</code>) to the location mentioned above. Btw, the way to access WSL's root filesystem is to type <code>\\\\wsl$</code> in the explorer address bar. See the figure above. </p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#windows-caveat-2-an-outdated-ssh-client","title":"Windows caveat 2: an outdated ssh client","text":"<p>The current VSCode has a bug that breaks ssh with jumphost. You have to manually fix it by following this. In a nutshell, manual download a newer win32 ssh to overwrite the one shipping with Win 10 (it's a good idea to save a back up). Window's security mechanism is in your way. Work around it. </p> <p>Note: 1. Make sure to download the OpenSSH-Win64 version (not Win32). 2. Double check the SSH version. See the screenshot below.</p> Turning off protection on ssh.exe (see link above) The newer ssh client manually installed <p>Now, you should be good to go with VSCode. </p> <p>Make sure you have the Remote.SSH extension installed. Click \"Remote Explorer\" on the left bar. The extension will pick up your ssh config file (again that's <code>C:/Users/%USERNAME%/.ssh/config</code>) and present a list of hosts recognized. Click one to connect to it. The extension will copy a bunch of stuffs to the host and launch some daemon on the host. Then you are connected. </p> <p>Password-less login used to work fine, but suddenly breaks? A common cause is that VSCode updates automatically, overwriting the ssh client you manually installed. Solution: check your ssh version and use the one we suggested. </p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#launch-a-terminal","title":"Launch a terminal","text":"<p>After connection, click \"remote\" on the left bar to bring up a remote terminal, in which you can execute commands to build projects, etc. Make sure to click the \"+\" sign to create a new shell terminal. </p> <p></p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#file-browsing-editing","title":"File browsing &amp; editing","text":"<p>Then you will specify a remote folder on the server to \"open\": </p> <p></p> <p>To browse &amp; edit files on the server, click \"explorer\" on the left bar</p> <p></p> <p>Click  \"source control\" on the left bar for a handy git interface. </p>"},{"location":"archived/ssh-proxy%20-%20jumphost%20old/#troubleshooting","title":"Troubleshooting","text":"<p>Windows auto update may break VSCode's ssh configuration that worked previously. In this case, deleting (or moving to other places) the .vscode-server folder on granger and portal may solved the problem. </p> <p>If things break, report: </p> <ul> <li>the error message of VSCode</li> <li>the PowerShell output when you try to connect to granger1 from the PowerShell command line</li> <li>the PowerShell output when you try to connect to cs portal from the PowerShell command line</li> <li>any recent Windows/VSCode updates</li> </ul>"},{"location":"exp0/rpi-os-full/","title":"0: Sharpen your tools (PRO VERSION)","text":"<p>THIS DOCUMENT CONTAINS DESCRIPTION: BOTH QEMU AND RPI3 (ACTUAL HARDARE); ALSO DEVELOP ON YOUR LOCAL MACHINES</p> <p>READING TIME: 30 MIN</p> <p>Get the code: </p> <pre><code>git clone https://github.com/fxlin/p1-kernel\n</code></pre>"},{"location":"exp0/rpi-os-full/#terms","title":"Terms","text":"<ul> <li>rpi3: raspberry pi 3, a credit card size computer</li> <li>baremetal: write &amp; run code directly on hardware (rpi3, real or emulated)</li> <li>kernel: the baremetal code you will develop to run on (real/emulated) hardware</li> <li>kernel binary/image: a single file, which contains the compiled kernel program and data</li> </ul>"},{"location":"exp0/rpi-os-full/#dev-platform-where-you-develop-kernel-code","title":"Dev platform (where you develop kernel code)","text":""},{"location":"exp0/rpi-os-full/#route-1-run-kernel-atop-qemu-emulator-recommended","title":"Route 1: run kernel atop QEMU (emulator, recommended)","text":"<p>Note: </p> <ul> <li> <p>Recommended configurations are underscored.</p> </li> <li> <p>How to connect to CS server(s): see here. </p> </li> <li> <p>VSCode: optional. It's available on Win/OSX/Linux. It can be used for any configuration below.</p> </li> </ul> Your local machine runs: If develop remotely on CS servers (recommended) If develop on local machine (only if you know what you are doing) Windows WSL for SSH shell WSL for toolchain. gdbserver could be tricky. Linux SSH shell Native toolchain + console Mac Terminal for SSH shell HomeBrew"},{"location":"exp0/rpi-os-full/#route-2-run-kernel-atop-rpi3-real-hardware","title":"Route 2: run kernel atop Rpi3 (real hardware)","text":"<p>Note: </p> <ul> <li> <p>Recommended configurations are underscored.</p> </li> <li> <p>How to connect to CS server(s): see here. </p> </li> <li> <p>VSCode: optional. It's available on Win/OSX/Linux. It can be used for any configuration below.</p> </li> </ul> Your local machine runs: Develop remotely on CS servers Develop locally Windows WSL for SSH shell; then download (scp) kernel binary to local WSL for toolchain Linux SSH shell; then download (scp) kernel binary to local Native toolchain + console Mac Terminal for SSH shell HomeBrew (untested)"},{"location":"exp0/rpi-os-full/#toolchain","title":"Toolchain","text":"<p>These are compiler, linker, etc. for us to generate the kernel code. Use the one provided by Ubuntu. </p> <p>Note: Below is necessary only when you develop kernel code on your local machine. The server already has the toolchain installed</p> <pre><code>$ sudo apt install gcc-aarch64-linux-gnu \n$ sudo apt install gdb-multiarch\n\n$ aarch64-linux-gnu-gcc --version\naarch64-linux-gnu-gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n</code></pre>"},{"location":"exp0/rpi-os-full/#test-platform","title":"Test Platform","text":"<p>This is where you run the kernel code. </p>"},{"location":"exp0/rpi-os-full/#route-1-qemu-emulator-recommended","title":"Route 1: QEMU (emulator, recommended)","text":""},{"location":"exp0/rpi-os-full/#compile-qemu-from-source","title":"Compile QEMU from source","text":"<p>This is required no matter you develop on local machines or on the server. </p> <p>Grab the QEMU source.  Our QEMU is based on upstream v4.2 with custom aarch64 debugging support. </p> <pre><code>git clone https://github.com/fxlin/qemu-cs4414.git qemu\ncd qemu\n./configure --target-list=aarch64-softmmu -enable-sdl    # -sdl builds in UI support over X \nmake -j`nproc`\nexport PATH=\"$(pwd)/aarch64-softmmu:${PATH}\"\n</code></pre> <p>If successful, this will result in QEMU executables in ./aarch64-softmmu/. The last line above adds the path to our search path. </p> <p>If you encounter compilation errors (e.g. unmet dependencies), make sure you run all <code>apt get</code> commands above. </p> <p>Now try QEMU &amp; check its version. The supported machines should include Rpi3</p> <pre><code>$ qemu-system-aarch64  --version                 \nQEMU emulator version 5.0.50 (v5.0.0-1247-gaf6f75d03f-dirty)                   \nCopyright (c) 2003-2020 Fabrice Bellard and the QEMU Project developers        \npatched for cs4414/6456 aarch64 kernel hacking    \n\n$ qemu-system-aarch64 -M help|grep rasp\nraspi2               Raspberry Pi 2B\nraspi3               Raspberry Pi 3B\n</code></pre>"},{"location":"exp0/rpi-os-full/#test-the-compilation","title":"Test the compilation","text":"<p>Test QEMU with Rpi3 baremetal code (NOTE: this repo is for validating your toolchain &amp; QEMU build; it is NOT our course project)</p> <pre><code>git clone https://github.com/fxlin/raspi3-tutorial.git\ncd raspi3-tutorial\ngit checkout b026449\ncd 05_uart0\nmake \nqemu-system-aarch64 -M raspi3 -kernel kernel8.img -serial stdio\n</code></pre> <p>If everything works fine, you should see QMEU print out: </p> <pre><code>My serial number is: 0000000000000000\n</code></pre> <p>Note: the test program runs an infinite loop which will cause high CPU usage on your host machine. Kill the test program timely. </p> <p>On Linux (e.g. connecting to the course server from your local machine): </p> <p>On Windows (local WSL, NOT using the course server). The emulated display requires the QEMU to be built with graphics support (e.g. a WSL or native Windows build)</p> <p></p> <p>Move to the QEMU cheatsheet. </p>"},{"location":"exp0/rpi-os-full/#route-2-rpi3-real-hardware","title":"Route 2: Rpi3 (real hardware)","text":""},{"location":"exp0/rpi-os-full/#check-list","title":"Check list","text":"Required: An Rpi3 board (Model B or B+) link Required: A USB-serial cable Amazon. Connection inside the dongle: black-GND; green-TXD; white-RXD; red-VCC. <ul> <li> <p>Required: A micro SD card. The capacity can be humble (e.g. 4GB). The speed does not matter much. The one I used was $6.  Rpi's official page about uSD</p> </li> <li> <p>Required: SD card reader. To be plugged in your PC for loading kernel to the micro SD card. A cheap one can be $7 on Amazon</p> </li> <li> <p>Recommended: A micro USB cable for powering Rpi3. </p> </li> </ul>"},{"location":"exp0/rpi-os-full/#prep-raspberry-pi-3-model-b","title":"Prep Raspberry Pi 3 Model B","text":"<p>Older versions of Raspberry Pi are not going to work with this tutorial because all lessons are designed to use a 64-bit processor that supports ARMv8 architecture, and such processor is only available in the Raspberry Pi 3. Newer versions, including Raspberry Pi 3 Model B+ should work fine. </p>"},{"location":"exp0/rpi-os-full/#load-raspbian-os-to-the-sd-card","title":"Load Raspbian OS to the SD card","text":"<p>Raspbian is a Debian-based Linux distro. It's the official OS for Rpi3. Why we need Raspbian? 1. to test USB to TTL cable connectivity initially. 2. after installing Raspbian, the SD card is formatted in the right way. All the proprietary binary blobs needed to boot Rpi3 are also in place. </p> <p>Load the SD card with Raspbian OS. Follow the official instructions. </p>"},{"location":"exp0/rpi-os-full/#plug-in-the-serial-cable","title":"Plug in the serial cable","text":"<pre><code>Rpi3 &lt;-- a USB-serial cable ---&gt; PC (running a temrinal emulator) \n</code></pre> <p>After you get a serial cable, you need to test your connection. If you never did this before I recommend you to follow this guide It describes the process of connecting your Raspberry PI via a serial cable in great details. Basically, you run Raspberry's official OS to ensure the hardware setup is fine. </p> <p></p>"},{"location":"exp0/rpi-os-full/#configure-the-serial-emulator-on-your-pc","title":"Configure the serial emulator on your PC","text":"<p>Linux users: minicom recommended.</p> <pre><code>sudo minicom -b 115200 -o -D /dev/ttyUSB0 -C /tmp/minicom.log\n</code></pre> <p>Note: your PC may give different names to the USB-serial dongle, e.g. /dev/ttyUSB1. Find it out by looking at <code>dmesg</code> output. </p> <p>Windows users (including WSL): PuTTY recommended. A sample configuration below. </p> <p></p> <p>Note: your PC may give different names to the USB-serial dongle, e.g. COM4. Find it out by looking at Windows Device Manager. </p>"},{"location":"exp0/rpi-os-full/#powering-up-rpi3","title":"Powering up RPi3","text":"<p>We recommend you power Rpi3 through its micro USB port. Perhaps use a flip switch on the other side of the USB power for power cycling Rpi3. The guide above also describes how to power your Raspberry Pi using a serial cable. RPi OS works fine with such kind of setup, however, in this case, you need to run your terminal emulator right after you plug in the cable. Check this issue for details.</p> <pre><code>Rpi3 &lt;-- micro USB ---&gt; PC\nRpi3 &lt;-- micro USB ---&gt; Wall charger\n</code></pre> <p>Power cycling Rpi3, you should see Linux kernel console output on PC terminal. </p>"},{"location":"exp0/rpi-os-full/#an-example-setup","title":"An example setup","text":"<p>This is my desktop when I hack with the Rpi3 kernel. </p> <p></p>"},{"location":"exp0/rpi-os-full/#test-your-dev-workflow","title":"Test your dev workflow","text":""},{"location":"exp0/rpi-os-full/#background-whats-on-sd-card","title":"Background: what's on SD card?","text":"<p>On powering up, Rpi3 looks for the following files on <code>boot</code> partition of the SD card. </p> <ul> <li>bootcode.bin: the proprietary bootloader for enabling SDRAM. This comes with Raspbian. </li> <li>start.elf: the proprietary firmware loaded by the bootloader. Using the updated Raspbian OS. This comes with Raspbian. </li> <li>fixup.dat: needed to use 1GB of memory. This comes with Raspbian. </li> <li>config.txt: to be parsed by start.elf and decide boot behavior. It offers a great deal of options which is pretty cool. A default one comes with Raspbian. This file is to be customized by us </li> <li>kernel8.img: our kernel. </li> </ul> <p>Summary: we need to change config.txt (once) and kernel8.img (every time we re-compile kernel) on the SD card. </p>"},{"location":"exp0/rpi-os-full/#update-configtxt","title":"Update config.txt","text":"<p>Plug the SD card to PC via the card reader. Open config.txt which is on the boot partition. The following two lines are crucial. Add them to config.txt. </p> <pre><code>arm_64bit=1\nenable_uart=1\n</code></pre> <p>Note: multiple online tutorials advise options like <code>kernel_old=1</code> or <code>arm_control</code>. You do NOT need those. With our options in config.txt above, Rpi3 will load the kernel named kernel8.img to 0x80000. Check the official doc for config.txt above. Look for <code>kernel_address</code>. </p> <p>Ref: the official doc for config.txt. </p>"},{"location":"exp0/rpi-os-full/#build-load-sample-baremetal-program","title":"Build &amp; load sample baremetal program","text":"<p>... to ensure our toolchain works fine. </p> <pre><code>git clone git@github.com:fxlin/raspi3-tutorial.git\ncd raspi3-tutorial\ngit checkout b026449\ncd 05_uart0\nmake \n</code></pre> <p>Note: the repo above (raspi3-tutorial.git) is NOT our project repo. It's someone's code for testing rpi3 hardware. We are just using for testing ONLY. </p> <p>Copy kernel8.img to the SD card. Eject the SD card from PC. Plug the SD to Rpi3. Make sure the serial connection is good and terminal emulator on your PC is ready. Power cycle Rpi3. You should see something like: </p> <p></p> <p>(Your serial number may be different)</p> <p>Viola! You just built your first baremetal program for Rpi3! </p>"},{"location":"exp0/rpi-os/","title":"0: Sharpen your tools","text":"<p>READING TIME: 30 MIN</p> <p>Get the code: </p> <pre><code>git clone https://github.com/fxlin/p1-kernel\n</code></pre>"},{"location":"exp0/rpi-os/#terms","title":"Terms","text":"<ul> <li>rpi3: raspberry pi 3, a credit card size computer</li> <li>baremetal: write &amp; run code directly on hardware (rpi3, real or emulated)</li> <li>kernel: the baremetal code you will develop to run on (real/emulated) hardware</li> <li>kernel binary/image: a single file, which contains the compiled kernel program and data</li> </ul> <p>Note: The document describes the recommended route: using QEMU to emulate rpi3; develop code on the CS servers. If you take the \"pro\" route: work with the actual hardware and/or develop on your local machine, see this.</p>"},{"location":"exp0/rpi-os/#dev-platform-where-you-develop-kernel-code","title":"Dev platform (where you develop kernel code)","text":"<p>Note: </p> <ul> <li> <p>How to connect to CS server(s): see here. </p> </li> <li> <p>VSCode: optional. It's available on Win/OSX/Linux. It can be used for any configuration below.</p> </li> </ul> Your local machine runs: Use local terminals Windows WSL for SSH shell Linux SSH shell Mac Terminal for SSH shell"},{"location":"exp0/rpi-os/#toolchain","title":"Toolchain","text":"<p>These are compiler, linker, etc. for us to generate the kernel code. Use the one provided by Ubuntu. </p> <p>To verify: </p> <pre><code>$ aarch64-linux-gnu-gcc --version\naarch64-linux-gnu-gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n</code></pre>"},{"location":"exp0/rpi-os/#test-platform","title":"Test Platform","text":"<p>This is where you run the kernel code. </p>"},{"location":"exp0/rpi-os/#run-the-qemu-executable","title":"Run the QEMU executable","text":"<p>Our QEMU is based on upstream v4.2 with custom aarch64 debugging support.  To add it to your execution path: </p> <pre><code>export PATH=\"/cs4414-shared/qemu/aarch64-softmmu/:${PATH}\"\n</code></pre> <p>This command has to be run for each new login.  To automate this process, you can append it to the end of your bash profile (\"~/.bashrc\").</p> <p>Alternatively,  you can load pre-defined commands (just make sure you understand env-qemu.sh). </p> <pre><code>cd p1-kernel &amp;&amp; source env-qemu.sh\n</code></pre> <p>Now try QEMU &amp; check its version. The supported machines should include Rpi3</p> <pre><code>$ qemu-system-aarch64  --version                 \nQEMU emulator version 5.0.50 (v5.0.0-1247-gaf6f75d03f-dirty)                   \nCopyright (c) 2003-2020 Fabrice Bellard and the QEMU Project developers        \npatched for cs4414/6456 aarch64 kernel hacking    \n\n$ qemu-system-aarch64 -M help|grep rasp\nraspi2               Raspberry Pi 2B\nraspi3               Raspberry Pi 3B\n</code></pre>"},{"location":"exp0/rpi-os/#test-qemu","title":"Test QEMU","text":"<p>Test QEMU with Rpi3 baremetal code (NOTE: this repo is for validating your toolchain &amp; QEMU build; it is NOT our course project)</p> <pre><code>git clone https://github.com/fxlin/raspi3-tutorial.git\ncd raspi3-tutorial\ngit checkout b026449\ncd 05_uart0\nmake \nqemu-system-aarch64 -M raspi3 -kernel kernel8.img -serial stdio\n</code></pre> <p>If everything works fine, you should see QMEU print out: </p> <pre><code>My serial number is: 0000000000000000\n</code></pre> <p>Note: the test program runs an infinite loop which will cause high CPU usage on your host machine. Kill the test program timely. </p> <p>On Linux (e.g. connecting to the course server from your local machine): </p> <p>To use QEMU with use, make sure to read the QEMU cheatsheet. </p>"},{"location":"exp1/rpi-os/","title":"1: Baremetal HelloWorld","text":"<p>READING TIME:  40 MIN</p>"},{"location":"exp1/rpi-os/#objectives","title":"Objectives","text":"<p>We will build: a minimal, baremetal program that can print \"Hello world\" via Rpi3's UART. </p> <p>Students will experience: </p> <ol> <li> <p>The C project structure</p> </li> <li> <p>The use of cross-compilation toolchain</p> </li> <li> <p>arm64 assembly (lightly)</p> </li> <li> <p>Basic knowledge on Rpi3 and its UART hardware</p> </li> </ol>"},{"location":"exp1/rpi-os/#get-the-code","title":"Get the code","text":"<p>Code location: p1-kernel/src/exp1</p> <p>Please: do a <code>git pull</code> even if you have cloned the p1-kenel repo previously, in case of upstream updates. </p> <p>Load pre-defined commands: \"cd p1-kernel &amp;&amp; source env-qemu.sh\". Make sure you read env-qemu.sh.</p>"},{"location":"exp1/rpi-os/#roadmap","title":"Roadmap","text":"<p>Create a Makefile project. Add minimum code to boot the platform. Initialize the UART hardware. Send characters to the UART registers. </p>"},{"location":"exp1/rpi-os/#terms","title":"Terms","text":"<ol> <li> <p>Strictly speaking, this baremetal program is not a \"kernel\". We nevertheless call it so for ease of explanation. </p> </li> <li> <p>\"QEMU\" means the Rpi3 platform as emulated by QEMU (route 1). \"Raspberry Pi\" means the actual Rpi3 hardware (route 2). We will explain details where the real hardware behaves differently from QEMU. </p> </li> </ol>"},{"location":"exp1/rpi-os/#code-walkthrough","title":"Code walkthrough","text":"<ol> <li><code>Makefile.qemu</code>: We will use the GNU Makefile to build the kernel. This file contains detailed comments. A refresher of Makefile: this article. </li> <li><code>src</code>: This folder contains all of the source code.</li> <li><code>include</code>: All of the header files are placed here. </li> </ol>"},{"location":"exp1/rpi-os/#the-linker-script-srclinker-qemuld","title":"The linker script (src/linker-qemu.ld)","text":"<p>A linker script describes how the sections in the input object files (<code>_c.o</code> and <code>_s.o</code>) should be mapped into the output file (<code>.elf</code>); it also controls the addresses of all program symbols (e.g. functions and variables). More information can be found here. Now let's take a look at the linker script:</p> <pre><code>SECTIONS\n{\n    .text.boot : { *(.text.boot) }\n    .text :  { *(.text) }\n    .rodata : { *(.rodata) }\n    .data : { *(.data) }\n    . = ALIGN(0x8);\n    bss_begin = .;\n    .bss : { *(.bss*) } \n    bss_end = .;\n}\n</code></pre> <p>After startup, the Rpi3 GPU loads <code>kernel8.img</code> into memory 0x0 and starts execution from the beginning of the file. That's why the <code>.text.boot</code> section must come first; we are going to put the kernel startup code inside this section. QEMU behaves differently: it loads the kernel image at 0x80000. </p> <p>Q: How to tweak the linker script to update the start address?</p> <p>The <code>.text</code>, <code>.rodata</code>, and <code>.data</code> sections contain kernel instructions, read-only data, and global data with init values. The <code>.bss</code> section contains data that should be initialized to 0. By putting such data in a separate section, the compiler can save some space in the ELF binary\u2013\u2013only the section size is stored in the ELF header, but the section content is omitted. </p> <p>After booting up, our kernel initializes the <code>.bss</code> section to 0; that's why we need to record the start and end of the section (hence the <code>bss_begin</code> and <code>bss_end</code> symbols) and align the section so that it starts at an address that is a multiple of 8. This eases kernel programming because the <code>str</code> instruction can be used only with 8-byte-aligned addresses.</p>"},{"location":"exp1/rpi-os/#kernel-startup","title":"Kernel startup","text":""},{"location":"exp1/rpi-os/#booting-the-kernel","title":"Booting the kernel","text":"<p>boot.S (src/boot.S) contains the kernel startup code. It has detailed comments. </p> <p>Q: It may make more sense to put core 1-3 in deep sleep using <code>wfi</code>. How? </p>"},{"location":"exp1/rpi-os/#kernel-memory-layout","title":"Kernel memory layout","text":"<p>If the current processor ID is 0, then execution branches to the <code>master</code> function:</p> <p>After cleaning the <code>.bss</code> section, the kernel initializes the stack pointer and passes execution to the <code>kernel_main</code> function. The Rpi3 loads the kernel at address 0 (QEMU loads at 0x80000); that's why the initial stack pointer can be set to any location high enough so that stack will not override the kernel image when it grows sufficiently large. <code>LOW_MEMORY</code> is defined in mm.h and is equal to 4MB. As our kernel's stack won't grow very large and the image itself is tiny, 4MB is more than enough for us. </p> <p></p> <p>Aside: Some ARM64 instructions used </p> <p>For those of you who are not familiar with ARM assembler syntax, let me quickly summarize the instructions that we have used:</p> <ul> <li>mrs Load value from a system register to one of the general purpose registers (x0\u2013x30)</li> <li>and Perform the logical AND operation. We use this command to strip the last byte from the value we obtain from the <code>mpidr_el1</code> register.</li> <li>cbz Compare the result of the previously executed operation to 0 and jump (or <code>branch</code> in ARM terminology) to the provided label if the comparison yields true.</li> <li>b Perform an unconditional branch to some label.</li> <li>adr Load a label's relative address into the target register. In this case, we want pointers to the start and end of the <code>.bss</code> region.</li> <li>sub Subtract values from two registers.</li> <li>bl \"Branch with a link\": perform an unconditional branch and store the return address in x30 (the link register). When the subroutine is finished, use the <code>ret</code> instruction to jump back to the return address.</li> <li>mov Move a value between registers or from a constant to a register.</li> </ul> <p>Our cheat sheet summarizes common ARM64 instructions. </p> <p>For official documentation, here is the ARMv8-A developer's guide. It's a good resource if the ARM ISA is unfamiliar to you. This page specifically outlines the register usage convention in the ABI.</p>"},{"location":"exp1/rpi-os/#the-kernel_main-function","title":"The <code>kernel_main</code> function","text":"<p>We have seen that the boot code eventually passes control to the <code>kernel_main</code> function. (VSCode: Ctrl-t then type \"kernel_main\")</p> <pre><code>#include \"mini_uart.h\"\n\nvoid kernel_main(void)\n{\n    uart_init();\n    uart_send_string(\"Hello, world!\\r\\n\");\n\n    while (1) {\n        uart_send(uart_recv());\n    }\n}\n</code></pre> <p>This function is one of the simplest in the kernel. It works with the <code>Mini UART</code> device to print to screen and read user input. The kernel just prints <code>Hello, world!</code> and then enters an infinite loop that reads characters from the user and sends them back to the screen.</p>"},{"location":"exp1/rpi-os/#a-bit-about-the-rpi3-hardware","title":"A bit about the Rpi3 hardware","text":"<p>The Rpi3 board is based on the BCM2837 SoC by Broadcom. The SoC manual is here. The SoC is not friendly for OS hackers: Broadcom poorly documents it and the hardware has many quirks. </p> <p>Despite so, the community figured out most of the SoC details over years because Rpi3's popularity. It's not our goal to dive in the SoC. Rather, our philosophy is to deal BCM2837-specific details as few as possible -- just enough to get our kernel working. We will spend more efforts on explaining generic hardware such as ARM64 cores, generic timers, irq controllers, etc. </p> <p>Rpi4 seems more friendly to kernel hackers. </p>"},{"location":"exp1/rpi-os/#memory-mapped-io","title":"Memory-mapped IO","text":"<p>On ARM-based SoCs, access to all devices is performed via memory-mapped registers. The Rpi3 SoC reserves physical memory address <code>0x3F000000</code> for IO devices. To configure a particular device, software reads/writes device registers. A device register is just a 32-bit region of memory. The meaning of each bit in each IO register is described in the SoC manual. </p> <p>The term \"device\" is heavily overloaded in many tech docs. Sometimes it means a board, e.g. \"an Rpi3 device\"; sometimes it means an IO peripheral, e.g. \"UART device\". We will be explicit. </p>"},{"location":"exp1/rpi-os/#uart","title":"UART","text":"<p>UART is a simple character device allowing software to send out text characters to a different machine. If you do not care about performance, UART requires very minimum software code. Therefore, it is often the first few IO devices to bring up when we build system software for a new machine. Only with UART meaning debugging is possible. (JTAG is another option which however requires more complex setup).</p> <p>In the simplest form, software writes ascii values to UART registers. The UART device converts written values to a sequence of high and low voltages on wire. This sequence is transmitted to your via the <code>TTL-to-serial cable</code> and is interpreted by your terminal emulator (e.g. PuTTY on Windows). </p> <p>Rpi3 has the two UART devices. Oddly enough, they are different. </p> Name Type Comments UART0 PL011 Secondary, intended as Bluetooth connector UART1 mini UART Primary, intended as debug console <p>UART1/Mini UART: easier to program; limited performance/functionalities. That's fine for our goal. For specification of the Mini UART registers: see page 8 of the SoC manual. </p> <p>UART0/PL011: richer functions; higher speed. Yet one needs to configure the board clock by talking to the GPU firmware. We won't do that. see Example code if you are interested. </p> <p>Both UARTs can be mapped to the same physical pins by setting the GPFSEL1 register. See the GPIO function diagram below. </p> <p>That's enough to know about Rpi UARTs. More:  official web page. </p>"},{"location":"exp1/rpi-os/#gpio","title":"GPIO","text":"<p>Another IO device is GPIO General-purpose input/output. GPIO provides a bunch of registers. Each bit in such a register corresponds to a pin on the Rpi3 board. By writing 1 or 0 to register bits, software can control the output voltage on the pins, e.g. for turning on/off LEDs connected to such pins. Reading is done in a similar fashion. The picture below shows GPIO pin headers populated on Rpi3. (Note: the picture shows Rpi2, which has the same pinout as Rpi3)</p> <p></p> <p>An SoC often has limited number of pins. Software can control the use of these pins, e.g. for GPIO or for UART. Software does so by writing to specific memory-mapped registers. </p> <p>The GPIO can be used to configure the behavior of different GPIO pins. For example, to be able to use the Mini UART, we need to activate pins 14 and 15 and set them up to use this device. The image below illustrates how numbers are assigned to the GPIO pins:</p> <p></p>"},{"location":"exp1/rpi-os/#walkthrough-the-uart-code","title":"Walkthrough: the UART code","text":"<p>The following init code configures pin 14 &amp; 15 as UART in/out, sets up UART clock and its modes, etc. </p> <p>Much of the UART init code is irrelevant to QEMU. Since QEMU \"emulates\" the UARTs, it can dump whatever our kernel writes to the emulated UART registers to stdio. Example: <code>qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio</code></p> <p>The first -serial means UART0 which we do not touch; the second -serial means we direct UART1 to stdio. </p> <pre><code>void uart_init ( void )\n{\n    unsigned int selector;\n\n    selector = get32(GPFSEL1);\n    selector &amp;= ~(7&lt;&lt;12);                   // clean gpio14\n    selector |= 2&lt;&lt;12;                      // set alt5 for gpio14\n    selector &amp;= ~(7&lt;&lt;15);                   // clean gpio15\n    selector |= 2&lt;&lt;15;                      // set alt5 for gpio 15\n    put32(GPFSEL1,selector);\n\n    put32(GPPUD,0);\n    delay(150);\n    put32(GPPUDCLK0,(1&lt;&lt;14)|(1&lt;&lt;15));\n    delay(150);\n    put32(GPPUDCLK0,0);\n\n    put32(AUX_ENABLES,1);                   //Enable mini uart (this also enables access to it registers)\n    put32(AUX_MU_CNTL_REG,0);               //Disable auto flow control and disable receiver and transmitter (for now)\n    put32(AUX_MU_IER_REG,0);                //Disable receive and transmit interrupts\n    put32(AUX_MU_LCR_REG,3);                //Enable 8 bit mode\n    put32(AUX_MU_MCR_REG,0);                //Set RTS line to be always high\n    put32(AUX_MU_BAUD_REG,270);             //Set baud rate to 115200\n\n    put32(AUX_MU_CNTL_REG,3);               //Finally, enable transmitter and receiver\n}\n</code></pre> <p>Here, we use the two functions <code>put32</code> and <code>get32</code>. Those functions are very simple -- read and write some data to and from a 32-bit register. You can take a look at how they are implemented in utils.S. <code>uart_init</code> is one of the most complex and important functions in this lesson, and we will continue to examine it in the next three sections.</p>"},{"location":"exp1/rpi-os/#init-gpio-alternative-function-selection","title":"Init: GPIO alternative function selection","text":"<p>First, we need to activate the GPIO pins. Most of the pins can be used with different IO devices. So before using a particular pin, we need to select the pin's alternative function,  a number from 0 to 5 that can be set for each pin and configures which IO device is virtually \"connected\" to the pin. </p> <p>See the list of all available GPIO alternative functions in the image below (taken from page 102 of the SoC manual)</p> <p></p> <p>Here you can see that pins 14 and 15 have the TXD1 and RXD1 alternative functions available. This means that if we select alternative function number 5 for pins 14 and 15, they will be used as a Mini UART Transmit Data pin and Mini UART Receive Data pin, respectively. The <code>GPFSEL1</code> register is used to control alternative functions for pins 10-19. The meaning of all the bits in those registers is shown in the following table (page 92 of the SoC manual):</p> <p></p> <p>So now you know everything you need to understand the following lines of code that are used to configure GPIO pins 14 and 15 to work with the Mini UART device:</p> <pre><code>    unsigned int selector;\n\n    selector = get32(GPFSEL1);\n    selector &amp;= ~(7&lt;&lt;12);                   // clean gpio14\n    selector |= 2&lt;&lt;12;                      // set alt5 for gpio14\n    selector &amp;= ~(7&lt;&lt;15);                   // clean gpio15\n    selector |= 2&lt;&lt;15;                      // set alt5 for gpio 15\n    put32(GPFSEL1,selector);\n</code></pre> <p>Init: GPIO pull-up/down &amp; how we disable it</p> <p>When working with GPIO pins, you will often encounter terms such as pull-up/pull-down. These concepts are explained in great detail in this article. For those who are too lazy to read the whole article, I will briefly explain the pull-up/pull-down concept.</p> <p>If you use a particular pin as input and don't connect anything to this pin, you will not be able to identify whether the value of the pin is 1 or 0. In fact, the device will report random values. The pull-up/pull-down mechanism allows you to overcome this issue. If you set the pin to the pull-up state and nothing is connected to it, it will report <code>1</code> all the time (for the pull-down state, the value will always be 0). In our case, we need neither the pull-up nor the pull-down state, because both the 14 and 15 pins are going to be connected all the time. </p> <p>The pin state is preserved even after a reboot, so before using any pin, we always have to initialize its state. There are three available states: pull-up, pull-down, and neither (to remove the current pull-up or pull-down state), and we need the third one.</p> <p>Switching between pin states is not a very simple procedure because it requires physically toggling a switch on the electric circuit. This process involves the <code>GPPUD</code> and <code>GPPUDCLK</code> registers and is described on page 101 of the SoC manual:</p> <pre><code>The GPIO Pull-up/down Clock Registers control the actuation of internal pull-downs on\nthe respective GPIO pins. These registers must be used in conjunction with the GPPUD\nregister to effect GPIO Pull-up/down changes. The following sequence of events is\nrequired:\n1. Write to GPPUD to set the required control signal (i.e. Pull-up or Pull-Down or neither\nto remove the current Pull-up/down)\n2. Wait 150 cycles \u2013 this provides the required set-up time for the control signal\n3. Write to GPPUDCLK0/1 to clock the control signal into the GPIO pads you wish to\nmodify \u2013 NOTE only the pads which receive a clock will be modified, all others will\nretain their previous state.\n4. Wait 150 cycles \u2013 this provides the required hold time for the control signal\n5. Write to GPPUD to remove the control signal\n6. Write to GPPUDCLK0/1 to remove the clock\n</code></pre> <p>This procedure describes how we can remove both the pull-up and pull-down states from a pin, which is what we are doing for pins 14 and 15 in the following code:</p> <pre><code>    put32(GPPUD,0);\n    delay(150);\n    put32(GPPUDCLK0,(1&lt;&lt;14)|(1&lt;&lt;15));\n    delay(150);\n    put32(GPPUDCLK0,0);\n</code></pre>"},{"location":"exp1/rpi-os/#init-mini-uart","title":"Init: Mini UART","text":"<p>Now our Mini UART is connected to the GPIO pins, and the pins are configured. The rest of the <code>uart_init</code> function is dedicated to Mini UART initialization. </p> <pre><code>    put32(AUX_ENABLES,1);                   //Enable mini uart (this also enables access to its registers)\n    put32(AUX_MU_CNTL_REG,0);               //Disable auto flow control and disable receiver and transmitter (for now)\n    put32(AUX_MU_IER_REG,0);                //Disable receive and transmit interrupts\n    put32(AUX_MU_LCR_REG,3);                //Enable 8 bit mode\n    put32(AUX_MU_MCR_REG,0);                //Set RTS line to be always high\n    put32(AUX_MU_BAUD_REG,270);             //Set baud rate to 115200\n\n    put32(AUX_MU_CNTL_REG,3);               //Finally, enable transmitter and receiver\n</code></pre> <p>Let's examine this code snippet line by line. </p> <pre><code>    put32(AUX_ENABLES,1);                   //Enable mini uart (this also enables access to its registers)\n</code></pre> <p>This line enables the Mini UART. We must do this in the beginning, because this also enables access to all the other Mini UART registers.</p> <pre><code>    put32(AUX_MU_CNTL_REG,0);               //Disable auto flow control and disable receiver and transmitter (for now)\n</code></pre> <p>Here we disable the receiver and transmitter before the configuration is finished. We also permanently disable auto-flow control because it requires us to use additional GPIO pins, and the TTL-to-serial cable doesn't support it. For more information about auto-flow control, you can refer to this article.</p> <pre><code>    put32(AUX_MU_IER_REG,0);                //Disable receive and transmit interrupts\n</code></pre> <p>It is possible to configure the Mini UART to generate a processor interrupt each time new data is available. We want to be as simple as possible. So for now, we will just disable this feature.</p> <pre><code>    put32(AUX_MU_LCR_REG,3);                //Enable 8 bit mode\n</code></pre> <p>Mini UART can support either 7- or 8-bit operations. This is because an ASCII character is 7 bits for the standard set and 8 bits for the extended. We are going to use 8-bit mode. </p> <pre><code>    put32(AUX_MU_MCR_REG,0);                //Set RTS line to be always high\n</code></pre> <p>The RTS line is used in the flow control and we don't need it. Set it to be high all the time.</p> <pre><code>    put32(AUX_MU_BAUD_REG,270);             //Set baud rate to 115200\n</code></pre> <p>The baud rate is the rate at which information is transferred in a communication channel. \u201c115200 baud\u201d means that the serial port is capable of transferring a maximum of 115200 bits per second. The baud rate of your Raspberry Pi mini UART device should be the same as the baud rate in your terminal emulator. </p> <p>The Mini UART calculates baud rate according to the following equation:</p> <pre><code>baudrate = system_clock_freq / (8 * ( baudrate_reg + 1 )) \n</code></pre> <p>The <code>system_clock_freq</code> is 250 MHz, so we can easily calculate the value of <code>baudrate_reg</code> as 270.</p> <pre><code>    put32(AUX_MU_CNTL_REG,3);               //Finally, enable transmitter and receiver\n</code></pre> <p>After this line is executed, the Mini UART is ready for work!</p>"},{"location":"exp1/rpi-os/#sending-data-over-uart","title":"Sending data over UART","text":"<p>After the Mini UART is ready, we can try to use it to send and receive some data. To do this, we can use the following two functions:</p> <pre><code>void uart_send ( char c )\n{\n    while(1) {\n        if(get32(AUX_MU_LSR_REG)&amp;0x20) \n            break;\n    }\n    put32(AUX_MU_IO_REG,c);\n}\n\nchar uart_recv ( void )\n{\n    while(1) {\n        if(get32(AUX_MU_LSR_REG)&amp;0x01) \n            break;\n    }\n    return(get32(AUX_MU_IO_REG)&amp;0xFF);\n}\n</code></pre> <p>Both of the functions start with an infinite loop, the purpose of which is to verify whether the device is ready to transmit or receive data. We are using  the <code>AUX_MU_LSR_REG</code> register to do this. Bit zero, if set to 1, indicates that the data is ready; this means that we can read from the UART. Bit five, if set to 1, tells us that the transmitter is empty, meaning that we can write to the UART.</p> <p>Next, we use <code>AUX_MU_IO_REG</code> to either store the value of the transmitted character or read the value of the received character.</p> <p>We also have a very simple function that is capable of sending strings instead of characters:</p> <pre><code>void uart_send_string(char* str)\n{\n    for (int i = 0; str[i] != '\\0'; i ++) {\n        uart_send((char)str[i]);\n    }\n}\n</code></pre> <p>This function just iterates over all characters in a string and sends them one by one. </p> <p>Low efficiency? Apparently Tx/Rx with busy wait burn lots of CPU cycles for no good. It's fine for our baremetal program -- simple &amp; less error-prone. Production software often do interrupt-driven Rx/Tx. </p>"},{"location":"exp1/rpi-os/#take-the-kernel-for-a-spin","title":"Take the kernel for a spin","text":""},{"location":"exp1/rpi-os/#qemu-route-1","title":"QEMU (route 1)","text":"<p>Setup</p> <p>Follow the instructions in Prerequisites.</p> <p>Type <code>make -f Makefile.qemu</code> . </p> <p>Run</p> <pre><code>$ qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img -serial null -serial stdio\nVNC server running on 127.0.0.1:5900\nHello, world!\n&lt;Ctrl-C&gt;\n</code></pre>"},{"location":"exp1/rpi-os/#rpi3-route-2","title":"Rpi3 (route 2)","text":"<p>Run <code>make -f Makefile.rpi3</code> to build the kernel. </p> <p>The Raspberry Pi startup sequence is the following (simplified):</p> <ol> <li>The device is powered on.</li> <li>The GPU starts up and reads the <code>config.txt</code> file from the boot partition. This file contains some configuration parameters that the GPU uses to further adjust the startup sequence.</li> <li><code>kernel8.img</code> is loaded into memory and executed.</li> </ol> <p>Setup</p> <p>To be able to run our simple OS, the <code>config.txt</code> file should be the following:</p> <pre><code>enable_uart=1\narm_64bit=1\nkernel_old=1\ndisable_commandline_tags=1\n</code></pre> <ul> <li><code>kernel_old=1</code> specifies that the kernel image should be loaded at address 0.</li> <li><code>disable_commandline_tags</code> instructs the GPU to not pass any command line arguments to the booted image.</li> </ul> <p>Run</p> <ol> <li>Copy the generated <code>kernel8.img</code> file to the <code>boot</code> partition of your Raspberry Pi flash card and delete <code>kernel7.img</code> as well as any other <code>kernel*.img</code> files on your SD card. Make sure you left all other files in the boot partition untouched (see 43 and 158 issues for details). </li> </ol> <p>Update (2/10/21): students reported that UART1 stops to work with the newest Rpi3 firmware (either extracted from Raspbian OS or from the upstream github repo). The symptom: no \"helloworld\" is printed, while UART1 seems echoing fine. UART0 seems unaffected. My guess: it has something to do with the firmware's new device tree feature? Action: use older firmware provided by us: https://github.com/fxlin/p1-kernel/releases/tag/exp1-rpi3. </p> <ol> <li> <p>Modify the <code>config.txt</code> file as described above.</p> </li> <li> <p>Connect the USB-to-TTL serial cable as described in the Prerequisites.</p> </li> <li> <p>Power on your Raspberry Pi.</p> </li> <li> <p>Open your terminal emulator. You should be able to see the <code>Hello, world!</code> message there.</p> </li> </ol> <p>Aside (optional): prepare the SD card from scratch (w/o Raspbian)</p> <p>The steps above assume that you have Raspbian installed on your SD card. It is also possible to run the RPi OS using an empty SD card.</p> <ol> <li> <p>Prepare your SD card:</p> <ul> <li>Use an MBR partition table</li> <li>Format the boot partition as FAT32 <p>The card should be formatted exactly in the same way as it is required to install Raspbian. Check <code>HOW TO FORMAT AN SD CARD AS FAT</code> section in the official documenation for more information.</p> </li> </ul> </li> <li> <p>Copy the following files to the card:</p> <ul> <li> <p>bootcode.bin This is the GPU bootloader, it contains the GPU code to start the GPU and load the GPU firmware. </p> </li> <li> <p>start.elf This is the GPU firmware. It reads <code>config.txt</code> and enables the GPU to load and run ARM specific user code from <code>kernel8.img</code></p> </li> </ul> <p>Update (2/10/21): UART1 is broken by these upstream firmware for unknown reason. Use older firmware provided by us: https://github.com/fxlin/p1-kernel/releases/tag/exp1-rpi3. </p> </li> <li> <p>Copy <code>kernel8.img</code> and <code>config.txt</code> files. </p> </li> <li> <p>Connect the USB-to-TTL serial cable.</p> </li> <li> <p>Power on your Raspberry Pi.</p> </li> <li> <p>Use your terminal emulator to connect to the RPi OS. </p> </li> </ol> <p>Unfortunately, all Raspberry Pi firmware files are closed-sourced and undocumented. For more information about the Raspberry Pi startup sequence, you can refer to some unofficial sources, like this StackExchange question or this Github repository.</p>"},{"location":"exp1/workflow/","title":"Simplifying the dev workflow","text":"<p>This is for developing for the actual Rpi3 hardware. Does not apply if you use QEMU. </p>"},{"location":"exp1/workflow/#motivation","title":"Motivation","text":"<p>You may have found that building &amp; testing the kernel requires tedious manual effort. Here are some steps to simplify the workflow, so that we can focus on kernel hacking. </p> <p>You should proceed only after having verified your hardware setup is correct. </p>"},{"location":"exp1/workflow/#is-it-safe-to","title":"Is it safe to ...?","text":""},{"location":"exp1/workflow/#unplug-the-micro-sd-card-usd-when-rpi3-is-powered-on","title":"Unplug the micro SD card (uSD) when Rpi3 is powered on?","text":"<p>Safe. Doing so when Rpi3 runs a full-fledged OS, e.g. Raspbian OS, may corrupt data because the OS caches data in memory. Our tiny kernel does not attempt to write any data to the micro SD. </p>"},{"location":"exp1/workflow/#plug-in-a-micro-sd-card-when-rpi3-is-powered-on","title":"Plug in a micro SD card when Rpi3 is powered on?","text":"<p>Safe. Then you can power-cycle the Rpi3 so </p>"},{"location":"exp1/workflow/#disconnect-the-serial-cable-when-rpi3-is-on","title":"Disconnect the serial cable when Rpi3 is on?","text":"<p>Safe. If your Rpi3 is powered over the serial cable -- no state to lose. If you Rpi3 is powered over micro USB: why disconnect the serial cable frequently? </p>"},{"location":"exp1/workflow/#unplug-micro-sd-from-pc-without-ejectingunmounting-from-the-pc-os","title":"Unplug micro SD from PC without \"ejecting/unmounting\" from the PC OS?","text":"<p>Safe. See here. </p>"},{"location":"exp1/workflow/#the-manual-workflow","title":"The manual workflow","text":"<p>(Once) Connect Rpi3 and PC via the serial cable. </p> <p>Repeat: </p> <ol> <li>Modify our kernel source if needed. Make kernel8.img</li> <li>Unplug uSD from Rpi3. Rpi3 does not have to be powered off. </li> <li>Plug in uSD to the card reader on PC. </li> <li>Copy kernel8.img to the uSD's boot partition. Overwrite the previous kernel8.img.</li> <li>Eject/umount uSD from PC. </li> <li>Plug in uSD to Rpi3.</li> <li>Power-cycle Rpi3. Wait for the kernel to execute. See output. Reason about it. </li> </ol>"},{"location":"exp1/workflow/#the-automated-workflow","title":"The automated workflow","text":"<p>Depending on your PC OS: </p> <p>Linux: there's a Python script which you can adapt. </p> <p>Windows (WSL): (contribute your experience)</p> <p>OSX: (contribute your experience)</p>"},{"location":"exp2/rpi-os/","title":"2: Processor initialization","text":"<p>READING TIME: 30 MIN</p> <p></p>"},{"location":"exp2/rpi-os/#objectives","title":"Objectives","text":"<p>We are going to build: </p> <p>A baremetal program that can switch among CPU exception levels and print out the current level. </p> <p>Students will: </p> <ol> <li>Experiment with exception levels (ELs)</li> <li>Observe switches among ELs -- crucial for subsequent experiments!</li> <li>Tinker with the kernel, e.g. debugging</li> </ol>"},{"location":"exp2/rpi-os/#get-the-code","title":"Get the code","text":"<p>Code location: p1-kernel/src/exp2</p> <p>Please: do a <code>git pull</code> even if you have cloned the p1-kenel repo previously, in case of upstream updates. </p>"},{"location":"exp2/rpi-os/#background-exception-levels-el","title":"Background: Exception levels (EL)","text":"<p>ARMv8 defines 4 exception levels. An exception level is a processor execution mode in which only a subset of all operations and registers is available. </p> <p>The least privileged exception level, i.e. lowest level, is level 0. When processor operates at this level, it mostly uses only general purpose registers (X0 - X30) and stack pointer register (SP). EL0 also allows using <code>STR</code> and <code>LDR</code> instructions to load and store data to and from memory, among other instructions commonly used by a user program.</p> <p></p> <p>Why exception levels? Because an OS needs to implement isolation. A user process should not be able to access other process's data. To achieve such behavior, a kernel always runs each user process at EL0. Operating at this exception level a process can only use it's own virtual memory and can't access any instructions that change ELs, MMUs, etc. </p> <p>The kernel itself usually works at EL1. While running at this exception level CPU gets access to the registers that allows configuring MMU as well as some system registers. </p> <p>About EL2/3: </p> <p>EL2 is for virtual machines. In this case the virtual machine hypervisor runs at EL2 and guest OSes run at EL1. This allows the hypervisor to isolate guest OSes in a similar way how OS isolates user processes.</p> <p>EL3 is for Arm TrustZone. It is used for transitions from ARM \"Secure World\" to \"Insecure world\". This abstraction exist to provide full hardware isolation between the software running in two different \"worlds\". Application from an \"Insecure world\" can in no way access or modify information (both instruction and data) that belongs to \"secure world\", and this restriction is enforced at the hardware level. </p>"},{"location":"exp2/rpi-os/#switching-els","title":"Switching ELs","text":"<p>In Arm architecture, there is no way a program can raise its own exception level without invoking code that is allowed to run on a higher level. This makes a perfect sense: otherwise, any program would be able to escape its assigned EL and makes unauthorized access to memory or registers. </p> <p>Current EL can be changed only if an exception is generated. Common causes of exceptions include:  </p> <ul> <li>software executes some illegal instruction (for example, tries to access memory location at a nonexisting address; </li> <li>software tries to divide an integer by 0; </li> <li>software executes special instructions (e.g. <code>svc</code>) to request exceptions. </li> </ul> <p>How about interrupts generated by IO? In Arm's lingo, interrupts are also handled as a special type of exceptions. </p> <p>Whenever an exception is generated the following sequence of steps takes place (In the description, the exception is handled at EL <code>n</code>, were <code>n</code> could be 1, 2 or 3).</p> <ol> <li>Address of the current instruction is saved in <code>ELR_ELn</code> (exception link register)</li> <li>Current processor state is stored in <code>SPSR_ELn</code> (Saved Program Status Register)</li> <li>NB: As some of you may know, other CPU hardware may automatically push registers on stack prior to exception handling. Armv8 does NOT do that. </li> <li>The CPU executes an exception handler at ELn.</li> <li>The exception handler calls <code>eret</code> instruction. This instruction restores processor state from <code>SPSR_ELn</code> and resumes execution starting from the address, stored in the <code>ELR_ELn</code>  register.</li> </ol> <p>There are more details, e.g. the exception handler software also needs to store the state of all general purpose registers and restore it back afterwards, as we will discuss this process in details in the upcoming experiment. For now, we need just to understand the process in general and remember the meaning of the <code>ELR_ELm</code> and <code>SPSR_ELn</code> registers.</p> <p>An important thing to know is that exception handler is not obliged to return to the same instruction where the exception originates. Both <code>ELR_ELm</code> and <code>SPSR_ELn</code> are writable and the exception handler can modify them in order to specify the instructions to execute right after the EL switch. We are going to use this technique to our advantage when we try to switch from EL3 to EL1 in our code.</p>"},{"location":"exp2/rpi-os/#aside-enhanced-debugging","title":"Aside: enhanced debugging","text":""},{"location":"exp2/rpi-os/#bring-up-printf","title":"Bring up printf()","text":"<p>Right now, the kernel can only print some constant string on a screen, but what I need is some analog of printf function. With <code>printf</code> I can easily display values of different registers and variables. Such functionality is essential for the kernel development because you don't have any other debugger support and <code>printf</code> becomes the only mean for figuring out what is going on inside Rpi3.</p> <p>Let's not reinvent the wheel and use one of  existing printf implementations This function consists mostly from string manipulations and is not very interesting from a kernel developer point of view. The implementation that I used is very small and don't have external dependencies, that allows it to be easily integrated into the kernel. The only thing that I have to do is to define <code>putc</code>  function that can send a single character to the screen. This function is defined here and it just uses already existing <code>uart_send</code> function. Also, we need to initialize the <code>printf</code> library and specify the location of the <code>putc</code> function. This is done in a single line of code.</p>"},{"location":"exp2/rpi-os/#qemu-gdb-debugging","title":"QEMU + GDB debugging","text":"<p>Reminder: GDB allows you to do single step, etc. It may help understand specific instructions. You can find extensive information online. </p>"},{"location":"exp2/rpi-os/#code-walkthrough","title":"Code Walkthrough","text":""},{"location":"exp2/rpi-os/#finding-out-the-current-el","title":"Finding out the current EL","text":"<p>As we are equipped with the <code>printf</code> function, we can proceed to figure out at which exception level the kernel is booted. A small function that can answer this question looks like this.</p> <pre><code>.globl get_el\nget_el:\n    mrs x0, CurrentEL\n    lsr x0, x0, #2\n    ret\n</code></pre> <p>Here we use <code>mrs</code> instruction to read the value from <code>CurrentEL</code> system register into <code>x0</code> register. Then we shift this value 2 bits to the right (because the lowest 2 bits in the <code>CurrentEL</code> register are reserved and always have value 0). Finally the register <code>x0</code> contains an integer number indicating current exception level. Now the only thing that is left is to display this value, like this.</p> <pre><code>    int el = get_el();\n    printf(\"Exception level: %d \\r\\n\", el);\n</code></pre>"},{"location":"exp2/rpi-os/#switching-to-el1","title":"Switching to EL1","text":"<p>EL1 is intended for OS kernels. Strictly speaking, our kernel is not obliged to switch to EL1 when it boots up, but EL1 is a natural choice for us because this level has just the right set of privileges to implement all common OS tasks. It also will be an interesting exercise to see how switching exceptions levels works in action. Let's take a look at the source code that does this (boot.S). </p> <pre><code>master:\n    ldr    x0, =SCTLR_VALUE_MMU_DISABLED\n    msr    sctlr_el1, x0        \n\n    ldr    x0, =HCR_VALUE\n    msr    hcr_el2, x0\n\n    ldr    x0, =SCR_VALUE\n    msr    scr_el3, x0\n\n    ldr    x0, =SPSR_VALUE\n    msr    spsr_el3, x0\n\n    adr    x0, el1_entry        \n    msr    elr_el3, x0\n\n    eret                \n</code></pre> <p>The code configures a few system registers. Now we are going to examine those registers one by one. The register details are documented in the Armv8 architecture manual which we will refer to as needed. </p>"},{"location":"exp2/rpi-os/#sctlr_el1-system-control-register-el1","title":"SCTLR_EL1, System Control Register (EL1)","text":"<pre><code>    ldr    x0, =SCTLR_VALUE_MMU_DISABLED\n    msr    sctlr_el1, x0        \n</code></pre> <p>Here we set the value of the <code>sctlr_el1</code> system register. <code>sctlr_el1</code> is responsible for configuring different parameters of CPU when CPU operates at EL1. For example, it controls whether the cache is enabled and, what is most important for us, whether the MMU (Memory Management Unit) is turned on. <code>sctlr_el1</code> is accessible from all exception levels higher or equal than EL1 (you can infer this from <code>_el1</code> postfix) </p> <p><code>SCTLR_VALUE_MMU_DISABLED</code> constant is defined here Individual bits of this value are defined like this:</p> <ul> <li><code>#define SCTLR_RESERVED                  (3 &lt;&lt; 28) | (3 &lt;&lt; 22) | (1 &lt;&lt; 20) | (1 &lt;&lt; 11)</code> Some bits in the description of <code>sctlr_el1</code> register are marked as <code>RES1</code>. Those bits are reserved for future usage and should be initialized with <code>1</code>.</li> <li><code>#define SCTLR_EE_LITTLE_ENDIAN          (0 &lt;&lt; 25)</code> Exception Endianness. This field controls endianess of explicit data access at EL1. We are going to configure the processor to work only with <code>little-endian</code> format.</li> <li><code>#define SCTLR_EOE_LITTLE_ENDIAN         (0 &lt;&lt; 24)</code> Similar to previous field but this one controls endianess of explicit data access at EL0, instead of EL1. </li> <li><code>#define SCTLR_I_CACHE_DISABLED          (0 &lt;&lt; 12)</code> Disable instruction cache. We are going to disable all caches for simplicity. You can find more information about data and instruction caches here.</li> <li><code>#define SCTLR_D_CACHE_DISABLED          (0 &lt;&lt; 2)</code> Disable data cache.</li> <li><code>#define SCTLR_MMU_DISABLED              (0 &lt;&lt; 0)</code> Disable MMU. MMU must be disabled until the lesson 6, where we are going to prepare page tables and start working with virtual memory.</li> </ul> <p>FYI - official doc</p>"},{"location":"exp2/rpi-os/#hcr_el2-hypervisor-configuration-el2","title":"HCR_EL2, Hypervisor Configuration (EL2)","text":"<pre><code>    ldr    x0, =HCR_VALUE\n    msr    hcr_el2, x0\n</code></pre> <p>We are NOT going to implement our own hypervisor. Still we need to use this register. Among other settings, bit 31 (RW) controls the execution state at EL1, being AArch64 (1) or AArch32 (0). This register also controls at which EL we will handle IRQ. </p> <p>In <code>sysregs.h</code> we set HCR_VALUE to be (1&lt;&lt;31). </p> <p>Official doc</p>"},{"location":"exp2/rpi-os/#scr_el3-secure-configuration-el3","title":"SCR_EL3, Secure Configuration (EL3)","text":"<pre><code>    ldr    x0, =SCR_VALUE\n    msr    scr_el3, x0\n</code></pre> <p>This register is responsible for configuring security settings. For example, it controls whether all lower levels are executed in \"secure\" or \"nonsecure\" world. It also controls execution state at EL2. Here we set that EL2 will execute at <code>AArch64</code> state, and all lower exception levels will be \"non secure\". </p> <p>This register has no counterpart at EL2. Therefore, we don't have to set it on qemu emulation. </p> <p>Official doc</p>"},{"location":"exp2/rpi-os/#spsr_el3-saved-program-status-el3","title":"SPSR_EL3, Saved Program Status (EL3)","text":"<pre><code>    ldr    x0, =SPSR_VALUE\n    msr    spsr_el3, x0\n</code></pre> <p><code>spsr_el3</code> contains CPU state, that will be restored after we execute <code>eret</code> instruction. What is CPU state? It consists of the following information:</p> <ul> <li> <p>Condition Flags Those flags contains information about previously executed executions: whether the result was negative (N flag), zero (A flag), has unsigned overflow (C flag) or has signed overflow (V flag). Values of those flags can be used in conditional branch instructions. For example, <code>b.eq</code> instruction will jump to the provided label only if the result of the last comparison operation is equal to 0. The processor checks this by testing whether Z flag is set to 1.</p> </li> <li> <p>Interrupt disable bits Those bits allows to enable/disable different types of interrupts.</p> </li> <li> <p>EL &amp; other information, required to fully restore the processor execution state after an exception is handled. </p> </li> </ul> <p>Usually <code>spsr_el3</code> is saved automatically by CPU hardware, when an exception is taken to EL3. Furthermore, this register is writable by our code, so we take advantage of this fact and manually prepare CPU state. <code>SPSR_VALUE</code> is prepared here and we initialize the following fields:</p> <ul> <li><code>#define SPSR_MASK_ALL        (7 &lt;&lt; 6)</code> After we change EL to EL1 all types of interrupts will be masked (or disabled, which is the same).</li> <li><code>#define SPSR_EL1h        (5 &lt;&lt; 0)</code> This indicates to which EL the <code>eret</code> instruction will take the CPU to. It's EL1. About EL1h: At EL1 we can either use our own dedicated stack pointer or use EL0 stack pointer. <code>EL1h</code> mode means that we are using EL1 dedicated stack pointer. </li> </ul> <p>Official doc</p>"},{"location":"exp2/rpi-os/#elr_el3-exception-link-el3","title":"ELR_EL3, Exception Link (EL3)","text":"<pre><code>    adr    x0, el1_entry        \n    msr    elr_el3, x0\n    eret                \n</code></pre> <p><code>elr_el3</code> holds the address, to which we are going to return after <code>eret</code> instruction will be executed. Here we set this address to the location of <code>el1_entry</code> label.</p> <p>Official doc</p>"},{"location":"exp2/rpi-os/#conclusion","title":"Conclusion","text":"<p>That is pretty much it: when we enter <code>el1_entry</code> function the execution should be already at EL1 mode. </p> <p>Qemu.log: </p> <pre><code>Exception return from AArch64 EL2 to AArch64 EL1 PC 0x80038\n</code></pre> <p>The address 0x80038 should point to el1_entry. Check it out using addr2line. </p> <p>Our subsequent experiments will switch between EL1 (kernel) and EL0 (user) frequently. </p> <p>Go ahead and try it out! </p>"},{"location":"exp3/fb/","title":"3 bonus: Interrupt-driven animation","text":"<p>This is optional for the course purpose. Thus, this write up is not intended to be as thorough as others. </p>"},{"location":"exp3/fb/#objectives","title":"Objectives","text":"<ol> <li>See a use case of interrupts</li> <li>Learn about framebuffer </li> <li>Have some eye candy. </li> </ol>"},{"location":"exp3/fb/#environment","title":"Environment","text":"<p>Rpi3: need an HDMI cable connecting to a display. </p> <p>QEMU (with Windows/Mac local machines): run QEMU with sdl support over X. QEMU must be configured with \"--enable-sdl\" and built. </p> <p>See here: https://docs.google.com/document/d/1MVOJzVWuJeYznnzXg1C6Pe6bLi1KlmXik2FiPB1mKlE/edit#heading=h.brve2j4duzqk</p> <p>If you want to run QEMU locally, you can download prebuilt QEMU binaries. https://www.qemu.org/download/. To invoke prebuilt QEMU from PowerShell: </p> <p></p>"},{"location":"exp3/fb/#quick-start","title":"Quick start","text":"<pre><code>cd exp3-bonus\nmake clean\nUSE_QEMU=1 make # for QEMU\nUSE_QEMU make # for rpi3\n</code></pre> <p>Pre-built binaries for Rpi3:</p> <p>https://github.com/fxlin/p1-kernel/releases/tag/p1exp3bonus</p>"},{"location":"exp3/fb/#result-rpi3","title":"Result (Rpi3)","text":"<p>QEMU has caveats. See below. </p>"},{"location":"exp3/fb/#background","title":"Background","text":"<p>Framebuffer A memory region for pixel data. In the simplest form, CPU write RGB values there and pixels will show up on the display. </p> <p>Mailbox. On Rpi3, CPU talks to GPU through hardware mailbox. It's a small piece of memory shared between CPU/GPU. CPU puts commands in the shared memory (mbox) and kicks the GPU by writing to a GPU register; GPU executes the commands and responds by writing results to the shared memory. Code: <code>mbox.c</code></p>"},{"location":"exp3/fb/#rpi3-framebuffer-properties","title":"Rpi3 framebuffer properties","text":"<p>On Rpi3, CPU talks to the GPU to set up the framebuffer. This function constructs a mbox message for GPU with a series of framebuffer properties. </p> <p>Virtual height/width define the framebuffer dimension. CPU is responsible for providing these pixels. </p> <p>Physical height/width define a rectangular region of pixels to be displayed. These pixels are derived by GPU from the framebuffer. See below. </p> <p>Virtual offsets define the top-left corner of the physical region within the virtual region. </p> <p>Pitch (bytes) is the actual memory size that each pixel raw takes in the framebuffer. </p> <p>Note: the following is based on (1) the Rpi foundation online documentation; (2) QEMU source code for emulating Rpi3 GPU/display; (3) my experiments on Rpi3. </p> <p>(1) can be vague or erroneous and (2) is rudimentary. </p> <p>Case 1: Virtual region &gt; physical region (i.e. the viewport is a strict subpart of the framebuffer). This can be useful for screen panning and double buffering. This is how game consoles implement scrolling, e.g. over a large map pre-rendered in memory. Here's an excellent video on GameBoy: https://www.youtube.com/watch?v=FzPTK91EJY8&amp;t=405s</p> <p></p> <p>The Rpi3 mechanism is shown in the figure above. </p> <p>The hardware takes the pixels in from the viewport (defined by the phys region) in the framebuffer and sends to display. Scaling is applied before the final display. The viewport size does not necessarily correspond to the resolution on display. For instance, the viewport (phys height x width) can be 300x300; the final picture on the display could occupy the full screen (with x/y ratio preserved). This is also in the figure above. </p> <p>Case 2: Virtual region &lt; physical region (i.e. the viewport is a strict superpart of the framebuffer)</p> <p> In this case, GPU scales the framebuffer pixels (virtual region) to the viewport (physical region). GPU seems to be doing interpolation to generate the additional pixels. Then GPU sends the physical region to display as above. </p> <p>The virtual region can be very small. \"On boot, the virtual size is set to 2x2. If a framebuffer is allocated without reconfiguring the virtual size, the screen will consist of four very large virtual pixels.  Coloured red, green, yellow and blue, they produce the \"rainbow\" startup screen.\" [2]. See the picture below. This is the default display when Rpi3 boots without any additional changes to its default 2x2 (four pixel) framebuffer. </p> <p>Virtual offsets are ineffective. I confirmed that. QEMU code <code>fb_use_offsets</code> also suggests so. </p> <p>The picture below: the virtual region: 64x48 filled with a test image of 64x48; the physical region: 600x600. </p> <p></p> <p>Case 3: otherwise? (untested. Per QEMU code virtual offsets will be ineffective).</p>"},{"location":"exp3/fb/#qemus-emulation-caveats","title":"QEMU's emulation caveats","text":"<p>(Observation based on QEMU's master branch as of Feb 2020.)</p> <p>QEMU's emulation of Rpi3 display only realizes the most common cases, e.g. virt = physical with offsets=0. Beyond that, it's quite problematic. For instance, here's how QEMU would display when virt 64x48 &lt; physical 600x600, showing it does not implement scaling. </p> <p></p> <p>QEMU display will also flicker when CPU is updating offsets periodically. Likely a bug in the code below. </p> <p></p> <p><code>hw/misc/bcm2835_property.c</code> implements the CPU/GPU mailbox interface. Can see what framebuffer properties are implemented. </p> <p><code>hw/display/bcm2835_fb.c</code> has the actual emulation logic. See <code>fb_use_offsets()</code> which only applies virt offsets when virtual is smaller than physical. <code>bcm2835_fb_validate_config()</code> is how QEMU think the Rpi3 framebuffer should work, which can be problematic. </p>"},{"location":"exp3/fb/#kernel-code-walkthrough","title":"Kernel code walkthrough","text":""},{"location":"exp3/fb/#set-up-the-framebuffer","title":"Set up the framebuffer","text":"<p><code>lfb.c</code> is the framebuffer code. <code>lfb_init</code> sets up the framebuffer dimension. <code>lfb_showicture()</code> fills in the framebuffer with pixels from an image. We do not load from an image file (no filesystem yet!). Instead, we convert an image to a C header (e.g. tv-test-scree.h) using GIMP. Pretty cool! </p> <p></p> <p>The header looks like this: </p> <pre><code>static unsigned int tv_width = 1280;\nstatic unsigned int tv_height = 800;\n\n/*  Call this macro repeatedly.  After each use, the pixel data can be extracted  */\n\n#define HEADER_PIXEL(data,pixel) {\\\npixel[0] = (((data[0] - 33) &lt;&lt; 2) | ((data[1] - 33) &gt;&gt; 4)); \\\npixel[1] = ((((data[1] - 33) &amp; 0xF) &lt;&lt; 4) | ((data[2] - 33) &gt;&gt; 2)); \\\npixel[2] = ((((data[2] - 33) &amp; 0x3) &lt;&lt; 6) | ((data[3] - 33))); \\\ndata += 4; \\\n}\nstatic char *tv_data =\n    \"````````````````````````````````````````````````````````````````\"\n    \"````````````````````````````````````````````````````````````````\"\n    \"`0T]I+#A!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n    \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n    \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n    \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!35F*Y_0D````````````````\"\n    \"````````````````````````````````````````````````````````````````\"\n    ...\n</code></pre> <p>The header can be large, e.g. a few MBs. </p> <p>As a result, the raw RGB values will be compiled as an array in our kernel. </p>"},{"location":"exp3/fb/#adjust-the-linker-script","title":"Adjust the linker script","text":"<p>Now build the kernel. You may see an error like this:</p> <pre><code>aarch64-linux-gnu-ld -T build-qemu/linker.ld -o build-qemu/kernel8.elf  build-qemu/mbox_c.o build-qemu/lfb_c.o build-qemu/kernel_c.o build-qemu/irq_c.o build-qemu/mini_uart_c.o build-qemu/printf_c.o build-qemu/timer_c.o build-qemu/timer_s.o build-qemu/utils_s.o build-qemu/irq_s.o build-qemu/entry_s.o build-qemu/mm_s.o build-qemu/boot_s.o\nbuild-qemu/boot_s.o: In function `el1_entry':\n/data/teaching/p1-kernel-workspace/p1-kernel/src/exp3-bonus/src/boot.S:44:(.text.boot+0x38): relocation truncated to fit: R_AARCH64_ADR_PREL_LO21 against symbol `bss_begin' defined in .bss section in build-qemu/kernel8.elf\n/data/teaching/p1-kernel-workspace/p1-kernel/src/exp3-bonus/src/boot.S:45:(.text.boot+0x3c): relocation truncated to fit: R_AARCH64_ADR_PREL_LO21 against symbol `bss_end' defined in .bss section in build-qemu/kernel8.elf\nMakefile:49: recipe for target 'kernel8.img' failed\nmake: *** [kernel8.img] Error 1\n</code></pre> <p>Understand this is a linker error: because the message shows up when invoking <code>ld</code>. </p> <p>Per the error message, this error is about <code>el1_entry</code>. </p> <pre><code>el1_entry:\n    adr x0, bss_begin\n    adr x1, bss_end\n</code></pre> <p>It refers to two symbols bss_begin and bss_end using instructions ADR (\"R_AARCH64_ADR_PREL_LO21\"). The instructions encode the addresses of bss_begin/end as relative offsets to PC. The maximum offsets are 21 bits (\"LO21\"). Now we put lots of extra bytes in .data section, el1_entry is too far away from bss_begin/end. This can be seen from the existing linker script, where .data is sandwiched in between .text.boot and .bss. </p> <pre><code>SECTIONS\n{\n    . = START_ADDR;\n    .text.boot : { *(.text.boot) }\n    .text : { *(.text) }\n    .rodata : { *(.rodata) }\n    .data : { *(.data) }\n    . = ALIGN(0x8);\n    bss_begin = .;\n    .bss : { *(.bss*) } \n    bss_end = .;        \n}\n</code></pre> <p>Solution: move .bss to right after .text and we are good. </p>"},{"location":"exp3/fb/#updating-the-framebuffer","title":"Updating the framebuffer","text":"<p><code>lfb_update</code> simply increments virt offsets via mbox to the GPU. </p> <p>From the timer interrupt, we call <code>lfb_update</code>: </p> <pre><code>void handle_generic_timer_irq( void ) \n{\n    gen_timer_reset(interval);\n    lfb_update(); // refresh fb\n}\n</code></pre>"},{"location":"exp3/fb/#known-issues","title":"Known issues","text":""},{"location":"exp3/fb/#reference","title":"Reference","text":"<ol> <li> <p>https://github.com/bztsrc/raspi3-tutorial/tree/master/09_framebuffer</p> </li> <li> <p>https://github.com/brianwiddas/pi-baremetal</p> </li> </ol>"},{"location":"exp3/fb/#as-tribute-to","title":"As tribute to...","text":"<p>KONAMI, Fighting Eleven World Soccer 2, Super Famicom, 1995. </p> <p></p>"},{"location":"exp3/rpi-os/","title":"3: Interrupts","text":"<p>READING TIME: 40 MIN</p> <p></p>"},{"location":"exp3/rpi-os/#objectives","title":"Objectives","text":"<p>We will build a baremetal program that prints out messages, as driven by periodic interrupts from a hardware timer. </p> <p>You will learn and experience with: </p> <ol> <li>Exception/interrupt vectors</li> <li>Handling interrupts</li> <li>Program hardware timers</li> </ol>"},{"location":"exp3/rpi-os/#get-the-code","title":"Get the code","text":"<p>Code location: p1-kernel/src/exp3</p> <p>Please: do a <code>git pull</code> even if you have cloned the p1-kenel repo previously, in case of upstream updates. </p>"},{"location":"exp3/rpi-os/#terms","title":"Terms","text":"<p>\"Interrupts\" or \"irq\"? We use these two terms interchangeably. Many kernel documents use the latter. </p>"},{"location":"exp3/rpi-os/#hacking-tips-tracing-interrupts-with-qemu","title":"Hacking tips -- tracing interrupts with QEMU","text":"<pre><code>qemu-system-aarch64 -M raspi3 -kernel ./kernel8.img \\\n-serial null -serial stdio \\\n-d int -D test.log \n</code></pre> <p>See the qmeu cheatsheet for more. </p>"},{"location":"exp3/rpi-os/#background-interrupts-exceptions-in-arm64","title":"Background: interrupts &amp; exceptions in ARM64","text":""},{"location":"exp3/rpi-os/#interrupts","title":"Interrupts","text":"<p>Interrupts are generated by IO devices, go through the irq controller, and eventually arrive the CPU. The CPU can program the irq controller to enable/disable specific interrupt sources. By disabling an irq source, the CPU will not lose any irq from that device, but just defer receiving irq until the CPU re-enables the irq source. The CPU can also read from the irq controller which IO devices have pending interrupts, meaning that the IO devices need attention. </p> <p></p> <p>By their canonical definitions, interrupts are asynchronous while exceptions are synchronous. </p>"},{"location":"exp3/rpi-os/#interrupts-exceptions-on-aarch64","title":"Interrupts &amp; Exceptions on aarch64","text":"<p>However in ARM64 lingo, exception is broadly defined; interrupts are a special kind of exceptions. x86 has its own lingo, calling exceptions as \"traps\". </p> <p>In this article, we use ARM's broad definition of exceptions unless stated otherwise. </p>"},{"location":"exp3/rpi-os/#exception-vectors","title":"Exception vectors","text":"<p>Figure above: the EL1 vector table as in memory. EL2 and EL3 each has a separate vector table like this.</p> <p>An exception vector (or handler) is a piece of code the CPU will execute when a specific exception happens. \"These would normally be branch instructions that direct the core to the full exception handler.\" (the ARM64 manual). </p> <p>The ARM64 hardware mandates: each exception vector can occupy<code>0x80</code> bytes maximum (thus <code>.align 7</code> in the asm code). </p> <p>A vector table is an array of exception vectors. Each exception level (EL) has its own vector table. The above figure shows the vector table for EL1. </p> <p>The vector table for EL1. Provided by our kernel. Purpose: to handle exceptions taken from EL0 (user programs) or EL1 (the kernel's own execution). </p> <p>Format: the kernel defines 16 exception handlers: 4 types [sync, irq, fiq, serror] for each of the CPU 4 execution states [EL1t, EL1h, EL0_64, EL0_32]. </p> <p>Four exception types  (focus the former two) </p> <ol> <li> <p>Synchronous exceptions Exceptions of this type are always caused by the currently executed instruction. For example, you can use <code>str</code> instruction to store some data at a non-existing memory location. In this case, a synchronous exception is generated. Synchronous exceptions also can be used to generate a \"software interrupt\". Software interrupt is a synchronous exception that is generated on purpose by <code>svc</code> instruction. We will use this technique in lesson 5 to implement system calls.</p> </li> <li> <p>Asynchronous exceptions (IRQ) Those are normal interrupts. They are always asynchronous, which means that they have nothing to do with the currently executed instruction.  In contrast to synchronous exceptions, they are always not generated by the processor itself, but by external hardware.</p> </li> <li> <p>FIQ (Fast Interrupt Request) This type of exception is called \"fast interrupts\" and exist solely for the purpose of prioritizing exceptions. It is possible to configure some interrupts as \"normal\" and other as \"fast\". Fast interrupts will be signaled first and will be handled by a separate exception handler. Linux doesn't use fast interrupts and we also are not going to do so.</p> </li> <li> <p>SError (System Error) Like <code>IRQ</code> and <code>FIQ</code>, <code>SError</code> exceptions are asynchronous and are generated by external hardware. Unlike <code>IRQ</code> and <code>FIQ</code>, <code>SError</code> always indicates some error condition. Here you can find an example explaining when <code>SError</code> can be generated.</p> </li> </ol> <p>Four CPU execution states</p> <ol> <li>EL1t Exception happens when CPU is at EL1 while the stack pointer (SP) was set to be shared with EL0. This happens when <code>SPSel</code> register holds the value <code>0</code>.  Recall that <code>SPSel</code> is part of the CPU's PSTATE. </li> <li>EL1h Exception happens at EL1 at the time when a dedicated SP was allocated for EL1. This happens when <code>SPSel</code> holds the value <code>1</code>. This is the mode that our kernel is are currently using.</li> <li>EL0_64 Exception is taken from EL0 executing in 64-bit mode. This experiment will not deal with EL0. Spoiler: EL0_64 corresponds to the exceptions that caused by 64-bit user programs. (Note: in the vector table for EL1, this entry is for EL0_64; in the vector table for EL2, this is for EL1_64)</li> <li>EL0_32 Exception is taken from EL0 executing in 32-bit mode. This experiment will not deal with EL0 or 32-bit mode. Spoiler: this corresponds to exceptions in 32-bit user programs. (Note: in the vector table for EL1, this entry is for EL0_32; in the vector table for EL2, this is for EL1_32)</li> </ol> <p>\"The t and h suffixes are based on the terminology of thread and handler, introduced in ARMv7-M.\" -- ARM</p> <p>The vector tables for EL2 or EL3? The format is the same as EL1, e.g. 16 (=4x4) exception handlers. Note: EL2 vectors are for exceptions taken from EL2 and EL1; EL3 vectors are for exceptions taken from EL3 and EL2. See the short official document \"AArch64 exception vector table\". </p>"},{"location":"exp3/rpi-os/#code-walkthrough","title":"Code Walkthrough","text":""},{"location":"exp3/rpi-os/#exception-vectors-tables-etc-entrys","title":"Exception vectors, tables, etc. (entry.S)","text":"<p>The figure below shows how vector table is defined. The code mimics what the ARM64 Linux kernel does. </p> <p></p> <p>Why named \"entry.S\"? Because in a full-fledged kernel, exception/irq handlers are where user programs enter the kernel for execution. Although this experiment is not building such a kernel, we follow the naming convention. </p> <p>The vector table consists of 16 <code>ventry</code> definitions:</p> <pre><code>.align  11\n.globl vectors \nvectors:\n    ventry  sync_invalid_el1t           // Synchronous EL1t\n    ventry  irq_invalid_el1t            // IRQ EL1t\n    ventry  fiq_invalid_el1t            // FIQ EL1t\n    ventry  error_invalid_el1t          // Error EL1t\n... \n</code></pre> <p>The macro ventry is used to create entries in the vector table.</p> <pre><code>    .macro    ventry    label\n    .align    7\n    b    \\label\n    .endm\n</code></pre> <p>As suggested above: for code clarity, we are not going to handle exceptions right inside the exception vector. Instead, we make each vector a branch instruction (<code>b \\label</code>) that jumps to a label provided for the macro as <code>label</code> argument.</p> <p>We need <code>.align 7</code> because all exception vectors should be spaced at <code>0x80</code> bytes (2&lt;&lt;7) one from another. A useful assembly trick. </p>"},{"location":"exp3/rpi-os/#making-cpu-aware-of-the-vector-table-irqs","title":"Making CPU aware of the vector table (irq.S)","text":"<p>Ok, now we have prepared the vector table, but the processor doesn't know where it is located and therefore can't use it. In order for the exception handling to work, we must set <code>vbar_el1</code> (Vector Base Address Register) to the vector table address. </p> <pre><code>.globl irq_vector_init\nirq_vector_init:\n    adr    x0, vectors        \n    msr    vbar_el1, x0       \n    ret\n</code></pre>"},{"location":"exp3/rpi-os/#a-simple-handler-for-unexpected-exceptions","title":"A simple handler for unexpected exceptions","text":"<p>In this experiment we are only interested in handling <code>IRQ</code> that occurred at EL1h. Yet, our kernel  defines all 16 handlers for EL1. This is for debugging ease: we want to print out meaningful message in case our kernel triggers some other exceptions due to our programming mistakes. </p> <p>We name all the handlers that are NOT supposed to be trigged  with a <code>invalid</code> postfix. We implement these handlers using a handle_invalid_entry macro:</p> <pre><code>    .macro handle_invalid_entry type\n    kernel_entry\n    mov    x0, #\\type\n    mrs    x1, esr_el1\n    mrs    x2, elr_el1\n    bl    show_invalid_entry_message\n    b    err_hang\n    .endm\n</code></pre> <p>The first line invokes a macro <code>kernel_entry</code> which is the first few instructions the kernel should execute in handling an exception/interrupt (recall the term \"entry\"). We will discuss it below.</p> <p>Then we call show_invalid_entry_message() and prepare 3 arguments for it. The arguments are passed in 3 registers: x0, x1, and x2. </p> <ul> <li>x0: the exception type. The value comes from the argument to this macro. It can take one of these values defined in entry.h. It tells us exactly which exception handler has been executed.</li> <li>x1: information about what causes the exception. The value comes from <code>esr_el1</code> register.  <code>ESR</code> stands for Exception Syndrome Register. EL1 implies \"when an exception is taken to EL1\", i.e. when the exception is handled at EL1. Note: in this experiment our kernel runs at EL1 and when an interrupt happens it is handled at EL1. Read the ref again. </li> <li>x2: the address of the instruction being executed when the exception happens. The value comes from the  <code>elr_el1</code> as described earlier. For synchronous exceptions, this is the instruction that causes the exception; for irqs (asynchronous), this is the instruction completed right before irq happens. Again, the postfix EL1 indicates that \"when taking an exception to EL1, (this reg) holds the address to return to.\" </li> </ul> <p>The code next invokes <code>show_invalid_entry_message</code>  function, which prints textual information to UART. Returning from that function, the code executes in an infinite loop as we have nothing else to do. </p>"},{"location":"exp3/rpi-os/#kernel_entry-exit","title":"kernel_entry &amp; exit","text":"<p>To handle valid exceptions (timer interrupts in our case), the kernel needs to save &amp; restore the context of the \"normal\" execution, i.e. switching from the normal execution to the exception handler, executing it, and resuming the execution being interrupted. In other words, after the exception handler, we want all general purpose registers to have the same values as they had before the exception was generated. </p> <p>Why does NOT the above handler <code>handle_invalid_entry</code> save registers? Because it ends with an infinite loop and never intends to resume the interrupted execution. </p> <pre><code>el1_irq:\n    kernel_entry \n    bl  handle_irq\n    kernel_exit \n</code></pre> <p>Back to <code>kernel_entry</code>. This is the first thing to do in handling an exception: saving the processor state, notably registers x0 - x30, to the stack. To do so, it first subtracts from <code>sp</code> the size of total stored registers (#S_FRAME_SIZE) and then fills the stack space. </p> <p>According to <code>kernel_entry</code>, there is <code>kernel_exit</code> to be called as the last thing of an exception handler. <code>kernel_exit</code> restores the CPU state by copying back the values of x0 - x30. The order exactly mirrors that of <code>kernel_entry</code> otherwise we will see wrong register values. Finally <code>kernel_exit</code> executes <code>eret</code>, which returns to the interrupted execution (still at EL1). </p> <p>The following figure shows how the kernel memory look like before &amp; after handling an interrupt. </p> <p></p>"},{"location":"exp3/rpi-os/#interrupt-enabledisable","title":"interrupt enable/disable?","text":"<p>When an exception happens, the CPU will turn off interrupts automatically.\u00a0When we return from an interrupt, ERET will restore PSTATE from SPSR_EL1, which contains the DAIF flags that control the interrupt state (i.e. enabled or disabled). </p>"},{"location":"exp3/rpi-os/#configuring-interrupts","title":"Configuring interrupts","text":""},{"location":"exp3/rpi-os/#_1","title":"exp3","text":""},{"location":"exp3/rpi-os/#configuring-the-interrupt-controller","title":"Configuring the Interrupt controller","text":"<p>Bcm2837, the SoC for Rpi3, has its own interrupt controller described on page 109 of BCM2837 ARM Peripherals manual. Because of the hardware quirks (e.g. many irqs are routed from GPU to CPU), the interrupt controller organizes irq sources into three groups and has registers for controlling/checking individual groups. </p> <p>Be aware of their weird naming: these irq groups are called \"Basic\" (irqs routed to the ARM CPU), \"1\", and \"2\" (irqs routed from GPU to CPU). For example, <code>IRQ basic pending</code>, <code>IRQ pending 1</code>, <code>IRQ pending 2</code>.  The SoC manual has more dirty details. </p> <p>We are only interested in timer interrupts. The SoC manual, page 113 states that irq #1 and #3 are from the system timer. These irq sources belong to the irq group 1, which can be enabled using ENABLE_IRQS_1. So <code>enable_interrupt_controller()</code> enables system timer IRQ at #1: </p> <pre><code>void enable_interrupt_controller()\n{\n    put32(ENABLE_IRQS_1, SYSTEM_TIMER_IRQ_1);\n}\n</code></pre>"},{"location":"exp3/rpi-os/#maskingunmasking-interrupts","title":"Masking/unmasking interrupts","text":"<p>From time to time, the kernel must mask/unmask ALL interrupts, so that some critical code regions will never be interrupted. For example, what happens if an interrupt occurs right in the middle of <code>kernel_entry</code> macro? The CPU state would be corrupted. </p> <p>Upon entry to ANY exception/interrupt, the processor automatically masks all interrupts so that the kernel can save the CPU state atomically. The kernel then unmasks exceptions (often interrupts) it wants to handle during the execution of the interrupt handler. Right before exiting the exception handling (<code>eret</code>), the kernel masks all interrupts again for atomic CPU state restore. </p> <p>Note: it is perfectly legal to have nested interrupts, i.e. handling another interrupt in the middle of an interrupt handler. Nested interrupts are NOT common: for simple designs, many kernels intentionally keep interrupt handlers very short so they can mask interrupts throughout an interrupt handler without delaying future interrupts too much. However, handling interrupts during exception handlers is VERY common. Syscalls are executed as exception handlers, during which the kernel must be responsive to interrupts. </p> <p>The following two functions (irq.S) mask and unmask interrupts.</p> <pre><code>.globl enable_irq\nenable_irq:\n    msr    daifclr, #2\n    ret\n\n.globl disable_irq\ndisable_irq:\n    msr    daifset, #2\n        ret\n</code></pre> <p>Explanation: ARM processor state (PSTATE) has 4 bits holding mask status for different types of interrupts. </p> <ul> <li>D  Masks debug exceptions. These are a special type of synchronous exceptions. For obvious reasons, it is not possible to mask all synchronous exceptions, but it is convenient to have a separate flag that can mask debug exceptions.</li> <li>A Masks <code>SErrors</code>. It is called <code>A</code> because <code>SErrors</code> sometimes are called asynchronous aborts.</li> <li>I Masks <code>IRQs</code></li> <li>F Masks <code>FIQs</code></li> </ul> <p>Now you can probably guess why registers that are responsible for changing interrupt mask status are called <code>daifclr</code> and <code>daifset</code>. Those registers set and clear interrupt mask status bits in the processor state.</p> <p>Why do we use constant value <code>2</code> in both of the functions? This is because we only want to set and clear the second (<code>I</code>) bit.</p>"},{"location":"exp3/rpi-os/#arms-generic-hardware-timer","title":"Arm's generic hardware timer","text":"<p>We use the Arm generic timer, which is part of Arm64 core design (i.e. not defined by SoC). This is nice, as the generic timers exist for all Armv8 CPUs. Your experiences will apply to other Armv8 SoCs as well. Arm's official webpage (ARM062-1010708621-30) describes the use of generic timers. </p> <p>The following figure shows the generic timer hardware. In a nutshell, a global, chip-level hardware counter (i.e. \"System Counter\") drives per-core timer instances. As hardware boots, System Counter keeps incrementing, i.e. free running. Software can read the current System Counter. But System Counter alone does not generate interrupts. Software must program the timers so that they interrupt corresponding CPU cores at specific time intervals. </p> <p>Note: PE means CPU cores.</p> <p></p> <p>As our kernel only deals with one core, we focus on one timer instance. </p> <p>How should the kernel program the timer? The hardware provides two core registers (among others) as two alternative ways for programming the same timer. </p> <ul> <li>CVAL, a 64-bit comparator. Roughly, this sets a \"threshold\" for System Counter: </li> <li>Example: The kernel writes a value X to CVAL. When System Counter exceeds X, the timer generates an interrupt.</li> <li>TVAL, a 32-bit signed timer value. Roughly, this sets a \"delta\" for System Counter: </li> <li>Example: The kernel writes a value X to TVAL. The hardware updates CVAL +=  the Current System Counter + TVAL. The timer generates an interrupt according to the new CVAL. </li> </ul> <p>The above brief description would suffice in our kernel experiment. Beyond them, TVAL has another less intuitive, \"countdown\" function (not used in this experiment but useful for timekeeping). Since the last write by software, TVAL decrements as System Counter increments. The moment TVAL counts down to 0 is when an interrupt fires. After that, TVAL will keep counting down to a negative value. </p> <p>To summarize: If software needs a timer event in X ticks of the clock, the software can write X to TVAL periodically. Alternatively, if software wants an event when the system count reaches Y, software can write Y to CVAL. If software wants to know the remaining ticks until the next interrupt, the software reads from TVAL.</p>"},{"location":"exp3/rpi-os/#initialize-timer-timers","title":"Initialize timer (timer.S)","text":"<p>By programming the timer device, We turn on the timer and allow it to generate interrupts. </p> <pre><code>gen_timer_init:\n    mov x0, #1\n    msr CNTP_CTL_EL0, x0\n    ret\n</code></pre> <p>This writes 1 to the control register (<code>CNTP_CTL_EL0</code>) of the EL1 physical timer. Google \"ddi0595 CNTP_CTL_EL0\" for the register definition. </p> <p>Note: some students observed that if at the time of writing to CNTP_CTL_EL0 the timer firing condition is met (i.e. TVAL is a negative value), an interrupt will be fired immediately.  If you experience the same thing, you should omit the spurious interrupt.</p> <p>How to interpret the register name \"CNTP_CTL_EL0\": </p> <p>CTL indicates this is a control register; </p> <p>CNTP_XXX_EL0 indicates that this is for the EL1 physical timer. Why _EL0? I guess it means that the timer is accessible to both EL1 and EL0. See the table below. </p> Register Purpose <code>&lt;timer&gt;_CTL_EL&lt;x&gt;</code> Control register <code>&lt;timer&gt;_CVAL_EL&lt;x&gt;</code> Comparator value <code>&lt;timer&gt;_TVAL_EL&lt;x&gt;</code> Timer value Timer name Register prefix <code>EL&lt;x&gt;</code> EL1 physical timer CNTP <code>EL0</code> EL1 virtual time CNTV <code>EL0</code> Non-secure EL2 physical timer CNTHP <code>EL2</code> Non-secure EL2 virtual timer CNTHV <code>EL2</code> EL3 physical timer CNTPS <code>EL1</code> Secure EL2 physical timer CNTHPS <code>EL2</code> Secure EL2 virtual timer CNTHVS <code>EL2</code> <p>(From Arm's generic timer document:)</p> <p>The CNTPCT_EL0 system register reports the current system count value.</p> <p>CNTFRQ_EL0 reports the frequency of the system count. However, this register is not populated by hardware. The register is write-able at the highest implemented Exception level and readable at all Exception levels. Firmware, typically running at EL3, populates this register as part of early system initialization. Higher-level software, like an operating system, can then use the register to get the frequency.</p>"},{"location":"exp3/rpi-os/#turn-on-timer-interrupt-at-the-cpu-core","title":"Turn on timer interrupt at the CPU core","text":"<p>We have to deal with yet another Rpi3 quirk. The Arm generic timer IRQs are wired to a per-core interrupt controller/register. For core 0, this is <code>TIMER_INT_CTRL_0</code> at 0x40000040; bit 1 is for physical timer at EL1 (CNTP). This register is documented in the manual of BCM2836 (search for \"Core timers interrupts\"). Note the manual is NOT for the BCM2837 SoC used by Rpi3. I have no idea how community figured this out. </p> <pre><code>// irq.c \nvoid enable_interrupt_controller()\n{\n    // Enables Core 0 Timers interrupt control for the generic timer \n    put32(TIMER_INT_CTRL_0, TIMER_INT_CTRL_0_VALUE);\n}\n</code></pre> <p>To summarize the above: we have to program three places in order to receive the timer interrupts: the timer device, the per-core interrupt controller, and the core itself (DAIF). </p>"},{"location":"exp3/rpi-os/#handing-timer-interrupts","title":"Handing timer interrupts","text":"<p>The kernel gets an irq. The kernel check if it comes from the timer; if so, the kernel sets the timer for firing the next interrupt. </p> <pre><code>void handle_irq(void) {\n    // Each Core has its own pending local intrrupts register\n    unsigned int irq = get32(INT_SOURCE_0);\n    switch (irq) {\n        case (GENERIC_TIMER_INTERRUPT):\n            handle_generic_timer_irq();\n            break;\n    ...\n</code></pre> <p>The EL1h exception handler invokes the above function. The function reads <code>INT_SOURCE_0</code> (0x4000:0060), search for \"Core interrupt sources\" in the BCM2836 manual), where bit 1 is for our CNTP timer. </p>"},{"location":"exp3/rpi-os/#reset-timer-timers","title":"Reset timer (timer.S)","text":"<p>The kernel writes a delta value (1&lt;&lt;24) to TVAL, requesting an interrupt to fire after 1&lt;&lt;24 ticks. </p> <pre><code>gen_timer_reset:\n    mov x0, #1\n    lsl x0, x0, #24 \n    msr CNTP_TVAL_EL0, x0\n    ret\n</code></pre>"},{"location":"exp3/rpi-os/#fyi-other-timers-on-rpi3","title":"FYI: other timers on Rpi3","text":"<p>There are other timers on Rpi3 which you may see from various online blogs/tutorials/forums. The information can be very confusing. The naming of timers does NOT help. I list them below together with Arm generic timers described above. I suggest you stay away from other timers because the experience will not be as useful. </p> Name Implemented by IRQ QEMU support? (v5.0 ) Phys Addr Document System Timer Broadcom (?) Global. In GPU irq space Implemented as bcm2835_systmr. However free running and cannot generate irq. 3f003000 BCM2837 ARM timer Arm ip (sp804) Global. In Arm core's private irq space (\"Basic irqs\") Unimplemented. See QEMU code bcm2835_peripherals.c 3f00b400 BCM2836 Local timer Broadcom (?) Per core Partially implemented. Can generate trigger irq but readback seems unsupported. 40000034 BCM2836 Arm generic timer Arm, as part of armv8 Per core Implemented 40000040 Armv8 doc +  BCM2836 for IRQ routing"},{"location":"exp3/rpi-os/#fyi-programming-the-rpi3s-system-timer-not-used-in-this-experiment","title":"FYI: Programming the Rpi3's system timer (not used in this experiment)","text":"<p>Raspberry Pi system timer is a very simple device. It has a counter that increases its value by 1 after each clock tick. It also has 4 interrupt lines that connect to the interrupt controller (so it can generate 4 different interrupts)  and 4 corresponding compare registers. When the value of the counter becomes equal to the value stored in one of the compare registers the corresponding interrupt is fired. That's why, before we will be able to use system timer interrupts, we need to initialize one of the compare registers with a non-zero value, the larger the value is - the later an interrupt will be generated. This is done in timer_init function.</p> <pre><code>const unsigned int interval = 200000;\nunsigned int curVal = 0;\n\nvoid timer_init ( void )\n{\n    curVal = get32(TIMER_CLO);\n    curVal += interval;\n    put32(TIMER_C1, curVal);\n}\n</code></pre> <p>The first line reads current counter value, the second line increases it and the third line sets the value of the compare register for the interrupt number 1. By manipulating <code>interval</code> value you can adjust how soon the first timer interrupt will be generated.</p> <p>Finally, we got to the timer interrupt handler. It is actually very simple.</p> <pre><code>void handle_timer_irq( void )\n{\n    curVal += interval;\n    put32(TIMER_C1, curVal);\n    put32(TIMER_CS, TIMER_CS_M1);\n    printf(\"Timer iterrupt received\\n\\r\");\n}\n</code></pre> <p>Here we first update compare register so that that next interrupt will be generated after the same time interval. Next, we acknowledge the interrupt by writing 1 to the <code>TIMER_CS</code> register. In the documentation <code>TIMER_CS</code> is called \"Timer Control/Status\" register. Bits [0:3] of this register can be used to acknowledge interrupts coming from one of the 4 available interrupt lines.</p>"},{"location":"exp3/rpi-os/#conclusion","title":"Conclusion","text":"<p>The last thing that you might want to take a look at is the kernel_main function where all previously discussed functionality is orchestrated. After you compile and run the sample it should print \"Timer interrupt received\" message after an interrupt is taken. Please, try to do it by yourself and don't forget to carefully examine the code and experiment with it.</p>"},{"location":"exp4a/rpi-os/","title":"4a: Cooperative Multitasking","text":"<p>READING TIME: 30MIN</p> <p>Results with UART output: </p> <p></p>"},{"location":"exp4a/rpi-os/#overview","title":"Overview","text":"<p>From this experiment onward, our kernel starts to schedule multiple tasks. This makes it a true \"kernel\" instead of a baremetal program. </p> <p>This experiment focuses on scheduling and task switch. Tasks must voluntarily yield to each other.  We do not need timer interrupts to drive task switch, which is what upcoming experiment (4b) will do. Therefore, in the given code, irqs are turned off by default. </p> <p>However, for assignment you may need to turn irqs back on (e.g. to implement sleep) and take care of irq handling. </p>"},{"location":"exp4a/rpi-os/#roadmap","title":"Roadmap","text":"<p>We will implement: </p> <ol> <li>The <code>task_struct</code> data structure </li> <li>Task creation by manipulating <code>task_struct</code>, registers, and stack</li> <li>Minimalist memory allocation</li> <li>Minimalist task scheduling     </li> </ol> <p>Processes or tasks?. As we do not have virtual memory yet, we use the term \"tasks\" instead of \"processes\". Note: in Linux both thread and processes are just different types of tasks; the difference is in how they share address spaces. </p>"},{"location":"exp4a/rpi-os/#get-the-code","title":"Get the code","text":"<p>Code location: p1-kernel/src/exp4a</p> <p>Please: do a <code>git pull</code> even if you have cloned the p1-kenel repo previously, in case of upstream updates. </p>"},{"location":"exp4a/rpi-os/#key-data-structures","title":"Key data structures","text":"<p> Figure above: an array of pointers to task_structs of tasks </p>"},{"location":"exp4a/rpi-os/#task_struct","title":"task_struct","text":"<p>A struct describing a task. Its name comes from the Linux kernel (again). The code is as follows (<code>sched.h</code>).</p> <pre><code>struct cpu_context {\n    unsigned long x19;\n    unsigned long x20;\n    unsigned long x21;\n    unsigned long x22;\n    unsigned long x23;\n    unsigned long x24;\n    unsigned long x25;\n    unsigned long x26;\n    unsigned long x27;\n    unsigned long x28;\n    unsigned long fp;\n    unsigned long sp;\n    unsigned long pc;\n};\n\nstruct task_struct {\n    struct cpu_context cpu_context;\n    long state;\n    long counter;\n    long priority;\n    long preempt_count;\n};\n</code></pre> <p>This struct has the following members:</p> <ul> <li><code>cpu_context</code> This is a struct that contains values of all registers that might be different between the tasks.</li> <li>Why don't we save all registers, but only <code>x19 - x30</code> and <code>sp</code>? (<code>fp</code> is <code>x29</code> and <code>pc</code> is <code>x30</code>). A short answer: to cater to the Armv8 calling convention. <ul> <li>Because task switch happens only when a task calls cpu_switch_to function. From the point of view of the task that is being scheduled out (i.e. the \"switched-from\" task), it just calls <code>cpu_switch_to</code> function and it returns after some (potentially long) time. </li> <li>The \"switched from\" task is unaware of that another task (i.e. the \"switched-to\" task) happens to runs during this period.  </li> <li>Accordingly to ARM calling conventions registers <code>x0 - x18</code> can be overwritten by the callee (i.e. <code>cpu_switch_to()</code> in our case). Hence, the kernel doesn't have to save the contents of <code>x0 - x18</code> for the caller (the \"switched-from\" task). </li> </ul> </li> <li><code>state</code> The state of the currently running task (NOT <code>PSTATE</code> -- an orthogonal concept). For a task just doing CPU work but not IO, the task state will always be TASK_RUNNING. For now, this is the only state supported by our kernel. </li> <li>Later we add a few additional states. For example, a task waiting for an interrupt should be in a different state, because it doesn't make sense to schedule the task when it is not ready to run yet. </li> <li><code>counter</code> is used to determine how long the current task has been running. <code>counter</code> decreases by 1 each timer tick. When it reaches 0, the kernel will attempt to schedule another task. This supports our simple scheduling algorithm.</li> <li><code>priority</code>  When the kernel schedules a new task, the kernel copies the task's  <code>priority</code> value to <code>counter</code>. In this way, the kernel can regulate the amount of processor time the task gets relative to other tasks.</li> <li><code>preempt_count</code> A flag. A non-zero value means that the current task is executing in a critical code region that cannot be interrupted, e.g. by switching to another task. Any timer tick should be ignored and not triggering rescheduling. </li> </ul> <p>After the kernel startup, there is only one task running: the one that runs kernel_main(). It is called \"init task\". Before the scheduler is enabled, we must fill <code>task_struct</code> of the init task. This is done in <code>INIT_TASK</code>.</p> <p>All <code>task_struct</code>s are stored in <code>task</code> (sched.c) array. This array has only 64 slots - that is the maximum number of simultaneous tasks the kernel can have. It won't suit a production OS, but it is ok for our goals.</p> <p>An important global variable is <code>current</code> (sched.c) that always points to <code>task_struct</code> of currently executing task. Both <code>current</code> and <code>task</code> array are initially set to hold a pointer to the init task. There is also a global variable <code>nr_task</code> - it contains the number of currently running tasks in the system.</p>"},{"location":"exp4a/rpi-os/#task-switch","title":"Task switch","text":""},{"location":"exp4a/rpi-os/#preparing-task_structs-kernelc","title":"Preparing task_structs (kernel.c)","text":"<pre><code>void kernel_main(void)\n{\n    uart_init();\n    init_printf(0, putc);\n    irq_vector_init();\n\n    int res = copy_process((unsigned long)&amp;process, (unsigned long)\"12345\");\n    if (res != 0) {\n        printf(\"error while starting process 1\");\n        return;\n    }\n    res = copy_process((unsigned long)&amp;process, (unsigned long)\"abcde\");\n    if (res != 0) {\n        printf(\"error while starting process 2\");\n        return;\n    }\n\n    while (1){\n        schedule();\n    }\n}\n</code></pre> <ol> <li> <p>A new function <code>copy_process</code> is introduced. <code>copy_process</code> takes 2 arguments: a function to execute in a new thread and an argument passed to this function. <code>copy_process</code> allocates a new <code>task_struct</code>  and makes it available for the scheduler.</p> </li> <li> <p>Another new function <code>schedule</code>. This is the core scheduler function: it checks whether there is a new task that needs to preempt the current one. In cooperative scheduling, a task voluntarily calls <code>schedule</code> if it doesn't have any work to do at the moment. </p> </li> </ol> <p>For preemptive multitasking, <code>schedule</code> is also called from the timer interrupt handler.</p> <p>Try your self with QEMU: set a breakpoint at copy_process &amp; launch the kernel. Examine task_struct with <code>print *p</code>. Examine the value of cpu_context.[pc|sp|fn|arg]. </p> <p>We are calling <code>copy_process</code> 2 times, each time passing a pointer to the process function as the first argument.</p> <p><code>process</code> function is very simple.</p> <pre><code>void process(char *array)\n{\n    while (1){\n        for (int i = 0; i &lt; 5; i++){\n            uart_send(array[i]);\n            delay(100000);\n            schedule();\n        }\n    }\n}\n</code></pre> <p>It just keeps printing characters from the array, which is passed as an argument. Task 1 is created with the argument \"12345\" and task 2 is with the argument \"abcde\". After printing out a string, a task yields to others by calling <code>schedule()</code>. If our scheduler implementation is correct, both threads will take turns to print strings. </p>"},{"location":"exp4a/rpi-os/#switching-tasks-schedc-scheds","title":"Switching tasks (sched.c &amp; sched.S)","text":"<p>This is where the magic happens. The code looks like this.</p> <pre><code>void switch_to(struct task_struct * next)\n{\n    if (current == next)\n        return;\n    struct task_struct * prev = current;\n    current = next;\n    cpu_switch_to(prev, next);\n}\n</code></pre> <p>If the \"next\" process is not the same as the \"current\",  the kernel updates <code>current</code>. The <code>cpu_switch_to</code> function is where the real context switch happens. To manipulates registers, it is in assembly. </p> <pre><code>.globl cpu_switch_to\ncpu_switch_to:\n    mov    x10, #THREAD_CPU_CONTEXT\n    add    x8, x0, x10\n    mov    x9, sp\n    stp    x19, x20, [x8], #16        // store callee-saved registers\n    stp    x21, x22, [x8], #16\n    stp    x23, x24, [x8], #16\n    stp    x25, x26, [x8], #16\n    stp    x27, x28, [x8], #16\n    stp    x29, x9, [x8], #16\n    str    x30, [x8]\n    add    x8, x1, x10\n    ldp    x19, x20, [x8], #16        // restore callee-saved registers\n    ldp    x21, x22, [x8], #16\n    ldp    x23, x24, [x8], #16\n    ldp    x25, x26, [x8], #16\n    ldp    x27, x28, [x8], #16\n    ldp    x29, x9, [x8], #16\n    ldr    x30, [x8]\n    mov    sp, x9\n    ret\n</code></pre> <p>Let's examine it line by line.</p> <pre><code>    mov    x10, #THREAD_CPU_CONTEXT\n    add    x8, x0, x10\n</code></pre> <p><code>THREAD_CPU_CONTEXT</code> constant contains offset of the <code>cpu_context</code> structure in the <code>task_struct</code> (the offset is 0 in the current implementation). <code>x0</code> contains a pointer to the first argument, which is the current <code>task_struct</code> (i.e. the \"switch-from\" task).  After the copied 2 lines are executed, <code>x8</code> will contain a pointer to the current <code>cpu_context</code>.</p> <pre><code>    mov    x9, sp\n    stp    x19, x20, [x8], #16        // store callee-saved registers\n    stp    x21, x22, [x8], #16\n    stp    x23, x24, [x8], #16\n    stp    x25, x26, [x8], #16\n    stp    x27, x28, [x8], #16\n    stp    x29, x9, [x8], #16\n    str    x30, [x8]\n</code></pre> <p></p> <p>The figure above: During context switch, registers are being saved to task_struct.context</p> <p>Above: all callee-saved registers are stored in the order, in which they are defined in <code>cpu_context</code> structure. The current stack pointer is saved as <code>cpu_context.sp</code> and <code>x29</code> is saved as <code>cpu_context.fp</code> (frame pointer).</p> <p>Note: <code>x30</code>, the link register containing function return address, is stored as <code>cpu_context.pc</code>. Why?</p> <p>Now we calculate the address of the next task's <code>cpu_context</code>: </p> <pre><code>    add    x8, x1, x10\n</code></pre> <p>This a cute hack. <code>x10</code> contains <code>THREAD_CPU_CONTEXT</code> , the offset of the <code>cpu_context</code> structure inside <code>task_struct</code>. <code>x1</code> is a pointer to the next <code>task_struct</code>, so <code>x8</code> will contain a pointer to the next <code>cpu_context</code>.</p> <p>Now, restore the CPU context of \"switch_to\" task from memory to CPU registers. A mirror procedure. </p> <pre><code>    ldp    x19, x20, [x8], #16        // restore callee-saved registers\n    ldp    x21, x22, [x8], #16\n    ldp    x23, x24, [x8], #16\n    ldp    x25, x26, [x8], #16\n    ldp    x27, x28, [x8], #16\n    ldp    x29, x9, [x8], #16\n    ldr    x30, [x8]\n    mov    sp, x9\n    ret\n</code></pre> <p>The <code>ret</code> instruction will jump to the location pointed to by the link register (<code>x30</code>). If we are switching to a task for the first time, this will be the beginning of the <code>ret_from_fork</code> function. More on that below. In all other cases this will be the location previously saved in the <code>cpu_context.pc</code> by the <code>cpu_switch_to</code> function. Think: which instruction does it point to? </p>"},{"location":"exp4a/rpi-os/#launching-a-new-task","title":"Launching a new task","text":"<p>New task creation is implemented in the copy_process function.</p> <p>Keep in mind: after <code>copy_process</code> finishes execution, no context switch happens yet. The function only prepares new <code>task_struct</code> and adds it to the <code>task</code> array \u2014 this task will be executed only after <code>schedule</code> function is called.</p> <pre><code>int copy_process(unsigned long fn, unsigned long arg)\n{\n    struct task_struct *p;\n\n    p = (struct task_struct *) get_free_page();\n    if (!p)\n        return 1;\n    p-&gt;priority = current-&gt;priority;\n    p-&gt;state = TASK_RUNNING;\n    p-&gt;counter = p-&gt;priority;\n\n    p-&gt;cpu_context.x19 = fn;\n    p-&gt;cpu_context.x20 = arg;\n    p-&gt;cpu_context.pc = (unsigned long)ret_from_fork;\n    p-&gt;cpu_context.sp = (unsigned long)p + THREAD_SIZE;\n    int pid = nr_tasks++;\n    task[pid] = p;\n    return 0;\n}\n</code></pre> <p>We examine it in details.</p> <pre><code>    struct task_struct *p;\n</code></pre> <p>The function starts with allocating a pointer for the new task. As interrupts are off, the kernel will not be interrupted in the middle of the <code>copy_process</code> function.</p> <pre><code>    p = (struct task_struct *) get_free_page();\n    if (!p)\n        return 1;\n</code></pre> <p>Next, a new page is allocated. At the bottom of this page, we are putting the <code>task_struct</code> for the newly created task. The rest of this page will be used as the task stack. A few lines below, <code>context.sp</code> is set as <code>p + THREAD_SIZE</code>. THREAD_SIZE is defined as 4KB. It is the total amount of kernel memory for a task. The name, again, is following the Linux kernel convention. </p> Figure above: a task's task_struct in relative to its stack space <pre><code>    p-&gt;priority = current-&gt;priority;\n    p-&gt;state = TASK_RUNNING;\n    p-&gt;counter = p-&gt;priority;\n</code></pre> <p>After the <code>task_struct</code> is allocated, we can initialize its properties.  Priority and initial counters are set based on the current task priority. </p> <pre><code>    p-&gt;cpu_context.x19 = fn;\n    p-&gt;cpu_context.x20 = arg;\n    p-&gt;cpu_context.pc = (unsigned long)ret_from_fork;\n    p-&gt;cpu_context.sp = (unsigned long)p + THREAD_SIZE;\n</code></pre> <p>This is the most important part of the function. Here <code>cpu_context</code> is initialized. The stack pointer is set to the top of the newly allocated memory page (see the figure above). <code>pc</code>  is set to the ret_from_fork function. Details below. </p>"},{"location":"exp4a/rpi-os/#ret_from_fork-entrys","title":"ret_from_fork (entry.S)","text":"<p>This is the first piece of code executed by a newly created process. A new process P executes <code>ret_from_fork</code> after it is switched to for the first time. That is right after the scheduler picks P for the first time and restores P's CPU context from <code>task_struct</code> to CPU registers. Throughout its lifetime, P only executes <code>ret_from_fork</code> once. </p> <p>About naming: despite the name \"fork\", we are not doing fork() as in Linux/Unix. We are simply copying a <code>task_struct</code> while fork() does far more things like duplicating process address spaces. The naming follows the Linux kernel convention; and we will evolve our <code>ret_from_fork</code> in subsequent experiments. </p> <pre><code>.globl ret_from_fork\nret_from_fork:\n    bl    schedule_tail // will talk about this later\n    mov    x0, x20\n    blr    x19         //should never return\n</code></pre> <p>What are the initial values of <code>x19</code> and <code>x20</code>? See code <code>copy_process</code> above, which saves <code>fn</code> (the process's main function) and <code>arg</code> (the argument passed to the process) to<code>task_struct.x19</code> and <code>x20</code>. When switching to P, the kernel restores <code>fn</code> and <code>arg</code> from <code>task_struct</code> to <code>x19</code> and <code>x20</code>. And here we are:  <code>ret_from_fork</code> calls the function stored in <code>x19</code> register with the argument stored in <code>x20</code>. </p> <p>:wrench:Try your self with QEMU+GDB: set a breakpoint at ret_from_fork, launch the kernel, and single step into the new process function. </p>"},{"location":"exp4a/rpi-os/#memory-allocation","title":"Memory allocation","text":"<p>Each task in the system should have its dedicated stack. That's why when creating a new task we must have a way to allocate memory. For now, our memory allocator is extremely primitive. (The implementation can be found in mm.c file)</p> <pre><code>static unsigned short mem_map [ PAGING_PAGES ] = {0,};\n\nunsigned long get_free_page()\n{\n    for (int i = 0; i &lt; PAGING_PAGES; i++){\n        if (mem_map[i] == 0){\n            mem_map[i] = 1;\n            return LOW_MEMORY + i*PAGE_SIZE;\n        }\n    }\n    return 0;\n}\n\nvoid free_page(unsigned long p){\n    mem_map[(p - LOW_MEMORY) / PAGE_SIZE] = 0;\n}\n</code></pre> <p>:wrench: Try it yourself with QEMU: <code>ptype mem_map</code> then <code>print (short[10])*mem_map</code>. </p> <p>The allocator can work only with memory pages (each page is 4 KB in size). There is an array called <code>mem_map</code> that for each page in the system holds its status: whether it is allocated or free. Whenever we need to allocate a new page, we just loop through this array and return the first free page. This implementation is based on 2 assumptions:</p> <ol> <li>We know the total amount of memory in the system. It is <code>1 GB - 1 MB</code> (the last megabyte of memory is reserved for device registers.). This value is stored in the HIGH_MEMORY constant.</li> <li>First 4 MB of memory are reserved for the kernel image and init task stack. This value is stored in the LOW_MEMORY constant. All memory allocations start right after this point.</li> </ol> <p>Note: even with QEMU our kernel must start from 0x80000 (512KB), the above assumptions are good as there's still plenty room in 512KB -- LOW_MEMORY for our tiny kernel.</p>"},{"location":"exp4a/rpi-os/#the-scheduler","title":"The scheduler","text":"<p>Finally, we are ready to look at the scheduler algorithm. We almost precisely copied this algorithm from the first release of the Linux kernel. </p> <pre><code>void _schedule(void)\n{\n    int next,c;\n    struct task_struct * p;\n    while (1) {\n        c = -1;\n        next = 0;\n        // try to pick a task\n        for (int i = 0; i &lt; NR_TASKS; i++){\n            p = task[i];\n            if (p &amp;&amp; p-&gt;state == TASK_RUNNING &amp;&amp; p-&gt;counter &gt; c) {\n                c = p-&gt;counter;\n                next = i;\n            }\n        }\n        if (c) {\n            break;\n        }\n        // update counters\n        for (int i = 0; i &lt; NR_TASKS; i++) {\n            p = task[i];\n            if (p) {\n                p-&gt;counter = (p-&gt;counter &gt;&gt; 1) + p-&gt;priority;\n            }\n        }\n    }\n    switch_to(task[next]);\n}\n</code></pre> <p>The simple algorithm works like the following:</p> <ul> <li> <p>The first <code>for</code> loop iterates over all tasks and tries to find a task in <code>TASK_RUNNING</code> state with the maximum counter. If such a task is found, we immediately break from the <code>while</code> loop and switch to this task. </p> </li> <li> <p>If no such task is found, this is either because i) no task is in <code>TASK_RUNNING</code>  state or ii) all such tasks have 0 counters. In a real OS, i) might happen, for example, when all tasks are waiting for an interrupt. In our current tiny kernel, all tasks are always in <code>TASK_RUNNING</code> (Why?) </p> </li> <li> <p>The scheduler moves to the 2nd <code>for</code> loop to \"recharge\" counters. It bumps counters for all tasks once. The increment depends on a task's priority. Note: a task counter can never get larger than <code>2 * priority</code>.</p> </li> <li> <p>With updated counters, the scheduler goes back to the 1st <code>for</code> loop to pick a task. </p> </li> </ul> <p>We will augment the scheduling algorithm for preemptive multitasking later. </p>"},{"location":"exp4a/rpi-os/#conclusion","title":"Conclusion","text":"<p>We have seen important nuts &amp; bolts of multitasking. The subsequent experiment will enable task preemption. We will show a detailed workflow of context switch there. </p>"},{"location":"exp4a/rpi-os/#one-more-thing","title":"One more thing ...","text":"<p>There's support for a graphical console. Works for both QEMU and Rpi3. Display required. See instructions. </p> <p></p>"},{"location":"exp4b/rpi-os/","title":"4b: Preemptive Multitasking","text":"<p>READING TIME: 40MIN</p>"},{"location":"exp4b/rpi-os/#objectives","title":"Objectives","text":"<p>A minimum kernel that can schedule multiple tasks in a preemptive fashion. With this experiment, our tiny kernel is more like a \"real-time kernel\" commonly seen in embedded systems, e.g. FreeRTOS.</p> <ol> <li>Preempt tasks with time interrupts</li> <li>Understand context switch driven by interrupts, in particular switch to/from interrupt handlers</li> <li>Atomic kernel regions where preemption is disallowed </li> </ol>"},{"location":"exp4b/rpi-os/#get-the-code","title":"Get the code","text":"<p>Code location: p1-kernel/src/exp4b</p> <p>Please: do a <code>git pull</code> even if you have cloned the p1-kenel repo previously, in case of upstream updates. </p>"},{"location":"exp4b/rpi-os/#roadmap","title":"Roadmap","text":"<p>We will turn on timer interrupts. In the interrupt handler, our kernel invokes its scheduler to switch among runnable tasks. </p> <p>In addition to <code>switch_to</code>, the kernel should save &amp; restore CPU state upon entering/existing interrupt handling. </p>"},{"location":"exp4b/rpi-os/#turn-on-timer-interrupts","title":"Turn on timer interrupts!","text":"<p>We turn on timer interrupts in <code>kernel_main</code>. </p> <pre><code>void kernel_main(void) {\n    uart_init();\n    init_printf(0, putc);\n    irq_vector_init();\n    timer_init(); \n    enable_interrupt_controller(); \n    enable_irq(); /* new addition */\n    ... \n}\n</code></pre> <p>With that, tasks no longer need to call schedule() voluntarily. </p> <pre><code>void process(char *array)\n{\n    while (1){\n        for (int i = 0; i &lt; 5; i++){\n            uart_send(array[i]);\n            delay(100000);\n        }\n        // schedule(); // not needed\n    }\n}\n</code></pre>"},{"location":"exp4b/rpi-os/#calling-schedule-in-timer-tick","title":"Calling <code>schedule()</code> in timer tick","text":"<p>With preemptive scheduling, schedule() are called in two places. </p> <ol> <li>A task can call <code>schedule</code> voluntarily (as in cooperative scheduling). </li> <li>On a regular basis from the timer interrupt handler.</li> </ol> <p>Look at <code>timer_tick()</code>, which is called from the timer interrupt.</p> <pre><code>void timer_tick()\n{\n    --current-&gt;counter;\n    if (current-&gt;counter&gt;0 || current-&gt;preempt_count &gt;0) {\n        return;\n    }\n    current-&gt;counter=0;\n    enable_irq();\n    _schedule();\n    disable_irq();\n    ... \n</code></pre> <p>First of all, it decreases current task's counter. If the counter is greater than 0 or preemption is currently disabled the function returns. Otherwise<code>schedule</code> is called with interrupts enabled. (Note: we just came from an interrupt handler and CPU just automatically disabled all interrupts.) </p> <p>Why interrupts must be enabled in the scheduler? More on this later. </p>"},{"location":"exp4b/rpi-os/#how-scheduling-works-with-interrupt-entryexit","title":"How scheduling works with interrupt entry/exit?","text":"<p>With preemptive scheduling, the kernel must save &amp; restore CPU contexts for the task being interrupted. This is because, e.g. a task A may be interrupted at any point and get preempted (i.e. \"losing CPU\"). Later, when the kernel reschedules A, A should resume from where it was interrupted. </p> <p>Refresh your memory: in previous baremetal experiments with no multitasking, we have seen how kernel_entry and kernel_exit macros save and restore general-purpose CPU regs upon switch to/from an interrupt/exception handler. There, we rely on that the hardware automatically saves exception return address and CPU status in registers, <code>elr_el1</code> register and <code>spsr_el</code> register. When <code>eret</code> is executed, CPU restores execution from these registers.</p> <p></p> <p>Figure above: in previous experiments w/o multitasking, save/restore registers upon entering/leaving irq handlers. </p> <p>With multitasking, the kernel now has to create per-task copies of CPU context in memory: ALL general-purpose registers plus <code>elr_el1</code> and <code>spsr_el</code>. </p> <p>Where to store the CPU context? </p> <p>We choose to store the CPU context on the current task's stack (NOT in its <code>task_struct.cpu_context</code>). There are alternative designs to be examined later. </p>"},{"location":"exp4b/rpi-os/#an-example-workflow","title":"An example workflow","text":"<p>Kernel boots</p> <p>kernel_main function is executed (as init task, task0). The initial stack is configured to start at LOW_MEMORY, which is at 0x0040:0000 (4 MB).</p>"},{"location":"exp4b/rpi-os/#_1","title":"exp4b","text":"<p>Task 1 creation</p> <p><code>kernel_main</code> calls <code>copy_process</code> for the first time. A new 4 KB page is allocated, and <code>task_struct</code> is placed at the bottom of this page. </p> <p></p> <p>Task 2 creation</p> <p><code>kernel_main</code> calls <code>copy_process</code> for the second time and the same process repeats. Task 2 is created and added to the task list. </p> <p>Switching to task 1; task 1 runs</p> <p><code>kernel_main</code> (as init task) calls the schedule function and it decides to switch to task 1.</p> <ul> <li><code>cpu_switch_to</code> saves callee-saved registers in the init task <code>cpu_context</code>, which is located inside the kernel image.</li> <li><code>cpu_switch_to</code> restores callee-saved registers from task 1's <code>task_struct</code>.  At this point, <code>cpu_context.sp</code> points to <code>0x00401000</code>, lr points to ret_from_fork function, <code>x19</code> contains a pointer to the start of process() and <code>x20</code> a pointer to string \"12345\", which is located somewhere in the kernel image.</li> <li><code>cpu_switch_to</code> executes  <code>ret</code>, which jumps to the <code>ret_from_fork</code> function.</li> <li><code>ret_from_fork</code> reads <code>x19</code> and <code>x20</code> registers and  calls <code>process</code> function with the argument \"12345\". </li> <li>After <code>process</code> function starts, the stack of task 1 begins to grow.</li> </ul> <p></p> <p>While task 1 runs, a timer interrupt occurred</p> <ul> <li><code>kernel_entry</code> saves all general purpose registers &amp; <code>elr_el1</code> and <code>spsr_el1</code> to the bottom of task 1 stack (\"saved regs\" in the figure below).</li> <li>The kernel now executes in the irq context. It continues to grow the current stack which belongs to task 1. The growth is below the \"saved regs\" region and is marked as \"irq frame\" on the figure (i.e. the stack frame created by the execution in the irq context). </li> <li>The kernel proceeds to <code>schedule</code> and picks task 2. </li> </ul> <p></p> <p>Switching to task 2; task 2 runs</p> <p><code>cpu_switch_to</code> executes exactly the same sequence of steps that it does for task 1. Task 2 started to execute and it stack grows. </p> <p></p> <p>Note: until now, the kernel has NOT executed <code>eret</code> for the previous timer irq. This is fine as an intentional choice made for this experiment. </p> <p>How can we execute task 2 in the context of the previous irq? This is allowed because ARM64 CPU does not differentiate execution in an irq context vs. in an exception (i.e. syscall) context. All the CPU knows is the current EL (we always stay at EL1 before/after the irq) and the irq enable status. And irqs have been enabled previously in timer_tick before <code>schedule</code> was called. </p> <p>Nevertheless, there's a more common design in which the kernel finishes the previous irq handling (i.e. 'eret') before switching to a new task. See \"alternative design\" below. </p> <p>Another timer interrupt occurred while task 2 is running</p> <p>Same as above, <code>kernel_entry</code> saves all general purpose registers + <code>elr_el1</code> and <code>spsr_el1</code> at the bottom of task 2's stack. Task 2's irq frame begins to grow.</p> <p></p> <p>Scheduling out task 2</p> <p>The kernel calls <code>schedule()</code>. It observes that all tasks have their counters set to 0 and set counters to their tasks priorities.</p> <p><code>schedule</code> selects init task to run. (This is because all tasks now have their counters set to 1 and init task is the first in the list). But actually, it would be fully legal for <code>schedule</code> to select task 1 or task 2 at this point, because their counters has equal values. We are more interested in the case when task 1 is selected so let's now assume that this is what had happened.</p> <p>Switching to task 1, exiting from the 1st irq</p> <ol> <li><code>cpu_switch_to</code> is called and it restores previously saved callee-saved registers from task 1 <code>cpu_context</code>. Link register now points to the instruction right after <code>cpu_switch_to</code>, which was called last time when task 1 was executed. <code>sp</code> points to the bottom of task 1 interrupt stack. This is because task 1 finished handling the previous interrupt handler. </li> <li>From <code>cpu_switch_to</code>, task1 returns back to <code>switch_to</code>, to <code>_schedule</code>, and then to <code>timer_tick</code>. There, it disables interrupts and finally executes <code>kernel_exit</code>. There, task 1 irq frame (including the save regs) is unwound. </li> </ol> <p></p> <p>Task 1 resumes normal execution</p> <p><code>kernel_exit</code> restores all general purpose registers as well as <code>elr_el1</code> and <code>spsr_el1</code>. <code>elr_el1</code> now points somewhere in the middle of the <code>process</code> function. <code>sp</code> points to the bottom of task 1 stack. (Note: the remaining task size depends on the size  of local variables in <code>process</code> )</p> <p></p> <p>Finally, <code>kernel_exit</code> executes <code>eret</code> instruction which uses <code>elr_el1</code> register to jump back to <code>process</code> function. Task 1 resumes it normal execution!</p>"},{"location":"exp4b/rpi-os/#aside-an-alternative-design","title":"Aside: An alternative design","text":"<ul> <li> <p>When an interrupt happens, the CPU saves irq stack frame automatically on the stack of the current task, e.g. A. This is the same as the design above. </p> </li> <li> <p>The kernel copies the auto saved register contents from the irq frame to the current task's <code>task_struct</code>, representing the CPU context when this task was interrupted by irq. </p> </li> <li>The kernel calls its scheduler and returns from the irq (possibly to a different task). The irq stack on the A's stack is then unwound. Now irq is on. Later, when A is scheduled in, the kernel restores its CPU context from A's <code>task_struct</code>. </li> </ul> <p>Can you implement the alternative design? </p>"},{"location":"exp4b/rpi-os/#disable-preemption","title":"Disable preemption","text":"<p>The kernel needs mechanism to (temporarily) disable preemption. </p> <p>Example: in creating a new <code>task_struct</code>, we do not want rescheduling to happen. Otherwise the scheduler may see an incomplete <code>task_struct</code>. In other words, the creation of <code>task_struct</code> should be atomic. </p> <p>To disable preemption, one method is to disable interrupts. Beyond that, the kernel also needs fine-grained control. </p>"},{"location":"exp4b/rpi-os/#per-task-preempt_count","title":"Per-task <code>preempt_count</code>","text":"<p>To <code>task_struct</code>, we add: </p> <pre><code>struct task_struct {\n    struct cpu_context cpu_context;\n    long state;\n    long counter;\n    long priority;\n    long preempt_count; // new addition\n};\n</code></pre> <p><code>preempt_count</code> &gt;0  indicates that right now the current task is non-preemptable. The following two functions operate on it: </p> <pre><code>void preempt_disable(void) { current-&gt;preempt_count++;}\nvoid preempt_enable(void) { current-&gt;preempt_count--;}\n</code></pre> <p>Seeing this flag, the kernel will not invoke scheduler() at all, let alone descheduling this task (i.e. switching to a different task). This is done via the following code. </p> <pre><code>void timer_tick() {\n    if (current-&gt;counter&gt;0 || current-&gt;preempt_count &gt;0) \n        return; \n...\n</code></pre> <p>Why a count instead of a binary flag? This again mimics the Linux implementation. Individual kernel functions could increment &amp; decrement <code>preempt_count</code>. If all kernel functions have finished decrementing <code>preempt_count</code>, the count drops to zero and the scheduler is free to deschedule the task. This mechanism is called reference count, which is common in system software. </p> <p><code>preempt_count</code> does not prevent a task from shooting in its own foot, though. For instance, a misbehaving task calling schedule() when <code>preempt_count</code> &gt; 0 will likely corrupt kernel data structures. Try it out! </p>"},{"location":"exp4b/rpi-os/#creating-a-task_struct-atomically","title":"Creating a <code>task_struct</code> atomically","text":"<p>Going back to making <code>copy_process</code> atomic: </p> <pre><code>int copy_process(unsigned long fn, unsigned long arg)\n{\n    preempt_disable(); /* new addition */\n    struct task_struct *p;\n\n    p = (struct task_struct *) get_free_page();\n    if (!p)\n        return 1;\n    p-&gt;priority = current-&gt;priority;\n    p-&gt;state = TASK_RUNNING;\n    p-&gt;counter = p-&gt;priority;\n    p-&gt;preempt_count = 1; // new addition \n\n    p-&gt;cpu_context.x19 = fn;\n    p-&gt;cpu_context.x20 = arg;\n    p-&gt;cpu_context.pc = (unsigned long)ret_from_fork;\n    p-&gt;cpu_context.sp = (unsigned long)p + THREAD_SIZE;\n    int pid = nr_tasks++;\n    task[pid] = p;\n    preempt_enable(); /* new addition */\n    return 0;\n}\n</code></pre> <p><code>preempt_count</code> is set to 1, preventing the new task, once it starts to execute, from being preempted until it completes some initialization work. After that, the new task executes <code>ret_from_fork</code>, which calls <code>schedule_tail()</code> which will call <code>preempt_enable()</code> </p> <pre><code>// entry.S\n.globl ret_from_fork\nret_from_fork:\n    bl  schedule_tail\n    ...\n</code></pre>"},{"location":"exp4b/rpi-os/#making-the-scheduling-algorithm-atomic","title":"Making the scheduling algorithm atomic","text":"<p>The scheduler is non-reentrant. Making it atomic looks easy: we just call <code>preempt_disable/enable()</code> upon entering/leaving the scheduler. </p> <pre><code>void _schedule(void)\n{\n    preempt_disable(); /* new addition */\n    int next,c;\n    struct task_struct * p;\n    while (1) {\n        c = -1;\n        next = 0;\n        for (int i = 0; i &lt; NR_TASKS; i++){\n            p = task[i];\n            if (p &amp;&amp; p-&gt;state == TASK_RUNNING &amp;&amp; p-&gt;counter &gt; c) {\n                c = p-&gt;counter;\n                next = i;\n            }\n        }\n        if (c) {\n            break;\n        }\n        for (int i = 0; i &lt; NR_TASKS; i++) {\n            p = task[i];\n            if (p) {\n                p-&gt;counter = (p-&gt;counter &gt;&gt; 1) + p-&gt;priority;\n            }\n        }\n    }\n    switch_to(task[next]);\n    preempt_enable(); /* new addition */\n}\n</code></pre> <p>Why does the kernel disable preemption, instead of disabling all interrupts?</p> <p>By design, if no <code>TASK_RUNNING</code> tasks are there, the scheduler will run its while loop over and over again until some of the tasks will move to <code>TASK_RUNNING</code> state. But if we are running on a single CPU, how then a task state can change while this loop is running? The answer is that if some task is waiting for an interrupt, this interrupt can happen while <code>schedule</code> function is executed and interrupt handler can change the state of the task. </p> <p>This actually explains why interrupts must be enabled during <code>schedule</code> execution. This also demonstrates an important distinction between disabling interrupts and disabling preemption. <code>schedule</code> disables preemption for the duration of the whole function. This ensures that nested <code>schedule</code> will not be called while we are in the middle of the original function execution. However, interrupts can legally happen during <code>schedule</code> function execution.</p> <p>Note: our kernel does not (yet) have the mechanism for tasks to wait for interrupts. It's a important mechanism to be added. </p> <p>I am not very satisfied with leaving interrupt on during schedule(). There shall be an idle task which does <code>WFI</code> when no other tasks are runnable. In that way, the scheduler can avoid spinning and can run with interrupt off. To implement the idle task, the kernel shall implement task wait state. </p>"},{"location":"exp4b/rpi-os/#conclusion","title":"Conclusion","text":"<p>We are done with scheduling, but right now our kernel can manage only kernel threads: they are executed at EL1 and can directly access any kernel functions or data. In the next 2 lessons we are going fix this and introduce system calls and virtual memory.</p>"},{"location":"exp5/rpi-os/","title":"5: User processes and system calls","text":"<p>READING TIME: 40MIN</p> <p></p>"},{"location":"exp5/rpi-os/#objectives","title":"Objectives","text":"<p>Our kernel is evolving from an \"embedded\" kernel which often lacks user/kernel separation to a multiprogrammed kernel. </p> <ul> <li> <p>Run tasks in EL0</p> </li> <li> <p>Add the syscall mechanism</p> </li> <li> <p>Implement a few basic syscalls</p> </li> </ul> <p>NOTE: this experiment enables running user/kernel at different ELs. Yet, it does not NOT give each task its own address space \u2014 we are going to tackle this issue in lesson 6!</p>"},{"location":"exp5/rpi-os/#get-the-code","title":"Get the code","text":"<p>Code location: p1-kernel/src/exp5</p> <p>Please: do a <code>git pull</code> even if you have cloned the p1-kenel repo previously, in case of upstream updates. </p>"},{"location":"exp5/rpi-os/#roadmap","title":"Roadmap","text":"<ol> <li>Implement the syscall mechanism, in particular switch between EL0 and EL1 (you have already done something similar in previous experiments!)</li> <li>Implement two mechanisms that put user tasks to EL0: (a) forking an existing user task at EL0; (b) moving a kernel task EL1 -&gt; EL0</li> </ol>"},{"location":"exp5/rpi-os/#syscall-implementation","title":"Syscall implementation","text":"<p>Each system call is a synchronous exception. A user program prepares all necessary arguments, and then runs <code>svc</code> instruction. Such exceptions are handled at EL1 by the kernel. The kernel validates all arguments, does the syscall, and exits from the exception. After that, the user task resumes at EL0 right after the <code>svc</code> instruction. </p> <ul> <li>EL0 files: sys.h and sys.S</li> <li>EL1 files: sys.h and sys.c</li> </ul> <p></p> <p>We have 4 simple syscalls (cf. sys.h): </p> <ol> <li><code>write</code> outputs to UART. It accepts a buffer with the text to be printed as the first argument.</li> <li><code>clone</code> creates a new user thread. The location of the stack for the newly created thread is passed as the first argument.</li> <li><code>malloc</code> allocates a memory page for a user process. There is no analog of this syscall in Linux (and I think in any other OS as well.) The only reason that we have no virtual memory yet, and all user processes work with physical memory addresses. Each process needs a way to figure out which memory page can be used. <code>malloc</code> returns pointer to the newly allocated page or -1 in case of an error.</li> <li><code>exit</code> Each process must call this syscall after it finishes execution. It will do cleanup.</li> </ol> <p>An array sys_call_table (sys.c) contains pointers to all syscall handlers. Each syscall has a \"syscall number\" \u2014 this is just an index in the <code>sys_call_table</code> array. All syscall numbers are defined here \u2014 they are used by the assembler code to look up syscall. </p> <p>Let's use <code>write</code> syscall as an example: </p> <pre><code>//sys.S, executed at the user level\n.globl call_sys_write\ncall_sys_write:\n    mov w8, #SYS_WRITE_NUMBER\n    svc #0\n    ret\n</code></pre> <p>The wrapper stores the syscall number in the <code>w8</code> register and does <code>svc</code>. Convention: registers <code>x0</code> \u2014 <code>x7</code>are used for syscall arguments and <code>x8</code> is used to store syscall number. This allows a syscall to have up to 8 arguments.</p> <p>In commodity OSes, such wrapper functions are usually in user library such as glibc but not in the kernel. </p>"},{"location":"exp5/rpi-os/#switching-between-el0-and-el1","title":"Switching between EL0 and EL1","text":"<p>Our kernel should support switches between EL1/EL1, and between EL1/EL0. </p> <p>Previously, our kernel runs at EL1; when an interrupt occurs, it takes the interrupt at EL1. Now, we need to take exception (svc) from EL0 to EL1. To accommodate this, both <code>kernel_entry</code> and <code>kernel_exit</code> macros accepts an additional argument <code>el</code>, indicating the EL an exception is taken from. The information is required to properly save/restore stack pointer. </p> <pre><code>// kernel_entry (entry.S)\n.if    \\el == 0\nmrs    x21, sp_el0\n.else\nadd    x21, sp, #S_FRAME_SIZE\n.endif \n</code></pre> <pre><code>// kernel_exit\n.if    \\el == 0\nmsr    sp_el0, x21\n.endif \n...\neret\n</code></pre> <p>Even for the same task, we are using 2 distinct stacks for EL0 and EL1. This is needed to separate user/kernel. </p> <p>Supported by CPU hardware, after taking an exception from EL0 to EL1, the CPU automatically starts use the SP for EL1. The SP for EL0 can be found in the <code>sp_el0</code> register. </p> <p>The value of this register must be stored and restored upon entering/exiting the kernel, even if the kernel does not  use <code>sp_el0</code> in the exception handler. Reason: we need to virtualize <code>sp_el0</code> for each task because each task has its own user stack. Try to visualize this in your mind. </p> <p>When we do <code>kernel_exit</code>,  the EL to return to (EL0 or EL1) is encoded in the <code>spsr_el1</code> register that was saved, e.g. when syscall enters the kernel. So we always return to the level from which the exception was taken.</p> <p>How did we treat SP when taking interrupts (from EL1)? Revisit the figures in previous experiments. </p>"},{"location":"exp5/rpi-os/#handling-synchronous-exceptions","title":"Handling synchronous exceptions","text":"<p>In the exception table, <code>el0_sync</code> is registered as the handler for sync exception taken at EL0. </p> <pre><code>// entry.S\nel0_sync:\n    kernel_entry 0\n    mrs    x25, esr_el1                // read the syndrome register\n    lsr    x24, x25, #ESR_ELx_EC_SHIFT // exception class\n    cmp    x24, #ESR_ELx_EC_SVC64      // SVC in 64-bit state\n    b.eq   el0_svc\n    handle_invalid_entry 0, SYNC_ERROR\n</code></pre> <ul> <li> <p>As for all exception handlers, <code>kernel_entry</code> macro is called. </p> </li> <li> <p><code>esr_el1</code> (Exception Syndrome Register) is checked. This register contains \"exception class\" field at offset ESR_ELx_EC_SHIFT. If exception class is equal to ESR_ELx_EC_SVC64 this means that the current exception is caused by the <code>svc</code> instruction and it is a system call. In this case, we jump to <code>el0_svc</code> label and show an error message otherwise.</p> </li> </ul> <pre><code>// entry.S\nsc_nr   .req    x25                  // number of system calls\nscno    .req    x26                  // syscall number\nstbl    .req    x27                  // syscall table pointer\n\nel0_svc:\n    adr    stbl, sys_call_table      // load syscall table pointer\n    uxtw   scno, w8                  // syscall number in w8\n    mov    sc_nr, #__NR_syscalls\n    bl     enable_irq\n    cmp    scno, sc_nr               // check upper syscall limit\n    b.hs   ni_sys\n\n    ldr    x16, [stbl, scno, lsl #3] // address in the syscall table\n    blr    x16                       // call sys_* routine\n    b      ret_from_syscall\nni_sys:\n    handle_invalid_entry 0, SYSCALL_ERROR\n</code></pre> <p><code>el0_svc</code> first loads the address of the syscall table in the <code>stbl</code> (it is just an alias to the <code>x27</code> register.) and syscall number in the <code>scno</code> variable. Then interrupts are enabled and syscall number is compared to the total number of syscalls in the system \u2014 if it is greater or equal an error message is shown. If syscall number falls within the required range, it is used as an index in the syscall table array to obtain a pointer to the syscall handler. Next, the handler is executed and after it finishes <code>ret_from_syscall</code> is called. </p> <p>Note, that we don't touch here registers <code>x0</code> \u2013 <code>x7</code> \u2014 they are transparently passed to the handler. (Why?)</p> <p>Fast forward to the completion of syscall. </p> <pre><code>ret_from_syscall:\n    bl    disable_irq\n    str   x0, [sp, #S_X0]             // returned x0\n    kernel_exit 0\n</code></pre> <p><code>ret_from_syscall</code> first disables interrupts. Then it saves the value of <code>x0</code> register on the stack. This is required because <code>kernel_exit</code> will restore all general purpose registers from their saved values, but <code>x0</code> now contains return value of the syscall handler and we want this value to be passed to the user code. Finally <code>kernel_exit</code> is called, which returns to the user code.</p>"},{"location":"exp5/rpi-os/#executing-a-task-in-user-mode","title":"Executing a task in user mode","text":"<p>Atop that, the kernel implements two complementary ways for launching a user process. Overview: </p> <p></p>"},{"location":"exp5/rpi-os/#method-1-forking-user-processes","title":"Method 1: Forking user processes","text":"<p>At the user level, user_process() calls <code>call_sys_clone</code> to spawn a new task. </p> <pre><code>// sys.S\n.globl call_sys_clone\ncall_sys_clone:\n    /* Save args for the child. They will be preserved throughout syscall  */\n    mov    x10, x0                    /*fn*/\n    mov    x11, x1                    /*arg*/\n    mov    x12, x2                    /*stack*/\n\n    /* Prep syscall args. Do the system call.  */\n    mov    x0, x2                     /* stack  */\n    mov    x8, #SYS_CLONE_NUMBER\n    svc    0x0\n\n    cmp    x0, #0\n    beq    thread_start\n    ret\n\nthread_start:\n    mov    x29, 0\n\n    /* Pick up the function arg and execute.  */\n    mov    x0, x11\n    blr    x10\n\n    /* We are done, pass the return value through x0.  */\n    mov    x8, #SYS_EXIT_NUMBER\n    svc    0x0\n</code></pre> <p>The <code>clone</code> wrapper above mimics the coresponding function from in the <code>glibc</code> library. </p> <ol> <li>x0-x3 contain syscall arguments. They are intended for the child task. Save fn and arg to x10-x11. Why? The kernel syscall handler <code>el0_svc</code> does not preserve x0-x3. The new task will pick up x10 and x11 in <code>thread_start</code>. </li> <li>Save the pointer to the new task's stack in x2, as expected by <code>sys_clone(unsigned long stack)</code>. </li> <li>Starts syscall via <code>svc</code>. </li> <li>Upon returning from syscall, checks return value in x0: </li> <li>if 0, we are executing inside the child task. In this case, execution goes to <code>thread_start</code> label.</li> <li>If not 0, we are executing in the parent task. x0 is the PID of the child task. </li> <li>thread_start executes in the new task with the give entry function (x10) and the arg to the function (x11). Note x29 (FP) is cleared for correct stack unwinding at the user level.</li> <li>After the function finishes, <code>exit</code> syscall is performed \u2014 it never returns.</li> </ol>"},{"location":"exp5/rpi-os/#implementing-clone-in-kernel","title":"Implementing clone in kernel","text":"<p>Inside the kernel, clone() goes to is <code>sys_clone()</code> (sys.c). It just calls <code>copy_process()</code> . This function, however, has been modified since the last lesson. </p> <pre><code>int copy_process(unsigned long clone_flags, unsigned long fn, unsigned long arg, unsigned long stack)\n{\n    preempt_disable();\n    struct task_struct *p;\n\n    p = (struct task_struct *) get_free_page();\n    if (!p) {\n        return -1;\n    }\n\n    struct pt_regs *childregs = task_pt_regs(p);\n    memzero((unsigned long)childregs, sizeof(struct pt_regs));\n    memzero((unsigned long)&amp;p-&gt;cpu_context, sizeof(struct cpu_context));\n\n    // new addition\n    if (clone_flags &amp; PF_KTHREAD) {\n        p-&gt;cpu_context.x19 = fn;\n        p-&gt;cpu_context.x20 = arg;\n    } else {\n        struct pt_regs * cur_regs = task_pt_regs(current);\n        *childregs = *cur_regs;\n        childregs-&gt;regs[0] = 0;\n        childregs-&gt;sp = stack + PAGE_SIZE;\n        p-&gt;stack = stack;\n    }\n    p-&gt;flags = clone_flags;\n    p-&gt;priority = current-&gt;priority;\n    p-&gt;state = TASK_RUNNING;\n    p-&gt;counter = p-&gt;priority;\n    p-&gt;preempt_count = 1; //disable preemtion until schedule_tail\n\n    p-&gt;cpu_context.pc = (unsigned long)ret_from_fork;\n    p-&gt;cpu_context.sp = (unsigned long)childregs;\n    int pid = nr_tasks++;\n    task[pid] = p;\n    preempt_enable();\n    return pid;\n}\n</code></pre> <p>If creating a new kernel thread, the function does the same thing as before. If creating a user thread, the function takes care of <code>pt_regs</code> as it is unique to a user thread -- the state saved/restored upon entering/exiting the kernel. </p> <pre><code>struct pt_regs * cur_regs = task_pt_regs(current);\n*childregs = *cur_regs;\nchildregs-&gt;regs[0] = 0;\nchildregs-&gt;sp = stack + PAGE_SIZE;\np-&gt;stack = stack;\n</code></pre> <p>We populate the CPU context, i.e. <code>pt_regs</code>, for the new task. Note that <code>pt_regs</code> is always at the top of the stack page (recall the figure above), because when syscall enters/exits the kernel, the kernel stack is empty. </p> <p><code>x0</code> in the new state is set to <code>0</code>, because <code>x0</code> will be the return value of the <code>clone</code> syscall. We've just seen how clone wrapper function uses this value to determine whether we are in the parent or the child task. </p> <p>Next <code>sp</code> for the new task is set to point to the top of the new user stack page. We also save the pointer to the stack page in order to do a cleanup after the task finishes.</p>"},{"location":"exp5/rpi-os/#method-2-moving-an-existing-kernel-task-to-el0","title":"Method 2: Moving an existing kernel task to EL0","text":"<p>Overview: upon its creation, the kernel task calls its main function, <code>kernel_process()</code>, which calls <code>move_to_user_mode()</code>. The later prepares CPU context for exiting to EL0. Then <code>kernel_process()</code> returns to <code>ret_from_fork</code> which invokes the familiar <code>kernel_exit</code>. Eventually, an <code>eret</code> instruction - boom! We land in EL0. </p> <p>Code walkthrough</p> <p>First create a process (i.e. a task) as we did before. This is a \"kernel\" process to execute at EL1. </p> <pre><code>// kernel.c\nint res = copy_process(PF_KTHREAD, (unsigned long)&amp;kernel_process, 0, 0);\n</code></pre> <p>The kernel process invokes move_to_user_mode(), passing a function pointer to the <code>user_process</code> as the first argument. </p> <pre><code>void kernel_process() {\n    printf(\"Kernel process started. EL %d\\r\\n\", get_el());\n    int err = move_to_user_mode((unsigned long)&amp;user_process);\n    ...\n</code></pre> <p>The <code>move_to_user_mode</code> function prepares pt_regs and the user stack, so the kernel process becomes a \"legit\" user process. </p> <pre><code>int move_to_user_mode(unsigned long pc)\n{\n    struct pt_regs *regs = task_pt_regs(current);\n    memzero((unsigned long)regs, sizeof(*regs));\n    regs-&gt;pc = pc;\n    regs-&gt;pstate = PSR_MODE_EL0t;\n    unsigned long stack = get_free_page(); //allocate new user stack\n    if (!stack) {\n        return -1;\n    }\n    regs-&gt;sp = stack + PAGE_SIZE;\n    current-&gt;stack = stack;\n    return 0;\n}\n</code></pre> <p>pt_regs: the exception stack frame </p> <p>In the previous experiment: when an interrupt happens, <code>kernel_entry</code> saves CPU context to a stack frame marked as \"saved regs\", which is somewhere in the middle of a kernel task's stack. </p> <p></p> <p>Dump pt_regs in GDB:</p> <p>```</p> <p>p /x (struct pt_regs )((char *)current + 4096 - sizeof(struct pt_regs)) $7 = {                                                             regs = {[0x0] = 0x401fd0, [0x1] = 0x0, [0x2] = 0x401fe7, [0x3] = 0x401f40, [0x4] = 0x0 , [0x1d] = 0x401fc0, [0x1e] = 0x8088c},  sp = 0x401fc0,                                              pc = 0x830cc,                                                        pstate = 0x60000000 }                                                ``` <p>Check where syscall happens:                                                                   ```</p> <p>info line *0x830cc                                                                       Line 7 of \"src/sys.S\" starts at address 0x830cc  and ends at 0x830d0 .                                                                                     ``` <p>In this experiment, our kernel will additionally handle sync exceptions (syscalls). When a syscall happens, the CPU will create a stack frame in the same format called pt_regs. The name comes from Linux again. When syscall returns, the kernel unwinds <code>pt_regs</code>. </p> <p>For the first time return to EL0, <code>move_to_user_mode()</code> sets up <code>pt_regs</code>:</p> <ul> <li> <p><code>pt_regs.pc</code> This is the first instruction to be executed by the task once it lands in user mode via <code>eret</code>. </p> </li> <li> <p><code>pstate</code>. This specifies the CPU state for the task. Later, <code>kernel_exit</code> copies this field to <code>spsr_el1</code>. <code>eret</code> restores the CPU state from <code>pstate</code>. PSR_MODE_EL0t constant specifies that we will go to EL0. See manual. </p> </li> <li> <p>Furthermore, <code>move_to_user_mode</code>  allocates a new page for the user stack and sets <code>sp</code> field to point to the page top. </p> </li> </ul> <p>Where is pt_regs?</p> <p>It is at the top of the stack. See the figure above. Right before <code>kernel_exit()</code>, the task's stack is unwound just to the beginning of <code>pt_regs</code>. Therefore, <code>kernel_exit()</code> will restore CPU regs from the stack. </p> <p>task_pt_regs() calculates the address of a task's <code>pt_regs</code>. See the code below which is self-evident. Recall that THREAD_SIZE == 4KB which is the memory size for the task. </p> <pre><code>struct pt_regs * task_pt_regs(struct task_struct *tsk){\n    unsigned long p = (unsigned long)tsk + THREAD_SIZE - sizeof(struct pt_regs);\n    return (struct pt_regs *)p;\n}\n</code></pre>"},{"location":"exp5/rpi-os/#ret_from_fork-augmented","title":"ret_from_fork(), augmented","text":"<p>New addition is made to the middle of the ret_from_fork function: </p> <pre><code>.globl ret_from_fork\nret_from_fork:\n    bl    schedule_tail\n    cbz   x19, ret_to_user            // not a kernel thread, go to ret_to_user\n    mov   x0, x20\n    blr   x19\n    // kernel thread returns, and continues below\nret_to_user:\n    bl disable_irq\n    kernel_exit 0\n</code></pre> <p>Why are x19 and x20? That is where <code>copy_process()</code> saves the <code>fn</code> and <code>arg</code> specified for a new user process. </p> <p>Now, after a kernel thread finishes, the execution jumps to <code>ret_to_user</code>, where it disables interrupts and performs exception return (kernel_exit), using previously prepared processor state.</p> <p>If you get confused, revisit the \"overview\" figure: </p> <p></p>"},{"location":"exp5/rpi-os/#exiting-a-task","title":"Exiting a task","text":"<p>Each user task calls the <code>exit</code> syscall at the end of its life cycle. In the current implementation, the <code>call_sys_clone</code> wrapper calls <code>exit</code>; see above.  Into the kernel, <code>exit</code> syscall goes to <code>exit_process()</code>, which deactivates a task. The function is listed below.</p> <pre><code>void exit_process(){\n    preempt_disable();\n    for (int i = 0; i &lt; NR_TASKS; i++){\n        if (task[i] == current) {\n            task[i]-&gt;state = TASK_ZOMBIE;\n            break;\n        }\n    }\n    if (current-&gt;stack) {\n        free_page(current-&gt;stack);\n    }\n    preempt_enable();\n    schedule();\n}\n</code></pre> <p>Following Linux convention, we are not deleting the task at once but set its state to <code>TASK_ZOMBIE</code> instead. This prevents the task from being selected and executed by the scheduler. In Linux such approach is used to allow parent process to query information about the child even after it finishes.</p> <p><code>exit_process</code> also deletes now unnecessary user stack and calls <code>schedule</code>. After <code>schedule</code> is called new task will be selected, that's why this system call never returns.</p>"},{"location":"exp5/rpi-os/#conclusion","title":"Conclusion","text":"<p>Now that the kernel can manage user tasks, we become much closer to the full process isolation. But one important step is still missing: all user tasks share the same physical memory and can easily read one another's data. In the next lesson, we are going to introduce virtual memory and fix this issue.</p>"},{"location":"exp6/TA%20notes%20on%20VM/","title":"TA notes on VM","text":"<p>2/24/2023: init draft by Zhiming Xu, TA of CS4414 Sp23. Edited on 2/25/2023</p> <p>During the rest of p1, we'll add the final piece of a modern OS to our kernel, virtual memory (VM). There are many new terms arising here that might overwhelm you. When I learned this part, I also felt perplexed by how elusively VM manifests itself. So, I'll try to provide a mental model of it step by step. Hopefully it'll help in your experiments.</p>"},{"location":"exp6/TA%20notes%20on%20VM/#welcome-to-the-real-world-where-everything-is-where-it-appears","title":"Welcome to the real world, where everything is where it appears","text":"<p>First, without VM, the addresses in our kernel are physical. Recall the address of <code>delay</code> you've seen in exp3, say, it's <code>0x82ef0</code>. Then if you read the kernel image byte by byte, it is located at <code>0x82ef0</code> bytes away from the beginning. In other words, it resides at that place, physically. Well, Not exactly. If you still remember, our kernel runs in a VM(=virtual machine). <code>QEMU</code> seizes the space until <code>0x80000</code>. So it's <code>2ef0</code> away, but if you're using the rpi3 hardware, what you see is undoubtfully physical. </p>"},{"location":"exp6/TA%20notes%20on%20VM/#no-you-shall-not-pass","title":"NO! YOU SHALL NOT PASS","text":"<p>In reality, if everything is where it appears to be, the users can peek at the kernel and vice versa - we don't want that to happen. In order to separate the address spaces of user/kernel (as well as different tasks'), VM is invented to cover up the real addresses. In this way, every task is free to use any and all addresses they're entitled to (a user still can't trespass the kernel's territory), but now the addresses they claim are virtual. An address of <code>0x82ef0</code> doesn't necessarily locate at that # of bytes away from the beginning of the kernel image.</p>"},{"location":"exp6/TA%20notes%20on%20VM/#physical-addresses-and-where-to-find-them","title":"Physical addresses and where to find them","text":"<p>However, the data stored at the <code>0x82ef0</code> still exist somewhere in the physical memory, and the kernel needs a way to know where to serve the task. At this step, we can think of a virtual memory address as a pointer in C that points to a memory object. Here are two print statements you can run. They demonstrate the relation between a pointer and the object it points to.</p> <pre><code>int a = 2023;\nint *p = &amp;a;\nprintf(\"%d\", a); // this will give us 2023\nprintf(\"%ld\", p); // this will give us the virtual memory address. still a number, but remotely likely to be 2023\n</code></pre> <p>The pointer <code>p</code> doesn't save the integer variable itself but contains the address of the place that stores <code>a</code>. Similarly, a VM address is not the place that physically stores a memory object, but a portal to that place.</p>"},{"location":"exp6/TA%20notes%20on%20VM/#a-price-to-pay-for-the-truth","title":"A price to pay for the truth","text":"<p>So, how does the kernel translate a VM address to a physical one? Let's think of the translation process as a lookup table that encodes a one-to-one function, <code>f(VM)=PM</code>. An example is shown below.</p> <pre><code>| VM address | Physical address |\n| -------- | ---------- |\n| 0x80ef0  | 0x20230224 |\n| 0x80ef1  | 0x20220224 |\n| 0x80ef2  | 0x20210224 |\n...\n</code></pre> <p>It's very nice that we can readily find the physical address with this table, but the problem is not solved yet. You might already notice that if a VM address can map to any physical address it desires, the table is REALLY huge. In Aarch64, the addresses are 8-byte(=64 bits) long, and there can be $2^{48}$ legitimate addresses. We only need one column because we index with the VM address (go <code>0x80ef0</code> bytes away from the beginning in the virtual world). If the mapping were arbitrary, we would need this # of rows, consuming $8\\times 2^{48}$ bytes of memory. More than the entirety of the available VM, and MUCH MORE than the physical storage most of us can afford to buy!</p>"},{"location":"exp6/TA%20notes%20on%20VM/#spend-less-get-more","title":"Spend less, get more","text":"<p>The next problem is thus, how to shrink this table and make it memory efficient. The concept of page, i.e., a  continuous memory region of a fixed size, is introduced. Instead of per address, we mandate that a page in VM maps to a page in physical memory. In many platforms, we're dealing with a page size of 4KB($=2^{12}$). The policy ensures a 4KB region in VM gets translated to a 4KB region in physical memory. In this way, we only need to record the mapping between the beginning of this region in VM and the beginning of this region in PM, and keep only 1/4K entries in the table below.</p> <pre><code>| VM address | Physical address |\n| -------- | ---------- |\n| 0x80ef0  | 0x20230224 |\n// all entries previously here no longer needed\n| 0x80ef0+4K  | 0x20210224 |\n...\n</code></pre> <p>With the introduction of page, how much space can we save? Previously, it's $8\\times 2^{48}$. Now we only keep one in a 4K, 1/4K=$1/2^{12}$. It results in $8\\times 2^{48}/2^{12}=8\\times 2^{36}$, a triple-order magnitude reduction! You'll be promoted instantly if you can cut this much cost for your company.</p>"},{"location":"exp6/TA%20notes%20on%20VM/#still-want-to-bargain","title":"Still want to bargain?","text":"<p>We want to cut MORE! It's likely that we have enough money to buy a memory chip that can store the shrunk table, but human's greed knows no bounds. It drives us to build the final piece of VM, the hierarchy of page tables. Before, our translation has only one layer, i.e., <code>f(VM)=PM</code>, but what if hierarchical layers of them?  Recall the pointer example above, we've shown a pointer that points to an integer. In fact, we can have a pointer that points to a pointer that points to an integer.</p> <pre><code>int a; int *p;\np = &amp;a;\n// p -&gt; a: just one level\nint a; int *p1; int **p2;\np1 = &amp;a; p2 = &amp;p1;\n// p2 -&gt; p1 -&gt; a: two levels\n</code></pre> <p>We can of course add even more a pointer that points to a pointer that points to... in between to make the mechanism more obstructive/the sentence harder to read, but the example will do for the demonstration purpose.</p>"},{"location":"exp6/TA%20notes%20on%20VM/#take-me-to-action-boring-maths","title":"Take Me to Action, Boring Maths","text":"<p>In a standard Aarch64 VM layout with 4KB pages and additional four more hierarchies, i.e., PGD-&gt;PUD-&gt;PMD-&gt;PTE-&gt;pages. Apparently, one address of a higher hierarchy points to exactly one table (an array of the next-level pointers) of the immediately lower hierarchy. The information in each page table is 9-bit wide, totaling the full VM, $2^9\\times2^9\\times2^9\\times2^9\\times2^{12}=2^{48}$. In our experiment, it's a bit simpler. Since rpi3 only has 1GB physical memory, we can eliminate PTE and reduce the complexity. The smallest unit combines 9 bits in PTE and 12 bits in pages at 2MB$(=2^9\\times 2^12)$. It's a section in Aarch64 term, but we'll conveniently call it a page. The tables in the experiment take their final form here.</p> <pre><code>PGD -&gt; PUD -&gt; PMD -&gt; page\n|    PGD   |      PUD      |        |    PUD   |      PMD      |        |    PMD   |    page   |\n| -------- | ------------- |        | -------- | ------------- |        | -------- | --------- |\n| pgd_addr | pud_addr[2^9] |        | pud_addr | pmd_addr[2^9] |        | pmd_addr | page[2^9] |\n</code></pre> <p>Even to the right of the three tables, each page represents 2MB memory. Now, how many tables do we need for the 1GB RAM of rpi3? First, there will be 1GB/2MB=$2^9$ pages. Since every <code>pmd_addr</code> points to an array of $2^9$ pages. We need exactly one <code>pmd_addr</code>. As the table shows above, each <code>pud_addr</code> points to $2^9$ <code>pmd_addr</code>, and each <code>pgd_addr</code> points to $2^9$ <code>pud_addr</code>. For the single <code>pmd_addr</code>, we still need one of <code>pud_addr</code> and <code>pgd_addr</code> respectively. In other words, we have exactly one table of {PGD, PUD, PMD}, and each table have exactly one entry. Follow the <code>int</code> pointer example above, we have</p> <pre><code>int pages[1&lt;&lt;9]; // 2^9 pages;\nint *pmd[0];     // pmd is a single-element array, its element points to an int array\npmd[0] = pages;  // the entry is set to the beginning of the page array\nint **pud[0];    // pud is a single-element array, its element points to {an array whose element points to an int array}\npud[0] = pmd;    // the entry is set to the beginning of the array that points to the page array\nint ***pgd[0];   // pgd is a single-element array, its element points to {an array whose element points to (an array whose element points to an int array)}\npgd[0] = pud;\n</code></pre>"},{"location":"exp6/TA%20notes%20on%20VM/#parting-words","title":"Parting words","text":"<p>That's it! Now it's the journey's end of our VM tour. Your task in the following experiments is to fill in the tables so that we can command our VM space. And achieve the goal we have from the start - isolate user/kernel memory and Confundo every task to believe it owns the entirety of the memory space it's entitled to. Thank you for reading all the way down to this part, and hope you have a little bit more understanding of VM during this time.</p>"},{"location":"exp6/rpi-os/","title":"6: Virtual memory (VM)","text":"<p>READING TIME: 1HR</p>"},{"location":"exp6/rpi-os/#objectives","title":"Objectives","text":"<p>Make our tiny kernel capable of: </p> <ol> <li>enforcing separate virtual address spaces, and </li> <li>user-level demand paging. </li> </ol>"},{"location":"exp6/rpi-os/#roadmap","title":"Roadmap","text":"<p>Prior to this experiment, our kernel can run and schedule user processes, but the isolation between them is not complete - all processes and the kernel itself share the same memory. This allows any process to easily access somebody else's data and even kernel data. And even if we assume that all our processes are not malicious, there is another drawback: before allocating memory each process need to know which memory regions are already occupied - this makes memory allocation for a process more complicated.</p> <p>We take the following steps. </p> <ul> <li>Set up a pgtable for kernel. Using linear mapping. </li> <li>Turn on MMU shortly after kernel boots. This is a common kernel design. </li> <li>Set up pgtables for user processes</li> <li>Implement fork() for user processes</li> <li>Implement demand paging </li> </ul>"},{"location":"exp6/rpi-os/#get-the-code","title":"Get the code","text":"<p>Code location: p1-kernel/src/exp6</p> <p>Please: do a <code>git pull</code> even if you have cloned the p1-kenel repo previously, in case of upstream updates. </p>"},{"location":"exp6/rpi-os/#background-arm64-translation-process","title":"Background: ARM64 translation process","text":"<p>The Arm's document is well written. (\"Armv8-A Address Translation\", link)</p>"},{"location":"exp6/rpi-os/#page-table-format","title":"Page table format","text":"<p>This experiment introduces VM to our kernel. With VM, we can formally call tasks \"processes\". Each task will have its own address space. They issue memory access with virtual addresses. The MMU transparently translates virtual addresses to physical addresses. The MMU uses page table (or pgtable, or \"translation table\" in ARM's manual). </p> <p>The following diagram summarizes ARM64 address translation with uses 4-level pgtables. </p> <pre><code>                           Virtual address                                                                 Physical Memory\n+-----------------------------------------------------------------------+                                +-----------------_+\n|         | PGD Index | PUD Index | PMD Index | PTE Index | Page offset |                                |                  |\n+-----------------------------------------------------------------------+                                |                  |\n63        47     |    38      |   29     |    20    |     11      |     0                                |     Page N       |\n                 |            |          |          |             +--------------------+           +----&gt;+------------------+\n                 |            |          |          +---------------------+            |           |     |                  |\n          +------+            |          |                                |            |           |     |                  |\n          |                   |          +----------+                     |            |           |     |------------------|\n+------+  |        PGD        |                     |                     |            +----------------&gt;| Physical address |\n|TTBRx |----&gt;+-------------+  |           PUD       |                     |                        |     |------------------|\n+-EL1--+  |  |  entry #511 |  | +-&gt;+-------------+  |          PMD        |                        |     |                  |\n          |  +-------------+  | |  |     #511    |  | +-&gt;+-------------+  |          PTE           |     +------------------+\n          +-&gt;| PUD address |----+  +-------------+  | |  |   #511      |  | +-&gt;+--------------+    |     |                  |\n             +-------------+  +---&gt;| PMD address |----+  +-------------+  | |  |      #511    |    |     |                  |\n             |  entry #0   |       +-------------+  +---&gt;| PTE address |----+  +-------------_+    |     |                  |\n             +-------------+       |       #0    |       +-------------+  +---&gt;| Page address |----+     |                  |\n                                   +-------------+       |     #0      |       +--------------+          |                  |\n                                                         +-------------+       |      #0      |          |                  |\n                                                                               +--------------+          +------------------+\n</code></pre> <p>Notable points: </p> <ul> <li>Page tables have a hierarchical structure, i.e. a tree.  An item in any of the tables contains an address of the next table in the hierarchy.</li> </ul> <p>Note: strictly speaking a pgtable means a contiguous array of entries at any of the four levels. So a tree has many pgtables. Some documents casually use \"pgtable\" to refer to an entire pgtable tree. Be careful. </p> <ul> <li>There are 4 levels in the table hierarchy: PGD (Page Global Directory), PUD (Page Upper Directory), PMD (Page Middle Directory), PTE (Page Table Entry). PTE is the last table in the hierarchy and it points to the actual page in the physical memory. </li> </ul> <p>Don't read too much into the terms, which just represent lv1, 2, ... pgtables. Them terms come from the Linux kernel (x86), not ARM64. Over years, they became a common lingo among kernel hackers. </p> <ul> <li> <p>Besides holding a physical address, each pgtable item holds extra bits crucial for translation. Will examine the format below. </p> </li> <li> <p>MMU starts memory translation process by locating the base address of PGD. MMU locates the base address from the <code>TTBRx_EL1</code> register which should be set by the kernel. TTBR = translation table base register.</p> </li> <li> <p>bits [63-48] = 0xffff (all 1s). MMU uses <code>ttbr1_el1</code>. This is meant for the kernel space. </p> </li> <li>bits [63-48] = 0x0 (all 0s). MMU uses <code>ttbr0_el1</code>. This is meant for the user process. </li> <li> <p>Each process has its own address space. Therefore, it has its own copy of page table tree, starting from PGD. Therefore, the kernel keeps a separate PGD base address for each process. That is, the kernel virtualizes PGD for processes. During a context switch, the kernel loads the PGD base of the next process to <code>ttbr0_el1</code>.</p> </li> <li> <p>MMU walks the pgtable tree to look up the physical address. A virtual address uses only 48 out of 64 available bits.  When doing a translation, MMU splits an address into 4 parts:</p> </li> <li>9 bits [39 - 47] contain an index in the PGD table. MMU uses this index to find the location of the PUD.</li> <li>9 bits [30 - 38] contain an index in the PUD table. MMU uses this index to find the location of the PMD.</li> <li>9 bits [21 - 29] contain an index in the PMD table. MMU uses this index to find the location of the PTE.</li> <li>9 bits [12 - 20] contain an index in the PTE table. MMU uses this index to find a page in the physical memory.</li> <li> <p>Bits [0 - 11] contain an offset in the physical page. MMU uses this offset to determine the exact position in the previously found page that corresponds to the original virtual address.</p> </li> <li> <p>Memory for a user process is always allocated in pages. A page is a contiguous memory region 4KB in size (ARM processors support larger pages, but 4KB is the most common case and we are going to limit our discussion only to this page size).</p> </li> </ul> <p>Exercise: how large is a page table? From the diagram above we know that index in a page table occupies 9 bits (this is true for all page table levels). This means that each page table contains <code>2^9 = 512</code> items. Each item in a page table is an address of either the next page table in the hierarchy or a physical page in case of PTE. As we are using a 64-bit processor, each address must be 64 bit or 8 bytes in size. </p> <p>This means that each pgtable is <code>512 * 8 = 4096</code> bytes or 4 KB. A pgtable is exactly a page! This might give you an intuition why MMU designers chose such numbers.</p>"},{"location":"exp6/rpi-os/#section-2mb-mapping","title":"Section (2MB) mapping","text":"<p>This is specific to ARM64 for mapping large, continuous physical memory. Instead of 4 KB pages, we directly map 2MB blocks called sections. This eliminates one level of translation. The translation diagram, in this case, looks like the following.</p> <pre><code>                           Virtual address                                               Physical Memory\n+-----------------------------------------------------------------------+              +-----------------_+\n|         | PGD Index | PUD Index | PMD Index |      Section offset     |              |                  |\n+-----------------------------------------------------------------------+              |                  |\n63        47     |    38      |   29     |    20            |           0              |    Section N     |\n                 |            |          |                  |                    +----&gt;+------------------+\n                 |            |          |                  |                    |     |                  |\n          +------+            |          |                  |                    |     |                  |\n          |                   |          +----------+       |                    |     |------------------|\n+------+  |        PGD        |                     |       +-------------------------&gt;| Physical address |\n| TTBRx|----&gt;+-------------+  |           PUD       |                            |     |------------------|\n+--EL1-+  |  |             |  | +-&gt;+-------------+  |            PMD             |     |                  |\n          |  +-------------+  | |  |             |  | +-&gt;+-----------------+     |     +------------------+\n          +-&gt;| PUD address |----+  +-------------+  | |  |                 |     |     |                  |\n             +-------------+  +---&gt;| PMD address |----+  +-----------------+     |     |                  |\n             |             |       +-------------+  +---&gt;| Section address |-----+     |                  |\n             +-------------+       |             |       +-----------------+           |                  |\n                                   +-------------+       |                 |           |                  |\n                                                         +-----------------+           |                  |\n                                                                                       +------------------+\n</code></pre> <p>As you can see the difference here is that now PMD contains a pointer to the physical section. Also, the offset occupies 21 bits instead of 12 bits (this is because we need 21 bits to encode a 2MB range)</p>"},{"location":"exp6/rpi-os/#page-descriptor-format","title":"Page descriptor format","text":"<p>An item in a page table is called \"descriptor\". A description has a special format as mandated by MMU hardware. A descriptor contains an address of either next page table or a physical page.</p> <p>The key thing to understand: each descriptor always points to something that is page-aligned (either a physical page, a section or the next page table in the hierarchy). This means that last 12 bits of the address, stored in a descriptor, will always be 0. MMU uses those bits to store additional information  (\"attributes\") for translation. </p> <pre><code>                           Descriptor format\n`+------------------------------------------------------------------------------------------+\n | Upper attributes | Address (bits 47:12) | Lower attributes | Block/table bit | Valid bit |\n +------------------------------------------------------------------------------------------+\n 63                 47                     11                 2                 1           0\n</code></pre> <ul> <li>Bit 0 This bit must be set to 1 for all valid descriptors. If MMU encounter non-valid descriptor during translation process a synchronous exception is generated. If this invalid bit was set by kernel on purpose, the kernel shall handle this exception, allocate a new page, and prepare a correct descriptor (We will look in details on how this works a little bit later)</li> <li>Bit 1 This bit indicates whether the current descriptor points to a next page table in the hierarchy (we call such descriptor a \"table descriptor\") or it points instead to a physical page or a section (such descriptors are called \"block descriptors\").</li> <li>Bits [11:2] Those bits are ignored for table descriptors. For block descriptors they contain some attributes that control, for example, whether the mapped page is readable/writeable (AP), executable (XN), etc. Here also comes the MemAttr bits. See below. </li> <li>Bits [47:12]. This is the place where the address that a descriptor points to is stored. As I mentioned previously, only bits [47:12] of the address need to be stored, because all other bits are always 0.</li> <li>Bits [63:48] Another set of attributes.</li> </ul> <p>See Arm's official page. </p>"},{"location":"exp6/rpi-os/#configuring-page-attributes","title":"Configuring page attributes","text":"<p>As I mentioned in the previous section, each block descriptor contains a set of attributes (called MemAttr, bits[5:2]) that controls various virtual page parameters, notably cacheability or shareability. However, the attributes that are most important for our discussion are NOT encoded in the descriptor. Instead, ARM processors implement a trick for compressing descriptor attributes commonly used. (The days of simpler ARM hardware were gone)</p> <p>Memory attribute indirection </p> <p>ARMv8 architecture introduces <code>mair_el1</code> register (Search for \"mair_el1 ddi0595\" for definition). This register consists of 8 slots, each spanning 8 bits. Each slot configures a common set of attributes. A descriptor then specifies just an index of the <code>mair</code> slot, instead of specifying all attributes directly. This allows using only 3 bits in the descriptor to reference a <code>mair</code> slot. We are using only a few of available attribute options. Here is the code that prepares values for the <code>mair</code> register.</p> <pre><code>// arm/mmu.h\n/*\n * Memory region attributes:\n *\n *   n = AttrIndx[2:0]\n *            n    MAIR\n *   DEVICE_nGnRnE    000    00000000\n *   NORMAL_NC        001    01000100\n */\n#define MT_DEVICE_nGnRnE         0x0\n#define MT_NORMAL_NC            0x1\n#define MT_DEVICE_nGnRnE_FLAGS        0x00\n#define MT_NORMAL_NC_FLAGS          0x44\n#define MAIR_VALUE            (MT_DEVICE_nGnRnE_FLAGS &lt;&lt; (8 * MT_DEVICE_nGnRnE)) | (MT_NORMAL_NC_FLAGS &lt;&lt; (8 * MT_NORMAL_NC))\n</code></pre> <p>Here we are using only 2 out of 8 available slots in the <code>mair</code> registers. The first one corresponds to device memory (IO registers) and second to normal non-cacheable memory. <code>MT_DEVICE_nGnRnE</code> and <code>MT_NORMAL_NC</code> are indexes that we are going to use in block descriptors, <code>MT_DEVICE_nGnRnE_FLAGS</code> and <code>MT_NORMAL_NC_FLAGS</code> are values that we are storing in the first 2 slots of the <code>mair_el1</code> register.</p>"},{"location":"exp6/rpi-os/#kernel-vs-user-virtual-memory","title":"Kernel vs user virtual memory","text":"<p>After the MMU is switched on, each memory access issued by kernel must use virtual address instead of physical. One consequence is that the kernel itself must maintain its own set of page tables. One possible solution could be to reload <code>ttbr</code> (pointing to the PGD base) each time we switch from user to kernel mode. Reloading <code>ttbr</code> can be costly. (Why?) This makes syscalls and page faults expensive. </p> <p>Commodity kernels therefore avoid frequent reloads of PGD base. A kernel splits the virtual address space into 2 parts: user portion and kernel portion. When switching among user tasks, the kernel only changes the mapping of the user portion while keeping the kernel mapping unchanged. </p> <p>This classic kernel design turns out to lead to most severe security holes in recent years. Google \"spectre and meltdown\". </p> <p>On 32-bit CPUs, a kernel usually allocate first 3 GB of the address space for user and reserve last 1 GB for the kernel. 64-bit architectures are much more favorable in this regard because of huge virtual address space (how large?). And even more: ARMv8 architecture comes with a native feature that can be used to easily implement user/kernel address split.</p> <p>ARM64 defines 2 <code>TTBR</code> registers for holding PGD base addresses: </p> <ul> <li>TTBR0_EL1 points to a user PGD; </li> <li>TTBR1_EL1 points to the kernel PGD. </li> </ul> <p>MMU uses only 48 bits out of 64 bits in the virtual addresses for translation. MMU uses the upper 16 bits in a given virtual address to decide whether it uses TTBR0 or TTBR1. </p> <ul> <li>User virtual addresses: upper 16 bits == 0. MMU uses the PGD base stored in TTBR0_EL1.  This value shall be changed according to process switch. </li> <li>Kernel virtual addresses: upper 16 bits == <code>0xffff</code>.  MMU uses the PGD base stored in TTBR1_EL1. This value shall remain unchanged throughout the life of the kernel. </li> </ul> <p>The CPU also enforces that software at EL0 can never access virtual addresses started with <code>0xffff</code>. Doing so triggers a synchronous exception.  </p> <p>Here is a picture the memory layout. Source: Arm's document \"ARMv8-A Address Translation\". </p> <p></p>"},{"location":"exp6/rpi-os/#adjusting-kernel-addresses","title":"Adjusting kernel addresses","text":"<p>All absolute kernel addresses must start with <code>0xffff...</code>. There are 2 places in the kernel source code shall be changed. </p> <ul> <li> <p>In the linker script we specify base address of the image as <code>0xffff000000000000</code>. This will make the linker think that our image is going to be loaded at <code>0xffff000000000000</code> address, and therefore whenever it needs to generate an absolute address it will make it right. (There are a few more changes to the linker script, but we will discuss them later.) </p> </li> <li> <p>We hardcode absolute kernel base addresses in the header where we define device base address. After switching on MMU, kernel has to access all IO via virtual addresses. We can map them starting from <code>0xffff00003F000000</code>. In the next section we will explore in detail the code that creates this mapping.</p> </li> </ul>"},{"location":"exp6/rpi-os/#kernel-boot-initializing-kernel-page-tables","title":"Kernel boot: initializing kernel page tables","text":"<p>Important: the linker is completely oblivious to kernel physical address, e.g. the physical base (0x0 or 0x80000) where the kernel will be loaded. Two Implications: </p> <ol> <li>the linker links all kernel symbols at virtual addresses starting from <code>0xffff000000000000</code>; </li> <li>Before kernel boots and before it turns on MMU, the kernel will operate on physical addresses starting from 0x0 (or 0x80000 for QEMU). </li> </ol> <p>Keep this key constraint in mind. See below. </p> <p>Right after kernel switches to EL1 and clears the BSS, the kernel populates its pgtables via  __create_page_tables function. </p> <pre><code>// boot.S\n__create_page_tables:\n    mov    x29, x30                        // save return address\n</code></pre> <p>First, the function saves <code>x30</code> (LR). As we are going to call other functions from <code>__create_page_tables</code>, <code>x30</code> will be overwritten.  As we know that no code will use <code>x29</code> during <code>__create_page_tables</code> execution, preserving LR in <code>x29</code> works fine.</p> <p>Q: What could go wrong if we push x30 to stack here? </p> <pre><code>// boot.S\n    adrp    x0, pg_dir // adrp: form PC-relative address to 4KB page \n    mov    x1, #PG_DIR_SIZE\n    bl     memzero\n</code></pre> <p>pg_dir is the virtual base address of the pgtables. Its actual value is set by the linker. Refer to the linker script (e.g. linker-qemu.ld) for details. </p> <p>Next, we clear the initial page tables area. An important thing to understand here is where this area is located (x0) and how do we know its size (x1)? </p> <ul> <li> <p>Initial page tables area is defined in the linker script - this means that we are allocating the spot for this area in the kernel image itself. </p> </li> <li> <p>Calculating the size of this area is a little bit trickier. First, we need to understand the structure of the initial kernel page tables. We know that all our mappings are all inside 1 GB region (this is the size of RPi3 physical memory). One PGD descriptor can cover <code>2^39 = 512 GB</code>  and one PUD descriptor can cover <code>2^30 = 1 GB</code> of continuous virtual mapping area. (Those values are calculated based on the PGD and PUD indexes location in the virtual address.) This means that we need just one PGD and one PUD to map the whole RPi memory, and even more - both PGD and PUD will contain a single descriptor (of course we still need to allocate at least one page for them each). If we have a single PUD entry there also must be a single PMD table, to which this entry will point. (Single PMD entry covers 2 MB, there are 512 items in a PMD, so in total the whole PMD table covers the same 1 GB of memory that is covered by a single PUD descriptor.)   Next, we know that we need to map 1 GB region of memory, which is a multiple of 2 MB. This allows us to keep things simple -- using section mapping. This means that we don't need PTE at all. So in total, we need 3 pages: one for PGD, PUD and PMD - this is precisely the size of the initial page table area.</p> <p>Q: here, MMU is off and everything should be physical address. How could the kernel possibly address functions/variables like memzero, which are  linked at virtual addresses? (Hint: check the disassembly of the kernel binary)</p> </li> </ul>"},{"location":"exp6/rpi-os/#allocating-installing-a-new-pgtable","title":"Allocating &amp; installing a new pgtable","text":"<p>Now we are going to step outside <code>__create_page_tables</code> function and take a look on 2 essential macros: create_table_entry and create_block_map.</p> <p><code>create_table_entry</code> is responsible for allocating a new page table (In our case either PGD or PUD) The source code is listed below.</p> <pre><code>// boot.S\n    .macro    create_table_entry, tbl, virt, shift, tmp1, tmp2\n    lsr    \\tmp1, \\virt, #\\shift\n    and    \\tmp1, \\tmp1, #PTRS_PER_TABLE - 1            // table index\n    add    \\tmp2, \\tbl, #PAGE_SIZE\n    orr    \\tmp2, \\tmp2, #MM_TYPE_PAGE_TABLE\n    str    \\tmp2, [\\tbl, \\tmp1, lsl #3]\n    add    \\tbl, \\tbl, #PAGE_SIZE                    // next level table page\n    .endm\n</code></pre> <p>This macro accepts the following arguments.</p> <ul> <li><code>tbl</code> - a pointer to a memory region where new table has to be allocated.</li> <li><code>virt</code> - virtual address that we are currently mapping.</li> <li><code>shift</code> - shift that we need to apply to the virtual address in order to extract current table index. (39 in case of PGD and 30 in case of PUD)</li> <li><code>tmp1</code>, <code>tmp2</code> - temporary registers.</li> </ul> <p>This macro is very important, so we are going to spend some time understanding it.</p> <pre><code>    lsr    \\tmp1, \\virt, #\\shift\n    and    \\tmp1, \\tmp1, #PTRS_PER_TABLE - 1            // table index\n</code></pre> <p>The first two lines of the macro are responsible for extracting table index from the virtual address. We are applying right shift first to strip everything to the right of the index and then using <code>and</code> operation to strip everything to the left.</p> <pre><code>    add    \\tmp2, \\tbl, #PAGE_SIZE\n</code></pre> <p>Then the address of the next page table is calculated. Here we are using the convention that all our initial page tables are located in one continuous memory region. We simply assume that the next page table in the hierarchy will be adjacent to the current page table. </p> <pre><code>    orr    \\tmp2, \\tmp2, #MM_TYPE_PAGE_TABLE\n</code></pre> <p>Next, a pointer to the next page table in the hierarchy is converted to a table descriptor. (A descriptor must have 2 lower bits set to <code>1</code>)</p> <pre><code>    str    \\tmp2, [\\tbl, \\tmp1, lsl #3]\n</code></pre> <p>Then the descriptor is stored in the current page table. We use previously calculated index to find the right spot in the table.</p> <pre><code>    add    \\tbl, \\tbl, #PAGE_SIZE                    // next level table page\n</code></pre> <p>Finally, we change <code>tbl</code> parameter to point to the next page table in the hierarchy. This is convenient because now we can call <code>create_table_entry</code> one more time for the next table in the hierarchy without making any adjustments to the <code>tbl</code> parameter. This is precisely what we are doing in the create_pgd_entry macro, which is just a wrapper that allocates both PGD and PUD.</p>"},{"location":"exp6/rpi-os/#populating-a-pmd-table","title":"Populating a PMD table","text":"<p>Next important macro is<code>create_block_map</code>. As you might guess this macro is responsible for populating entries of the PMD table. It looks like the following.</p> <pre><code>// boot.S\n    .macro    create_block_map, tbl, phys, start, end, flags, tmp1\n    lsr    \\start, \\start, #SECTION_SHIFT\n    and    \\start, \\start, #PTRS_PER_TABLE - 1            // table index\n    lsr    \\end, \\end, #SECTION_SHIFT\n    and    \\end, \\end, #PTRS_PER_TABLE - 1                // table end index\n    lsr    \\phys, \\phys, #SECTION_SHIFT\n    mov    \\tmp1, #\\flags\n    orr    \\phys, \\tmp1, \\phys, lsl #SECTION_SHIFT            // table entry\n9999:    str    \\phys, [\\tbl, \\start, lsl #3]                // store the entry\n    add    \\start, \\start, #1                    // next entry\n    add    \\phys, \\phys, #SECTION_SIZE                // next block\n    cmp    \\start, \\end\n    b.ls    9999b\n    .endm\n</code></pre> <p>Parameters here are a little bit different.</p> <ul> <li><code>tbl</code> - a pointer to the PMD table.</li> <li><code>phys</code> - the start of the physical region to be mapped.</li> <li><code>start</code> - virtual address of the first section to be mapped.</li> <li><code>end</code> - virtual address of the last section to be mapped.</li> <li><code>flags</code> - flags that need to be copied into lower attributes of the block descriptor.</li> <li><code>tmp1</code> - temporary register.</li> </ul> <p>More about \"SIZE\": </p> <ul> <li>SECTION_SIZE: default 2MB. A \"section\" is ARM's term for its 2MB page, i.e. when a translation table has 3 levels. </li> <li>PAGE_SIZE: default 4KB. A page is 4KB, which is x86 convention and then adopted by almost all CPUs. </li> </ul> <p>Now, let's examine the source.</p> <pre><code>    lsr    \\start, \\start, #SECTION_SHIFT\n    and    \\start, \\start, #PTRS_PER_TABLE - 1            // table index\n</code></pre> <p>Those 2 lines extract the table index from <code>start</code> virtual address. This is done exactly in the same way as we did it before in the <code>create_table_entry</code> macro.</p> <pre><code>    lsr    \\end, \\end, #SECTION_SHIFT\n    and    \\end, \\end, #PTRS_PER_TABLE - 1                // table end index\n</code></pre> <p>The same thing is repeated for the <code>end</code> address. Now both <code>start</code> and <code>end</code> contains not virtual addresses, but indexes in the PMD table, corresponding to the original addresses.</p> <pre><code>    lsr    \\phys, \\phys, #SECTION_SHIFT\n    mov    \\tmp1, #\\flags\n    orr    \\phys, \\tmp1, \\phys, lsl #SECTION_SHIFT            // table entry\n</code></pre> <p>Next, block descriptor is prepared and stored in the <code>tmp1</code> variable. In order to prepare the descriptor <code>phys</code> parameter is first shifted to right then shifted back and merged with the <code>flags</code> parameter using <code>orr</code> instruction. If you wonder why do we have to shift the address back and forth - the answer is that this clears first 21 bit in the <code>phys</code> address and makes our macro universal, allowing it to be used with any address, not just the first address of the section.</p> <pre><code>9999:    str    \\phys, [\\tbl, \\start, lsl #3]                // store the entry\n    add    \\start, \\start, #1                    // next entry\n    add    \\phys, \\phys, #SECTION_SIZE                // next block\n    cmp    \\start, \\end\n    b.ls    9999b  // jump back if \"Unsigned Less than or equal\"\n</code></pre> <p>The final part of the function is executed inside a loop. Here we first store current descriptor at the right index in the PMD table. Next, we increase current index by 1 and update the descriptor to point to the next section. We repeat the same process until current index becomes equal to the last index.</p>"},{"location":"exp6/rpi-os/#putting-it-together-__create_page_tables","title":"Putting it together: __create_page_tables()","text":"<p>Now, when you understand how <code>create_table_entry</code> and <code>create_block_map</code> macros work, it will be straightforward to understand the rest of the <code>__create_page_tables</code> function.</p> <pre><code>// boot.S\n    adrp    x0, pg_dir\n    mov    x1, #VA_START\n    create_pgd_entry x0, x1, x2, x3\n</code></pre> <p>Here we create both PGD and PUD. We configure them to start mapping from VA_START virtual address. Because of the semantics of the <code>create_table_entry</code> macro, after <code>create_pgd_entry</code>  finishes <code>x0</code> will contain the address of the next table in the hierarchy - namely PMD.</p> <pre><code>    /* Mapping kernel and init stack*/\n    mov     x1, xzr                            // start mapping from physical offset 0\n    mov     x2, #VA_START                        // first virtual address\n    ldr    x3, =(VA_START + DEVICE_BASE - SECTION_SIZE)        // last virtual address\n    create_block_map x0, x1, x2, x3, MMU_FLAGS, x4\n</code></pre> <p>Next, we create virtual mapping of the whole memory, excluding device registers region. We use MMU_FLAGS constant as <code>flags</code> parameter - this marks all sections to be mapped as normal noncacheable memory. (Note, that <code>MM_ACCESS</code> flag is also specified as part of <code>MMU_FLAGS</code> constant. Without this flag each memory access will generate a synchronous exception.)</p> <pre><code>    /* Mapping device memory*/\n    mov     x1, #DEVICE_BASE                    // start mapping from device base address\n    ldr     x2, =(VA_START + DEVICE_BASE)                // first virtual address\n    ldr    x3, =(VA_START + PHYS_MEMORY_SIZE - SECTION_SIZE)    // last virtual address\n    create_block_map x0, x1, x2, x3, MMU_DEVICE_FLAGS, x4\n</code></pre> <p>Then device registers region is mapped. This is done exactly in the same way as in the previous code sample, with the exception that we are now using different start and end addresses and different flags.</p> <pre><code>    mov    x30, x29                        // restore return address\n    ret\n</code></pre> <p>Finally, the function restored link register and returns to the caller.</p>"},{"location":"exp6/rpi-os/#configuring-page-translation","title":"Configuring page translation","text":"<p>Now page tables are created and we are back to the <code>el1_entry</code> function. But there is still some work to be done before we can switch on the MMU. </p> <pre><code>    mov    x0, #VA_START\n    add    sp, x0, #LOW_MEMORY\n</code></pre> <p>We are updating init task stack pointer. Now it uses a virtual address, instead of a physical one. Therefore it could be used only after MMU is on. Recall that our kernel uses linear mapping therefore an offset is simply applied. </p> <pre><code>    adrp    x0, pg_dir\n    msr    ttbr1_el1, x0\n</code></pre> <p><code>ttbr1_el1</code> is updated to point to the previously populated PGD table.</p> <p>Q: Isn't pg_dir a virtual address (e.g. ffff000000083000) set by the linker? ttbr shall expect a physical address, right? How could this work? </p> <pre><code>    ldr    x0, =(TCR_VALUE)\n    msr    tcr_el1, x0\n</code></pre> <p><code>tcr_el1</code> of Translation Control Register is responsible for configuring some general parameters of the MMU. (For example, here we configure that both kernel and user page tables should use 4 KB pages.)</p> <pre><code>    ldr    x0, =(MAIR_VALUE)\n    msr    mair_el1, x0\n</code></pre> <p>We already discussed <code>mair</code> register in the \"Configuring page attributes\" section. Here we just set its value.</p> <pre><code>    ldr    x2, =kernel_main\n\n    mov    x0, #SCTLR_MMU_ENABLED\n    msr    sctlr_el1, x0 // BOOM!\n\n    br     x2\n</code></pre> <p><code>msr    sctlr_el1, x0</code> is the line where MMU is actually enabled. Now we can jump to the <code>kernel_main</code> function. From this moment onward kernel runs on virtual addresses completely. </p> <p>An interesting question is why can't we just execute <code>br kernel_main</code> instruction? Indeed, we can't. Before the MMU was enabled we have been working with physical memory, the kernel is loaded at a physical offset 0 - this means that current program counter (PC) is very close to 0. Switching on the MMU doesn't update PC. <code>br kernel_main</code> uses offset relative to the current PC and jumps to the place were <code>kernel_main</code> would have been if we don't turn on the MMU. </p> <p>Example: in generating the kernel binary, the linker starts from base address <code>0xffff000000000000</code> as controlled by our linker script. It assigns the instruction \"br kernel_main\" to address 0xffff000000000080; it assigns kernel_main to 0xffff000000003190. The instruction \"br kernel_main\" will be a relative jump, and will be emitted as \"br #0x3110\" (we  can verify this by disassembling the kernel binary).  At run time, when we reach \"br kernel_main\", PC is 0x80. Executing the instruction will update PC is to 0x3190. As MMU is on now, CPU fetches instruction at 0x3190 via MMU. A translation fault!</p> <p><code>ldr x2, =kernel_main</code> does not suffer from the problem. CPU loads <code>x2</code> with the link address of <code>kernel_main</code>, e.g. 0xffff000000003190. Different from <code>br kernel_main</code> which uses PC-based offset, <code>br x2</code> jumps to an absolute address stored in x2 (this is called long jmp). Therefore, PC will be updated with the link address of <code>kernel_main</code> which can be translated via MMU. In other words, by executing a long jmp, we \"synchronize\" the PC value with virtual addresses. </p> <p>Another question: why <code>ldr x2, =kernel_main</code> itself must be executed before we turn on the MMU? The reason is that <code>ldr</code> also uses <code>pc</code> relative offset.  See the manual. On my build, it emitted as <code>ldr x2, #0x10c</code>. So if we execute this instruction after MMU is on but before we \"synchronize\" PC, MMU will give another translation fault.</p>"},{"location":"exp6/rpi-os/#compiling-loading-user-programs","title":"Compiling &amp; loading user programs","text":"<p>Commodity kernels load user programs as ELF from filesystems. We won't be building a filesystem or ELF loader in this experiment. As a workaround, we will embed user programs in the kernel binary at link time, and load them at run time. For easy loading, we will store the user program in a separate ELF section of the kernel binary. Here is the relevant section of the linker script that is responsible for doing this.</p> <pre><code>//linker-qemu.ld (or linker.ld)\n    . = ALIGN(0x00001000);\n    user_begin = .;\n    .text.user : { build/user* (.text) }\n    .rodata.user : { build/user* (.rodata) }\n    .data.user : { build/user* (.data) }\n    .bss.user : { build/user* (.bss) }\n    user_end = .;\n</code></pre> <p>I made a convention: user level source code should be defined in C source files named as \"userXXX\". The linker script then can isolate all user related code in a continuous region, of which the start and end are marked with  <code>user_begin</code> and <code>user_end</code> symbols. At run time, the kernel simply copies everything between <code>user_begin</code> and <code>user_end</code> to the newly allocated process address space, thus simulating loading a user program. A simple hack, but suffice for our current purpose. </p>"},{"location":"exp6/rpi-os/#aside-our-user-symbol-addresses","title":"Aside: our user symbol addresses","text":"<p>As user programs will be linked as part the kernel binary, the linker will place all user symbols (functions &amp; variables) in the kernel's address space (0xffff000000000000 onwards). You can verify this by, e.g. <code>nm kernel8.elf|grep \" user_\"</code>. How could such user programs work?</p> <p>We rely on an assumption: our user programs are simple enough; they always address memory with register-relative offsets but not absolute address. You can verify this by disassembly. However, if our programs, e.g. call functions via pointers, the entailed long jmp will target absolute virtual address inside kernel and will trigger exception. </p> <p>This assumption can't go a long way. The right solution would be linking user programs and kernel separately. </p> <p>Right now there are 2 files that are compiled in the user region.</p> <ul> <li>user_sys.S This file contains definitions of the syscall wrapper functions. The RPi OS still supports the same syscalls as in the previous lesson, with the exception that now instead of <code>clone</code> syscall we are going to use <code>fork</code> syscall. The difference is that <code>fork</code> copies process virtual memory, and that is something we want to try doing.</li> <li>user.c User program source code. Almost the same as we've used in the previous lesson.</li> </ul>"},{"location":"exp6/rpi-os/#creating-first-user-process","title":"Creating first user process","text":"<p>As it was the case in the previous lesson, move_to_user_mode function is responsible for creating the first user process. We call this function from a kernel thread. Here is how we do this.</p> <pre><code>void kernel_process(){\n    printf(\"Kernel process started. EL %d\\r\\n\", get_el());\n    unsigned long begin = (unsigned long)&amp;user_begin;\n    unsigned long end = (unsigned long)&amp;user_end;\n    unsigned long process = (unsigned long)&amp;user_process;\n    int err = move_to_user_mode(begin, end - begin, process - begin);\n    if (err &lt; 0){\n        printf(\"Error while moving process to user mode\\n\\r\");\n    }\n}\n</code></pre> <p>Now we need 3 arguments to call <code>move_to_user_mode</code>: a pointer to the beginning of the user code area, size of the area and offset of the startup function inside it. This information is calculated based on the previously discussed <code>user_begin</code>  and <code>user_end</code> symbols (as global variables).</p> <p><code>move_to_user_mode</code> function is listed below.</p> <pre><code>int move_to_user_mode(unsigned long start, unsigned long size, unsigned long pc)\n{\n    struct pt_regs *regs = task_pt_regs(current);\n    regs-&gt;pstate = PSR_MODE_EL0t;\n    regs-&gt;pc = pc;\n    regs-&gt;sp = 2 *  PAGE_SIZE;\n    unsigned long code_page = allocate_user_page(current, 0);\n    if (code_page == 0)    {\n        return -1;\n    }\n    memcpy(code_page, start, size);\n    set_pgd(current-&gt;mm.pgd);\n    return 0;\n}\n</code></pre> <p>Now let's try to inspect in details what is going on here.</p> <pre><code>    struct pt_regs *regs = task_pt_regs(current);\n</code></pre> <p>As it was the case in the previous lesson, we obtain a pointer to <code>pt_regs</code> area and set <code>pstate</code>, so that after <code>kernel_exit</code> we will end up in EL0.</p> <pre><code>    regs-&gt;pc = pc;\n</code></pre> <p><code>pc</code> now points to the offset of the startup function in the user region.</p> <pre><code>    regs-&gt;sp = 2 *  PAGE_SIZE;\n</code></pre> <p>We made a simple convention that our user program will not exceed 1 page in size. We allocate the second page to the stack.</p> <pre><code>    unsigned long code_page = allocate_user_page(current, 0);\n    if (code_page == 0)    {\n        return -1;\n    }\n</code></pre> <p><code>allocate_user_page</code> reserves 1  memory page and maps it to the virtual address, provided as a second argument. In the process of mapping it populates page tables, associated with the current process. We will investigate in details how this function works later in this chapter.</p> <pre><code>    memcpy(code_page, start, size);\n</code></pre> <p>Next, we are going to copy the whole user region to the new address space (in the page that we have just mapped), starting from offset 0, so the offset in the user region will become an actual virtual address of the starting point.</p> <pre><code>    set_pgd(current-&gt;mm.pgd);\n</code></pre> <p>Finally, we call set_pgd, which updates <code>ttbr0_el1</code> register and thus activates the current process translation tables.</p>"},{"location":"exp6/rpi-os/#aside-tlb","title":"Aside: TLB","text":"<p>If you take a look at the <code>set_pgd</code> function you will see that after it sets <code>ttbr0_el1</code> it also clears TLB (Translation lookaside buffer). TLB is a cache that is designed specifically to store the mapping between physical and virtual pages. The first time some virtual address is mapped into a physical one this mapping is stored in TLB. Next time we need to access the same page we no longer need to perform full page table walk. Therefore it makes perfect sense that we invalidate TLB after updating page tables - otherwise our change will not be applied for the pages already stored in the TLB.</p> <p>Usually, we try to avoid using all caches for simplicity, but without TLB any memory access would become extremely inefficient, and I don't think that it is even possible to completely disable TLB. Besides, TLB doesn't add any other complexity to the OS, in spite of the fact that we must clean it after switching <code>ttbr0_el1</code>.</p>"},{"location":"exp6/rpi-os/#mapping-a-virtual-page-to-user","title":"Mapping a virtual page to user","text":"<p>We have seen previously how allocate_user_page function is used - now it is time to see what is inside it.</p> <pre><code>unsigned long allocate_user_page(struct task_struct *task, unsigned long va) {\n    unsigned long page = get_free_page();\n    if (page == 0) {\n        return 0;\n    }\n    map_page(task, va, page);\n    return page + VA_START;\n}\n</code></pre> <p>This function allocates a new page, maps it to the provided virtual address and returns a pointer to the page. When we say \"a pointer\" now we need to distinguish between 3 things: a pointer to a physical page, a pointer inside kernel address space and a pointer inside user address space - all these 3 different pointers can lead to the same location in memory. </p> <p>In our case <code>page</code> variable is a physical pointer (note its \"unsigned long\" type -- not a C pointer!) and the return value is a pointer inside kernel address space. This pointer can be easily calculated because we linearly map the whole physical memory starting at <code>VA_START</code> virtual address. Through the pointer, our kernel copies the user program to the page. Does our kernel have a virtual mapping for the new page? We do not have to worry, because kernel maps the entire physical memory in <code>boot.S</code>. </p> <p>User mapping is still required to be created and this happens in the map_page function, which we will explore next.</p> <pre><code>void map_page(struct task_struct *task, unsigned long va, unsigned long page){\n    unsigned long pgd;\n    if (!task-&gt;mm.pgd) {\n        task-&gt;mm.pgd = get_free_page();\n        task-&gt;mm.kernel_pages[++task-&gt;mm.kernel_pages_count] = task-&gt;mm.pgd;\n    }\n    pgd = task-&gt;mm.pgd;\n    int new_table;\n    unsigned long pud = map_table((unsigned long *)(pgd + VA_START), PGD_SHIFT, va, &amp;new_table);\n    if (new_table) {\n        task-&gt;mm.kernel_pages[++task-&gt;mm.kernel_pages_count] = pud;\n    }\n    unsigned long pmd = map_table((unsigned long *)(pud + VA_START) , PUD_SHIFT, va, &amp;new_table);\n    if (new_table) {\n        task-&gt;mm.kernel_pages[++task-&gt;mm.kernel_pages_count] = pmd;\n    }\n    unsigned long pte = map_table((unsigned long *)(pmd + VA_START), PMD_SHIFT, va, &amp;new_table);\n    if (new_table) {\n        task-&gt;mm.kernel_pages[++task-&gt;mm.kernel_pages_count] = pte;\n    }\n    map_table_entry((unsigned long *)(pte + VA_START), va, page);\n    struct user_page p = {page, va};\n    task-&gt;mm.user_pages[task-&gt;mm.user_pages_count++] = p;\n}\n</code></pre> <p><code>map_page</code> in some way duplicates what we've been doing in the <code>__create_page_tables</code> function: it allocates and populates a page table hierarchy. There are 3 important difference, however: now we are doing this in C, instead of assembler. <code>map_page</code> maps a single page, instead of the whole memory, and use normal page mapping, instead of section mapping.</p> <p>There are 2 important functions involved in the process:  map_table and map_table_entry. </p> <p><code>map_table</code> is listed below.</p> <pre><code>unsigned long map_table(unsigned long *table, unsigned long shift, unsigned long va, int* new_table) {\n    unsigned long index = va &gt;&gt; shift;\n    index = index &amp; (PTRS_PER_TABLE - 1);\n    if (!table[index]){\n        *new_table = 1;\n        unsigned long next_level_table = get_free_page();\n        unsigned long entry = next_level_table | MM_TYPE_PAGE_TABLE;\n        table[index] = entry;\n        return next_level_table;\n    } else {\n        *new_table = 0;\n    }\n    return table[index] &amp; PAGE_MASK;\n}\n</code></pre> <p>This function has the following arguments.</p> <ul> <li><code>table</code> This is a pointer to the parent page table. This page table is assumed to be already allocated, but might be empty.</li> <li><code>shift</code> This argument is used to extract table index from the provided virtual address.</li> <li><code>va</code> Virtual address itself.</li> <li><code>new_table</code> This is an output parameter. It is set to 1 if a new child table has been allocated and left 0 otherwise.</li> </ul> <p>You can think of this function as an analog of the <code>create_table_entry</code> macro. It extracts table index from the virtual address and prepares a descriptor in the parent table that points to the child table. Unlike <code>create_table_entry</code> macro we don't assume that the child table should be adjacent into memory with the parent table - instead, we rely on <code>get_free_table</code> function to return whatever page is available. It also might be the case that child table was already allocated (This might happen if child page table covers the region where another page has been allocated previously.). In this case we set <code>new_table</code> to 0 and read child page table address from the parent table.</p> <p><code>map_page</code> calls <code>map_table</code> 3 times: once for PGD, PUD and PMD. The last call allocates PTE and sets a descriptor in the PMD. Next, <code>map_table_entry</code> is called. You can see this function below.</p> <pre><code>void map_table_entry(unsigned long *pte, unsigned long va, unsigned long pa) {\n    unsigned long index = va &gt;&gt; PAGE_SHIFT;\n    index = index &amp; (PTRS_PER_TABLE - 1);\n    unsigned long entry = pa | MMU_PTE_FLAGS;\n    pte[index] = entry;\n}\n</code></pre> <p><code>map_table_entry</code> extracts PTE index from the virtual address and then prepares and sets PTE descriptor. It is similar to what we've been doing in the <code>create_block_map</code> macro. </p> <p>That's it about user page tables allocation, but <code>map_page</code> is responsible for one more important role: it keeps track of the pages that have been allocated during the process of virtual address mapping. All such pages are stored in the kernel_pages array. We need this array to be able to clean up allocated pages after a task exits. There is also user_pages array, which is also populated by the <code>map_page</code> function. This array store information about the correspondence between process virtual pages any physical pages. We need this information in order to be able to copy process virtual memory during <code>fork</code> (More on this later).</p>"},{"location":"exp6/rpi-os/#forking-a-user-process","title":"Forking a user process","text":"<p>Let's summarize where we are so far: we've seen how first user process is created, its page tables populated, code &amp; data copied to the proper location and stack initialized. After all of this preparation, the process is ready to run. The code that is executed inside user process is listed below.</p> <pre><code>void loop(char* str)\n{\n    char buf[2] = {\"\"};\n    while (1){\n        for (int i = 0; i &lt; 5; i++){\n            buf[0] = str[i];\n            call_sys_write(buf);\n            user_delay(1000000);\n        }\n    }\n}\n\nvoid user_process() \n{\n    call_sys_write(\"User process\\n\\r\");\n    int pid = call_sys_fork();\n    if (pid &lt; 0) {\n        call_sys_write(\"Error during fork\\n\\r\");\n        call_sys_exit();\n        return;\n    }\n    if (pid == 0){\n        loop(\"abcde\");\n    } else {\n        loop(\"12345\");\n    }\n}\n</code></pre>"},{"location":"exp6/rpi-os/#the-familiar-fork-semantics","title":"The familiar fork() semantics","text":"<p>The code itself is very simple as we expect. Unlike <code>clone</code>, when doing <code>fork</code> we don't need to provide the function that needs to be executed in a new process. Also, the fork wrapper function is much easier than the <code>clone</code> one. All of this is possible because of the fact that <code>fork</code> makes a full copy of the process virtual address space, so the fork wrapper function return twice: one time in the original process and one time in the new one. At this point, we have two identical processes, with identical stacks and <code>pc</code> positions. The only difference is the return value of the <code>fork</code> syscall: it returns child PID in the parent process and 0 in the child process. Starting from this point both processes begin completely independent life and can modify their stacks and write different things using same addresses in memory - all of this without affecting one another.</p>"},{"location":"exp6/rpi-os/#implementation","title":"Implementation","text":"<p>Now let's see how <code>fork</code> system call is implemented. copy_process function does most of the job.</p> <pre><code>int copy_process(unsigned long clone_flags, unsigned long fn, unsigned long arg)\n{\n    preempt_disable();\n    struct task_struct *p;\n\n    unsigned long page = allocate_kernel_page();\n    p = (struct task_struct *) page;\n    struct pt_regs *childregs = task_pt_regs(p);\n\n    if (!p)\n        return -1;\n\n    if (clone_flags &amp; PF_KTHREAD) {\n        p-&gt;cpu_context.x19 = fn;\n        p-&gt;cpu_context.x20 = arg;\n    } else {\n        struct pt_regs * cur_regs = task_pt_regs(current);\n        *childregs = *cur_regs;\n        childregs-&gt;regs[0] = 0;\n        copy_virt_memory(p);\n    }\n    p-&gt;flags = clone_flags;\n    p-&gt;priority = current-&gt;priority;\n    p-&gt;state = TASK_RUNNING;\n    p-&gt;counter = p-&gt;priority;\n    p-&gt;preempt_count = 1; //disable preemtion until schedule_tail\n\n    p-&gt;cpu_context.pc = (unsigned long)ret_from_fork;\n    p-&gt;cpu_context.sp = (unsigned long)childregs;\n    int pid = nr_tasks++;\n    task[pid] = p;\n\n    preempt_enable();\n    return pid;\n}\n</code></pre> <p>This function looks almost exactly the same as in the previous lesson with one exception: when copying user processes, now, instead of modifying new process stack pointer and program counter, we instead call copy_virt_memory. <code>copy_virt_memory</code> looks like this.</p> <pre><code>int copy_virt_memory(struct task_struct *dst) {\n    struct task_struct* src = current;\n    for (int i = 0; i &lt; src-&gt;mm.user_pages_count; i++) {\n        unsigned long kernel_va = allocate_user_page(dst, src-&gt;mm.user_pages[i].virt_addr);\n        if( kernel_va == 0) {\n            return -1;\n        }\n        memcpy(kernel_va, src-&gt;mm.user_pages[i].virt_addr, PAGE_SIZE);\n    }\n    return 0;\n}\n</code></pre> <p>It iterates over <code>user_pages</code> array, which contains all pages, allocated by the current process. Note, that in <code>user_pages</code> array we store only pages that are actually available to the process and contain its code or data; we don't include here page table pages, which are stored in <code>kernel_pages</code> array. Next, for each page, we allocate another empty page and copy the original page content there. We also map the new page using the same virtual address, that is used by the original one. This is how we get the exact copy of the original process address space.</p> <p>All other details of the forking procedure work exactly in the same way, as they have been in the previous lesson.</p> <p>Q: does our fork() implement COW? </p>"},{"location":"exp6/rpi-os/#demand-paging","title":"Demand paging","text":"<p>If you go back and take a look at the <code>move_to_user_mode</code> function, you may notice that we only map a single page, starting at offset 0. But we also assume that the second page will be used as a stack. Our kernel will map stack page, as well as any other page that a process needs to access as soon as it will be requested for the first time. Now we are going to explore the inner-workings of this mechanism.</p>"},{"location":"exp6/rpi-os/#setting-up-page-faults","title":"Setting up page faults","text":"<p>When a process tries to access some address which belongs to the page that is not yet mapped, a synchronous exception is generated. This is the second type of synchronous exception that we are going to support (the first type is an exception generated by the <code>svc</code> instruction which is a system call). Synchronous exception handler now looks like the following.</p> <pre><code>// entry.S\nel0_sync:\n    kernel_entry 0\n    mrs    x25, esr_el1                // read the syndrome register\n    lsr    x24, x25, #ESR_ELx_EC_SHIFT        // exception class\n    cmp    x24, #ESR_ELx_EC_SVC64            // SVC in 64-bit state\n    b.eq    el0_svc\n    cmp    x24, #ESR_ELx_EC_DABT_LOW        // data abort in EL0\n    b.eq    el0_da\n    handle_invalid_entry 0, SYNC_ERROR\n</code></pre> <p>Here we use <code>esr_el1</code> register to determine exception type. If it is a page fault exception (or, which is the same, data access exception) <code>el0_da</code> function is called.</p> <pre><code>// entry.S\nel0_da:\n    bl    enable_irq\n    mrs    x0, far_el1\n    mrs    x1, esr_el1\n    bl    do_mem_abort\n    cmp x0, 0\n    b.eq 1f\n    handle_invalid_entry 0, DATA_ABORT_ERROR\n1:\n    bl disable_irq\n    kernel_exit 0\n</code></pre> <p><code>el0_da</code> redirects the main work to the do_mem_abort function. This function takes two arguments</p> <ol> <li>The memory address which we tried to access. This address is taken from <code>far_el1</code>  register (Fault address register)</li> <li>The content of the <code>esr_el1</code> (Exception syndrome register)</li> </ol>"},{"location":"exp6/rpi-os/#handling-page-faults","title":"Handling page faults","text":"<p><code>do_mem_abort</code> is listed below.</p> <pre><code>// mm.c\nint do_mem_abort(unsigned long addr, unsigned long esr) {\n    unsigned long dfs = (esr &amp; 0b111111);\n    if ((dfs &amp; 0b111100) == 0b100) {\n        unsigned long page = get_free_page();\n        if (page == 0) {\n            return -1;\n        }\n        map_page(current, addr &amp; PAGE_MASK, page);\n        ind++;\n        if (ind &gt; 2){\n            return -1;\n        }\n        return 0;\n    }\n    return -1;\n}\n</code></pre> <p>In order to understand this function, you need to know a little bit about the specifics of that <code>esr_el1</code> register. Bits [32:26] of this register are called \"Exception Class\". We check those bits in the <code>el0_sync</code> handler to determine whether it is a syscall, or a data abort exception or potentially something else. Exception class determines the meaning of bits [24:0] - those bits are usually used to provide additional information about the exception. The meaning of [24:0] bits in case of the data abort exception is described on the page 2460 of the <code>AArch64-Reference-Manual</code>. In general, data abort exception can happen in many different scenarios (it could be a permission fault, or address size fault or a lot of other things). We are only interested in a translation fault which happens when some of the page tables for the current virtual address are not initialized. So in the first 2 lines of the <code>do_mem_abort</code> function, we check whether the current exception is actually a translation fault. If yes we allocate a new page and map it to the requested virtual address. All of this happens completely transparent for the user program - it doesn't notice that some of the memory accesses were interrupted and new page tables were allocated in the meantime.</p>"},{"location":"exp6/rpi-os/#conclusion","title":"Conclusion","text":"<p>This was a long and difficult chapter, but I hope it was useful as well. Virtual memory is really one of the most fundamental pieces of any operating system and I am glad we've passed through this chapter and, hopefully, started to understand how it works at the lowest level. With the introduction of virtual memory we now have full process isolation, but the RPi OS is still far from completion. It still doesn't support file systems, drivers, signals and interrupt waitlists, networking and a lot of other useful concepts, and we will continue to uncover them in the upcoming lessons.</p>"}]}